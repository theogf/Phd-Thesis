
@misc{Mathematica,
	title = {Mathematica, \{{V}\}ersion 12.0},
	author = {Inc., , Wolfram Research},
	year = {2019},
	note = {ZSCC: NoCitationData[s0] },
}

@article{nguyenOnlineVariationalBayesian2017,
	title = {Online {Variational} {Bayesian} {Inference}: {Algorithms} for {Sparse} {Gaussian} {Processes} and {Theoretical} {Bounds}},
	abstract = {Sparse approximations for Gaussian process models provide a suite of methods that enable these models to be deployed in large data regime and enable analytic intractabilities to be sidestepped. However, the field lacks a prin-cipled method to handle streaming data, which are important for time-series analysis. The small number of existing approaches either use subop-timal hand-crafted heuristics for hyperparameter learning, or suffer from catastrophic forgetting or slow updating when new data arrive. This paper develops a new principled framework for deploying Gaussian process probabilistic models in the streaming setting, providing principled methods for learning hyperparameters and optimising pseudo-input locations. New theoretical bounds for general online variational Bayesian inference are also given and discussed in the paper.},
	author = {Nguyen, Cuong V and Bui, Thang D and Li, Yingzhen and Turner, Richard E},
	year = {2017},
	note = {ZSCC: 0000003},
}

@book{yeh2006real,
	title = {Real analysis: theory of measure and integration second edition},
	publisher = {World Scientific Publishing Company},
	author = {Yeh, James},
	year = {2006},
	note = {ZSCC: 0000203 },
}

@article{jylanki2011robust,
	title = {Robust {Gaussian} process regression with a \{{S}\}tudent-t likelihood},
	volume = {12},
	number = {Nov},
	journal = {Journal of Machine Learning Research},
	author = {Jylänki, Pasi and Vanhatalo, Jarno and Vehtari, Aki},
	year = {2011},
	note = {ZSCC: NoCitationData[s0] },
	pages = {3227--3257},
}

@article{kingma2014adam,
	title = {Adam: {A} method for stochastic optimization},
	journal = {arXiv preprint arXiv:1412.6980},
	author = {Kingma, Diederik P and Ba, Jimmy},
	year = {2014},
	note = {ZSCC: 0041937 },
}

@article{Pandit_2018,
	title = {Comparative analysis of binning and {Gaussian} {Process} based blade pitch angle curve of a wind turbine for the purpose of condition monitoring},
	volume = {1102},
	journal = {Journal of Physics: Conference Series},
	author = {Pandit, Ravi Kumar and Infield, David},
	year = {2018},
	note = {ZSCC: 0000003 },
}

@article{schoenberg1938metric,
	title = {Metric spaces and completely monotone functions},
	journal = {Annals of Mathematics},
	author = {Schoenberg, Isaac J},
	year = {1938},
	note = {ZSCC: 0001058 
Publisher: JSTOR},
	pages = {811--841},
}

@book{bochner1959lectures,
	title = {Lectures on {Fourier} integrals},
	publisher = {Princeton University Press},
	author = {Bochner, Salomon},
	year = {1959},
	note = {ZSCC: 0000651 },
}

@article{kuhn2019probabilistic,
	title = {A probabilistic proof of {Schoenberg}'s theorem},
	volume = {476},
	number = {1},
	journal = {Journal of Mathematical Analysis and Applications},
	author = {Kühn, Franziska and Schilling, René L},
	year = {2019},
	note = {ZSCC: 0000003 
Publisher: Elsevier},
	pages = {13--26},
}

@article{van2017convolutional,
	title = {Convolutional {Gaussian} {Processes}},
	issn = {00320781},
	doi = {10.1093/oxfordjournals.pcp.a079040},
	abstract = {We present a practical way of introducing convolutional structure into Gaussian processes, making them more suited to high-dimensional inputs like images. The main contribution of our work is the construction of an inter-domain inducing point approximation that is well-tailored to the convolutional kernel. This allows us to gain the generalisation benefit of a convolutional kernel, together with fast but accurate posterior inference. We investigate several variations of the convolutional kernel, and apply it to MNIST and CIFAR-10, which have both been known to be challenging for Gaussian processes. We also show how the marginal likelihood can be used to find an optimal weighting between convolutional and RBF kernels to further improve performance. We hope that this illustration of the usefulness of a marginal likelihood will help automate discovering architectures in larger models.},
	journal = {Advances in Neural Information Processing Systems},
	author = {van der Wilk, Mark and Rasmussen, Carl Edward and Hensman, James},
	year = {2017},
	note = {ZSCC: 0000042 
arXiv: 1709.01894
ISBN: 1709.01894v1},
	file = {Convolutional Gaussian Processes - van der Wilk et al - 2017.pdf:/home/theo/Zotero/storage/JRXKRC2R/Convolutional Gaussian Processes - van der Wilk et al - 2017.pdf:application/pdf},
}

@article{naessethMarkovianScoreClimbing2020,
	title = {Markovian {Score} {Climbing} : {Variational} {Inference} with {KL} ( p {\textbar}{\textbar} q )},
	number = {Vi},
	author = {Naesseth, Christian A and Lindsten, Fredrik and Blei, David},
	year = {2020},
	note = {ZSCC: 0000000 
arXiv: 2003.10374v1},
}

@article{hayashiSelfmeasuringSimilarityMultitask2012,
	title = {Self-measuring similarity for multi-task {Gaussian} process},
	volume = {27},
	issn = {13468030},
	doi = {10.1527/tjsai.27.103},
	abstract = {Multi-task learning aims at transferring knowledge between similar tasks. The multi-task Gaussian process framework of Bonilla et al.models (incomplete) responses of C data points for R tasks (e.g., the responses are given by R×C matrix) by a Gaussian process; the covariance function is defined as the product of a covariance function on input-dependent features and the inter-task covariance matrix (which is empirically estimated as a model parameter). We extend this framework by incorporating a novel similarity measurement, which allows for the representation of much more complex data structures. The proposed framework also enables us to exploit additional information (e.g., the input-dependent features) by constructing the covariance matrices with combining them on the covariance function. We also derive an efficient learning algorithm to make prediction by using an iterative method. Finally, we apply our model to a real data set of recommender systems and show that the proposed method achieves the best prediction accuracy on the data set.},
	number = {3},
	journal = {Transactions of the Japanese Society for Artificial Intelligence},
	author = {Hayashi, Kohei and Takenouchi, Takashi and Tomioka, Ryota and Kashima, Hisashi},
	year = {2012},
	note = {ZSCC: 0000016},
	keywords = {Collaborative filtering, Conjugate gradient, Gaussian process, Multi-task learning},
	pages = {103--110},
	file = {Self-measuring similarity for multi-task Gaussian process - Hayashi et al - 2012.pdf:/home/theo/Zotero/storage/AY2PG827/Self-measuring similarity for multi-task Gaussian process - Hayashi et al - 2012.pdf:application/pdf},
}

@article{polsonBayesianInferenceLogistic2012,
	title = {Bayesian inference for logistic models using {Polya}-{Gamma} latent variables},
	issn = {0162-1459},
	url = {http://arxiv.org/abs/1205.0310},
	doi = {10.1080/01621459.2013.829001},
	abstract = {We propose a new data-augmentation strategy for fully Bayesian inference in models with binomial likelihoods. The approach appeals to a new class of Polya-Gamma distributions, which are constructed in detail. A variety of examples are presented to show the versatility of the method, including logistic regression, negative binomial regression, nonlinear mixed-effects models, and spatial models for count data. In each case, our data-augmentation strategy leads to simple, effective methods for posterior inference that: (1) circumvent the need for analytic approximations, numerical integration, or Metropolis-Hastings; and (2) outperform other known data-augmentation strategies, both in ease of use and in computational efficiency. All methods, including an efficient sampler for the Polya-Gamma distribution, are implemented in the R package BayesLogit. In the technical supplement appended to the end of the paper, we provide further details regarding the generation of Polya-Gamma random variables; the empirical benchmarks reported in the main manuscript; and the extension of the basic data-augmentation framework to contingency tables and multinomial outcomes.},
	author = {Polson, Nicholas G. and Scott, James G. and Windle, Jesse},
	year = {2012},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1205.0310},
	pages = {1--42},
	file = {Bayesian inference for logistic models using Polya-Gamma latent variables - Polson et al - 2012.pdf:/home/theo/Zotero/storage/8TVKPRKA/Bayesian inference for logistic models using Polya-Gamma latent variables - Polson et al - 2012.pdf:application/pdf},
}

@article{amariNaturalGradientWorks1998,
	title = {Natural {Gradient} {Works} {Efficiently} in {Learning}},
	volume = {10},
	issn = {08997667},
	url = {http://www.mitpressjournals.org/doi/10.1162/089976698300017746},
	doi = {10.1162/089976698300017746},
	abstract = {When a parameter space has a certain underlying structure, the ordinary gradient of a function does not represent its steepest direction, but the natural gradient does. Information geometry is used for calculating the natural gradients in the parameter space of perceptrons, the space of matrices (for blind source separation), and the space of linear dynamical systems (for blind source deconvolution). The dynamical behavior of natural gradient online learning is analyzed and is proved to be Fisher efficient, implying that it has asymptotically the same performance as the optimal batch estimation of parameters. This suggests that the plateau phenomenon, which appears in the backpropagation learning algorithm of multilayer perceptrons, might disappear or might not be so serious when the natural gradient is used. An adaptive method of updating the learning rate is proposed and analyzed.},
	number = {2},
	journal = {Neural Computation},
	author = {Amari, Shun Ichi},
	year = {1998},
	note = {ZSCC: 0002989 
ISBN: 0899-7667},
	pages = {251--276},
	file = {Natural Gradient Works Efficiently in Learning - Amari - 1998.pdf:/home/theo/Zotero/storage/R4GB5CUU/Natural Gradient Works Efficiently in Learning - Amari - 1998.pdf:application/pdf},
}

@article{Hensman2015,
	title = {Scalable {Variational} {Gaussian} {Process} {Classification}},
	volume = {38},
	issn = {15337928},
	abstract = {Gaussian process classification is a popular method with a number of appealing properties. We show how to scale the model within a variational inducing point framework, outperforming the state of the art on benchmark datasets. Importantly, the variational formulation can be exploited to allow classification in problems with millions of data points, as we demonstrate in experiments.},
	journal = {Aistats},
	author = {Hensman, James and Matthews, Alexander},
	year = {2015},
	note = {ZSCC: 0000200 
arXiv: 1411.2005},
	pages = {1--9},
	file = {Scalable Variational Gaussian Process Classification - Hensman_Matthews - 2015.pdf:/home/theo/Zotero/storage/GSXWSGCR/Scalable Variational Gaussian Process Classification - Hensman_Matthews - 2015.pdf:},
}

@article{mattosRecurrentGaussianProcesses2015,
	title = {Recurrent {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/1511.06644},
	abstract = {We define Recurrent Gaussian Processes (RGP) models, a general family of Bayesian nonparametric models with recurrent GP priors which are able to learn dynamical patterns from sequential data. Similar to Recurrent Neural Networks (RNNs), RGPs can have different formulations for their internal states, distinct inference methods and be extended with deep structures. In such context, we propose a novel deep RGP model whose autoregressive states are latent, thereby performing representation and dynamical learning simultaneously. To fully exploit the Bayesian nature of the RGP model we develop the Recurrent Variational Bayes (REVARB) framework, which enables efficient inference and strong regularization through coherent propagation of uncertainty across the RGP layers and states. We also introduce a RGP extension where variational parameters are greatly reduced by being reparametrized through RNN-based sequential recognition models. We apply our model to the tasks of nonlinear system identification and human motion modeling. The promising obtained results indicate that our RGP model maintains its highly flexibility while being able to avoid overfitting and being applicable even when larger datasets are not available.},
	number = {3},
	author = {Mattos, César Lincoln C. and Dai, Zhenwen and Damianou, Andreas and Forth, Jeremy and Barreto, Guilherme A. and Lawrence, Neil D.},
	year = {2015},
	note = {ZSCC: 0000046 
arXiv: 1511.06644
ISBN: 1511.06644},
	pages = {1--12},
	file = {Recurrent Gaussian Processes - Mattos et al - 2015.pdf:/home/theo/Zotero/storage/3MJNEJP2/Recurrent Gaussian Processes - Mattos et al - 2015.pdf:application/pdf},
}

@article{buiStreamingSparseGaussian2017,
	title = {Streaming {Sparse} {Gaussian} {Process} {Approximations}},
	issn = {10495258},
	url = {http://arxiv.org/abs/1705.07131},
	doi = {10.1016/j.renene.2013.06.012},
	abstract = {Sparse pseudo-point approximations for Gaussian process (GP) models provide a suite of methods that support deployment of GPs in the large data regime and enable analytic intractabilities to be sidestepped. However, the field lacks a principled method to handle streaming data in which both the posterior distribution over function values and the hyperparameter estimates are updated in an online fashion. The small number of existing approaches either use suboptimal hand-crafted heuristics for hyperparameter learning, or suffer from catastrophic forgetting or slow updating when new data arrive. This paper develops a new principled framework for deploying Gaussian process probabilistic models in the streaming setting, providing methods for learning hyperparameters and optimising pseudo-input locations. The proposed framework is assessed using synthetic and real-world datasets.},
	number = {Nips},
	author = {Bui, Thang D. and Nguyen, Cuong V. and Turner, Richard E.},
	year = {2017},
	note = {ZSCC: 0000029 
arXiv: 1705.07131},
	file = {Streaming Sparse Gaussian Process Approximations - Bui et al - 2017.pdf:/home/theo/Zotero/storage/LHRXZWXV/Streaming Sparse Gaussian Process Approximations - Bui et al - 2017.pdf:application/pdf;Streaming Sparse Gaussian Process Approximations - Bui et al - 2017.pdf:/home/theo/Zotero/storage/MD8XG32Q/Streaming Sparse Gaussian Process Approximations - Bui et al - 2017.pdf:application/pdf},
}

@article{bianeProbabilityLawsRelated2001,
	title = {Probability laws related to the jacobi theta and riemann zeta functions, and brownian excursions},
	volume = {38},
	issn = {02730979},
	abstract = {This paper reviews known results which connect Riemann's integral{\textbackslash}nrepresentations of his zeta function, involving Jacobi's theta function and its{\textbackslash}nderivatives, to some particular probability laws governing sums of independent{\textbackslash}nexponential variables. These laws are related to one-dimensional Brownian{\textbackslash}nmotion and to higher dimensional Bessel processes. We present some{\textbackslash}ncharacterizations of these probability laws, and some approximations of{\textbackslash}nRiemann's zeta function which are related to these laws.},
	number = {4},
	journal = {Bulletin of the American Mathematical Society},
	author = {Biane, Philippe and Pitman, Jim and Yor, Marc},
	year = {2001},
	note = {ZSCC: 0000294},
	keywords = {Bessel process, Functional equation, Infinitely divisible laws, Sums of independent exponential variables},
	pages = {435--465},
}

@article{matthewsSparseVariationalMethods2015,
	title = {On {Sparse} variational methods and the {Kullback}-{Leibler} divergence between stochastic processes},
	issn = {1938-7228},
	url = {http://arxiv.org/abs/1504.07027},
	abstract = {The variational framework for learning inducing variables (Titsias, 2009a) has had a large impact on the Gaussian process literature. The framework may be interpreted as minimizing a rigorously defined Kullback-Leibler divergence between the approximating and posterior processes. To our knowledge this connection has thus far gone unremarked in the literature. In this paper we give a substantial generalization of the literature on this topic. We give a new proof of the result for infinite index sets which allows inducing points that are not data points and likelihoods that depend on all function values. We then discuss augmented index sets and show that, contrary to previous works, marginal consistency of augmentation is not enough to guarantee consistency of variational inference with the original model. We then characterize an extra condition where such a guarantee is obtainable. Finally we show how our framework sheds light on interdomain sparse approximations and sparse approximations for Cox processes.},
	number = {1},
	journal = {Aistats},
	author = {Matthews, Alexander G. de G. and Hensman, James and Turner, Richard E. and Ghahramani, Zoubin},
	year = {2015},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1504.07027
ISBN: 1504.07027},
	pages = {1--8},
	file = {On Sparse variational methods and the Kullback-Leibler divergence between - Matthews et al - 2015.pdf:/home/theo/Zotero/storage/N9UYHA5B/On Sparse variational methods and the Kullback-Leibler divergence between - Matthews et al - 2015.pdf:application/pdf},
}

@article{Gretton1648,
	title = {New {Directions} for {Learning} with {Kernels} and {Gaussian} {Processes}},
	volume = {6},
	url = {http://www.dagstuhl.de/16481},
	doi = {10.4230/DagRep.6.11.142},
	abstract = {The Dagstuhl Seminar on 16481 " New Directions for Learning with Kernels and Gaussian Pro-cesses " brought together two principal theoretical camps of the machine learning community at a crucial time for the field. Kernel methods and Gaussian process models together form a signi-ficant part of the discipline's foundations, but their prominence is waning while more elaborate but poorly understood hierarchical models are ascendant. In a lively, amiable seminar, the par-ticipants re-discovered common conceptual ground (and some continued points of disagreement) and productively discussed how theoretical rigour can stay relevant during a hectic phase for the subject.},
	number = {11},
	journal = {Report from Dagstuhl Seminar},
	author = {Gretton, Arthur and Hennig, Philipp and Rasmussen, Carl Edward and Schölkopf, Bernhard},
	year = {1648},
	note = {ZSCC: NoCitationData[s0] },
	keywords = {1998 ACM Subject Classification G11 Interpolation, and phrases gaussian processes, G12 Approximation, G3 Probability and Statistics, I26 Learning Keywords and phrases gaussian process, kernel methods, machine learning, probabilistic nu-merics, probabilistic programming, probabilistic programming Digital Object},
	pages = {142--167},
	file = {New Directions for Learning with Kernels and Gaussian Processes - Gretton et al - 1648.pdf:/home/theo/Zotero/storage/9H9Q4PQG/New Directions for Learning with Kernels and Gaussian Processes - Gretton et al - 1648.pdf:application/pdf},
}

@article{jaakkolaBayesianParameterEstimation2000,
	title = {Bayesian parameter estimation via variational methods},
	volume = {10},
	issn = {09603174},
	doi = {10.1023/A:1008932416310},
	abstract = {We consider a logistic regression model with a Gaussian prior distribution over the parameters. We show that an accurate variational transformation can be used to obtain a closed form approximation to the posterior distribution of the parameters thereby yielding an approximate posterior predictive model. This approach is readily extended to binary graphical model with complete observations. For graphical models with incomplete observations we utilize an additional variational transformation and again obtain a closed form approximation to the posterior. Finally, we show that the dual of the regression problem gives a latent variable density model, the variational formulation of which leads to exactly solvable EM updates.},
	number = {1},
	journal = {Statistics and Computing},
	author = {Jaakkola, Tommi S. and Jordan, Michael I.},
	year = {2000},
	note = {ZSCC: 0000581},
	keywords = {Bayesian estimation, Belief networks, Graphical models, Incomplete data, Logistic regression, Variational methods},
	pages = {25--37},
}

@article{sukINCREMENTALSPARSEPSEUDOINPUT2012,
	title = {{INCREMENTAL} {SPARSE} {PSEUDO}-{INPUT} {GAUSSIAN} {PROCESS} {REGRESSION}},
	volume = {26},
	issn = {0218-0014},
	doi = {10.1142/s021800141250019x},
	abstract = {In this paper, we devise a novel method that incrementally learns pseudo-data, which represent the whole training data set for Gaussian Process (GP) regression. The method involves sparse approximation of the GP by extending the work of Snelson and Ghahramani. We call the proposed method Incremental Sparse Pseudo-input Gaussian Process (ISPGP) regression. Unlike the Snelson and Ghahramani's work, the proposed ISPGP algorithm allows for training from either a huge amount of training data by scanning through it only once or an online incremental training data set. We also design a likelihood weighting scheme to incrementally determine pseudo-data while maintaining the representational power. Due to the nature of the incremental learning algorithm, the proposed ISPGP algorithm can theoretically work with infinite data to which the conventional GP or Sparse Pseudo-input Gaussian Process (SPGP) algorithm is not applicable. From our experimental results on the KIN40K data set, we can see that the proposed ISPGP algorithm is comparable to the conventional GP algorithm using the same number of training data. It also significantly reduces the computational cost and memory requirement in regression and is scalable to a large training data set without significant performance degradation. Although the proposed ISPGP algorithm performs slightly worse than Snelson and Ghahramani's SPGP algorithm, the level of performance degradation is acceptable. © World Scientific Publishing Company.},
	number = {08},
	journal = {International Journal of Pattern Recognition and Artificial Intelligence},
	author = {SUK, HEUNG-IL and WANG, YUZHUO and LEE, SEONG-WHAN},
	year = {2012},
	note = {ZSCC: 0000002},
	pages = {1250019},
}

@article{gneitingNormalScaleMixtures1997,
	title = {Normal scale mixtures and dual probability densities},
	volume = {59},
	issn = {00949655},
	doi = {10.1080/00949659708811867},
	number = {4},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Gneiting, Tilmann},
	year = {1997},
	note = {ZSCC: 0000073 
ISBN: 0094965970881},
	keywords = {Dual density, Normal scale mixture, Random variate generation},
	pages = {375--384},
}

@article{khanConjugateComputationVariationalInference2017,
	title = {Conjugate-{Computation} {Variational} {Inference} : {Converting} {Variational} {Inference} in {Non}-{Conjugate} {Models} to {Inferences} in {Conjugate} {Models}},
	volume = {54},
	url = {http://arxiv.org/abs/1703.04265},
	abstract = {Variational inference is computationally challenging in models that contain both conjugate and non-conjugate terms. Methods specifically designed for conjugate models, even though computationally efficient, find it difficult to deal with non-conjugate terms. On the other hand, stochastic-gradient methods can handle the non-conjugate terms but they usually ignore the conjugate structure of the model which might result in slow convergence. In this paper, we propose a new algorithm called Conjugate-computation Variational Inference (CVI) which brings the best of the two worlds together -- it uses conjugate computations for the conjugate terms and employs stochastic gradients for the rest. We derive this algorithm by using a stochastic mirror-descent method in the mean-parameter space, and then expressing each gradient step as a variational inference in a conjugate model. We demonstrate our algorithm's applicability to a large class of models and establish its convergence. Our experimental results show that our method converges much faster than the methods that ignore the conjugate structure of the model.},
	author = {Khan, Mohammad Emtiyaz and Lin, Wu},
	year = {2017},
	note = {ZSCC: 0000036 
arXiv: 1703.04265},
	file = {Conjugate-Computation Variational Inference  Converting Variational Inference in Non-Conjugate Models to Inferences in Conjugate Models - Khan and Lin - 2017 - .pdf:/home/theo/Zotero/storage/QIGZKU6S/Conjugate-Computation Variational Inference  Converting Variational Inference in Non-Conjugate Models to Inferences in Conjugate Models - Khan and Lin - 2017 - .pdf:application/pdf},
}

@article{krauthAutoGPExploringCapabilities2016,
	title = {{AutoGP}: {Exploring} the {Capabilities} and {Limitations} of {Gaussian} {Process} {Models}},
	url = {http://arxiv.org/abs/1610.05392},
	abstract = {We investigate the capabilities and limitations of Gaussian process (GP) models by jointly exploring three complementary directions: (i) scalable and statistically efficient inference; (ii) flexible kernels; and (iii) objective functions for hyperparameter learning alternative to the marginal likelihood. Our approach outperforms all previously reported GP methods on the standard MNIST dataset; achieves state-of-the-art performance in a task particularly hard for kernel-based methods using the RECTANGLES-IMAGE dataset; and breaks the 1\% error-rate barrier in GP models using the MNIST8M dataset, showing along the way the scalability of our method at unprecedented scale for GP models (8 million observations) in classification problems. Overall, our approach represents a significant breakthrough in kernel methods and GP models, bridging the gap between deep learning approaches and kernel machines.},
	author = {Krauth, Karl and Bonilla, Edwin V. and Cutajar, Kurt and Filippone, Maurizio},
	year = {2016},
	note = {ZSCC: 0000028 
arXiv: 1610.05392},
	pages = {1--16},
	file = {AutoGP - Krauth et al - 2016.pdf:/home/theo/Zotero/storage/33VHIBR8/AutoGP - Krauth et al - 2016.pdf:application/pdf;AutoGP - Krauth et al - 2016.pdf:/home/theo/Zotero/storage/8GBCT9AA/AutoGP - Krauth et al - 2016.pdf:application/pdf},
}

@article{peyreComputationalOptimalTransport2019,
	title = {Computational optimal transport},
	volume = {11},
	issn = {19358245},
	doi = {10.1561/2200000073},
	abstract = {Optimal transport (OT) theory can be informally described using the words of the French mathematician Gaspard Monge (1746–1818): A worker with a shovel in hand has to move a large pile of sand lying on a construction site. The goal of the worker is to erect with all that sand a target pile with a prescribed shape (for example, that of a giant sand castle). Naturally, the worker wishes to minimize her total e ort, quantified for instance as the total distance or time spent carrying shovelfuls of sand. Mathematicians interested in OT cast that problem as that of comparing two probability distributions—two di erent piles of sand of the same volume. They consider all of the many possible ways to morph, transport or reshape the first pile into the second, and associate a “global” cost to every such transport, using the “local” consideration of how much it costs to move a grain of sand from one place to another. Mathematicians are interested in the properties of that least costly transport, as well as in its e cient computation. That smallest cost not only defines a distance between distributions, but it also entails a rich geometric structure on the space of probability distributions. That structure is canonical in the sense that it borrows key geometric properties of the underlying “ground” space on which these distributions are defined. For instance, when the underlying space is Euclidean, key concepts such as interpolation, barycenters, convexity or gradients of functions extend naturally to the space of distributions endowed with an OT geometry. OT has been (re)discovered in many settings and under different forms, giving it a rich history. While Monge’s seminal work was motivated by an engineering problem, Tolstoi in the 1920s and Hitchcock, Kantorovich and Koopmans in the 1940s established its significance to logistics and economics. Dantzig solved it numerically in 1949 within the framework of linear programming, giving OT a firm footing in optimization. OT was later revisited by analysts in the 1990s, notably Brenier, while also gaining fame in computer vision under the name of earth mover’s distances. Recent years have witnessed yet another revolution in the spread of OT, thanks to the emergence of approximate solvers that can scale to large problem dimensions. As a consequence, OT is being increasingly used to unlock various problems in imaging sciences (such as color or texture processing), graphics (for shape manipulation) or machine learning (for regression, classification and generative modeling). This paper reviews OT with a bias toward numerical methods, and covers the theoretical properties of OT that can guide the design of new algorithms.We focus in particular on the recent wave of efficient algorithms that have helped OT find relevance in data sciences. We give a prominent place to the many generalizations of OT that have been proposed in but a few years, and connect them with related approaches originating from statistical inference, kernel methods and information theory. All of the figures can be reproduced using code made available in a companion website1. This website hosts the book project Computational Optimal Transport. You will also find slides and computational resources.},
	number = {5-6},
	journal = {Foundations and Trends in Machine Learning},
	author = {Peyré, Gabriel and Cuturi, Marco},
	year = {2019},
	note = {ZSCC: 0000399 
arXiv: 1803.00567},
	pages = {1--257},
	file = {Computational optimal transport - Peyré_Cuturi - 2019.pdf:/home/theo/Zotero/storage/55BLVIVZ/Computational optimal transport - Peyré_Cuturi - 2019.pdf:application/pdf},
}

@article{hoffmanStochasticVariationalInference2012,
	title = {Stochastic {Variational} {Inference}},
	volume = {14},
	issn = {1532-4435},
	url = {http://arxiv.org/abs/1206.7051},
	doi = {citeulike-article-id:10852147},
	abstract = {We develop stochastic variational inference, a scalable algorithm for approximating posterior distributions. We develop this technique for a large class of probabilistic models and we demonstrate it with two probabilistic topic models, latent Dirichlet allocation and the hierarchical Dirichlet process topic model. Using stochastic variational inference, we analyze several large collections of documents: 300K articles from Nature, 1.8M articles from The New York Times, and 3.8M articles from Wikipedia. Stochastic inference can easily handle data sets of this size and outperforms traditional variational inference, which can only handle a smaller subset. (We also show that the Bayesian nonparametric topic model outperforms its parametric counterpart.) Stochastic variational inference lets us apply complex Bayesian models to massive data sets.},
	journal = {Journal of Machine Learning Research},
	author = {Hoffman, Matt and Blei, David M. and Wang, Chong and Paisley, John},
	year = {2012},
	pmid = {19926898},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1206.7051
ISBN: 1532-4435},
	pages = {1303--1347},
	file = {Stochastic Variational Inference - Hoffman et al - 2012.pdf:/home/theo/Zotero/storage/GNSVX88T/Stochastic Variational Inference - Hoffman et al - 2012.pdf:application/pdf},
}

@incollection{dongScalableLogDeterminants2017,
	title = {Scalable {Log} {Determinants} for {Gaussian} {Process} {Kernel} {Learning}},
	url = {http://papers.nips.cc/paper/7212-scalable-log-determinants-for-gaussian-process-kernel-learning.pdf},
	urldate = {2020-05-06},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 30},
	publisher = {Curran Associates, Inc.},
	author = {Dong, Kun and Eriksson, David and Nickisch, Hannes and Bindel, David and Wilson, Andrew G},
	editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	year = {2017},
	note = {ZSCC: NoCitationData[s1]},
	pages = {6327--6337},
	file = {NIPS Snapshot:/home/theo/Zotero/storage/7BYTYVGQ/7212-scalable-log-determinants-for-gaussian-process-kernel-learning.html:text/html;NIPS Full Text PDF:/home/theo/Zotero/storage/9ER9DP78/Dong et al. - 2017 - Scalable Log Determinants for Gaussian Process Ker.pdf:application/pdf},
}

@article{wilsonHumanKernel2015,
	title = {The {Human} {Kernel}},
	issn = {10495258},
	url = {http://arxiv.org/abs/1510.07389},
	abstract = {Bayesian nonparametric models, such as Gaussian processes, provide a compelling framework for automatic statistical modelling: these models have a high degree of flexibility, and automatically calibrated complexity. However, automating human expertise remains elusive; for example, Gaussian processes with standard kernels struggle on function extrapolation problems that are trivial for human learners. In this paper, we create function extrapolation problems and acquire human responses, and then design a kernel learning framework to reverse engineer the inductive biases of human learners across a set of behavioral experiments. We use the learned kernels to gain psychological insights and to extrapolate in human-like ways that go beyond traditional stationary and polynomial kernels. Finally, we investigate Occam's razor in human and Gaussian process based function learning.},
	author = {Wilson, Andrew Gordon and Dann, Christoph and Lucas, Christopher G. and Xing, Eric P.},
	year = {2015},
	note = {ZSCC: 0000038 
arXiv: 1510.07389},
	pages = {1--9},
	file = {PDF:/home/theo/Zotero/storage/UD2S4ZIY/Wilson et al. - 2015 - The Human Kernel(2).pdf:application/pdf},
}

@article{roweisUnifyingReviewLinear1999,
	title = {A unifying review of linear gaussian models},
	volume = {11},
	issn = {08997667},
	url = {http://www.mitpressjournals.org/doi/10.1162/089976699300016674},
	doi = {10.1162/089976699300016674},
	abstract = {Factor analysis, principal component analysis, mixtures of gaussian clusters, vector quantization, Kalman filter models, and hidden Markov models can all be unified as variations of unsupervised learning under a single basic generative model. This is achieved by collecting together disparate observations and derivations made by many previous authors and introducing a new way of linking discrete and continuous state models using a simple nonlinearity. Through the use of other nonlinearities, we show how independent component analysis is also a variation of the same basic generative model. We show that factor analysis and mixtures of gaussians can be implemented in autoencoder neural networks and learned using squared error plus the same regularization term. We introduce a new model for static data, known as sensible principal component analysis, as well as a novel concept of spatially adaptive observation noise. We also review some of the literature involving global and local mixtures of the basic models and provide pseudocode for inference and learning for all the basic models.},
	number = {2},
	journal = {Neural Computation},
	author = {Roweis, Sam and Ghahramani, Zoubin},
	year = {1999},
	pmid = {9950734},
	note = {ZSCC: 0001078 
arXiv: 1011.1669v3
ISBN: 0899766993000},
	pages = {305--345},
	file = {A unifying review of linear gaussian models - Roweis_Ghahramani - 1999.pdf:/home/theo/Zotero/storage/P8CIGI2Y/A unifying review of linear gaussian models - Roweis_Ghahramani - 1999.pdf:application/pdf},
}

@article{scholkopfNonlinearComponentAnalysis1998,
	title = {Nonlinear {Component} {Analysis} as a {Kernel} {Eigenvalue} {Problem}},
	volume = {10},
	issn = {08997667},
	doi = {10.1162/089976698300017467},
	abstract = {A new method for performing a nonlinear form of principal component analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in high-dimensional feature spaces, related to input space by some nonlinear map—for instance, the space of all possible five-pixel products in 16 × 16 images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition.},
	number = {5},
	journal = {Neural Computation},
	author = {Schölkopf, Bernhard and Smola, Alexander and Müller, Klaus Robert},
	year = {1998},
	pmid = {21939901},
	note = {ZSCC: 0008677 
ISBN: 0899-7667},
	pages = {1299--1319},
	file = {Nonlinear Component Analysis as a Kernel Eigenvalue Problem - Schölkopf et al - 1998.pdf:/home/theo/Zotero/storage/AL7ILCY7/Nonlinear Component Analysis as a Kernel Eigenvalue Problem - Schölkopf et al - 1998.pdf:},
}

@article{loukasHowCloseAre2017,
	title = {How close are the eigenvectors and eigenvalues of the sample and actual covariance matrices?},
	number = {1},
	author = {Loukas, Andreas},
	year = {2017},
	note = {ZSCC: 0000000 
arXiv: 1702.05443v1},
	pages = {1--13},
	file = {How close are the eigenvectors and eigenvalues of the sample and actual - Loukas - 2017.pdf:/home/theo/Zotero/storage/FWKAMTVE/How close are the eigenvectors and eigenvalues of the sample and actual - Loukas - 2017.pdf:application/pdf},
}

@article{klambauerSelfNormalizingNeuralNetworks2017,
	title = {Self-{Normalizing} {Neural} {Networks}},
	issn = {10495258},
	url = {http://arxiv.org/abs/1706.02515},
	doi = {1706.02515},
	abstract = {Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are "scaled exponential linear units" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance -- even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep. Implementations are available at: github.com/bioinf-jku/SNNs.},
	author = {Klambauer, Günter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},
	year = {2017},
	pmid = {197263},
	note = {ZSCC: 0000860 
arXiv: 1706.02515
ISBN: 978-3-89937-157-4},
	file = {Self-Normalizing Neural Networks - Klambauer et al - 2017.pdf:/home/theo/Zotero/storage/8GVAFX7L/Self-Normalizing Neural Networks - Klambauer et al - 2017.pdf:application/pdf},
}

@article{glickmanBasicBayesianMethods2007,
	title = {Basic {Bayesian} {Methods}},
	volume = {404},
	issn = {1064-3745},
	doi = {10.1007/978-1-59745-530-5_16},
	abstract = {In this chapter, we introduce the basics of Bayesian data analysis. The key ingredients to a Bayesian analysis are the likelihood function, which reflects information about the parameters contained in the data, and the prior distribution, which quantifies what is known about the parameters before observing data. The prior distribution and likelihood can be easily combined to from the posterior distribution, which represents total knowledge about the parameters after the data have been observed. Simple summaries of this distribution can be used to isolate quantities of interest and ultimately to draw substantive conclusions. We illustrate each of these steps of a typical Bayesian analysis using three biomedical examples and briefly discuss more advanced topics, including prediction, Monte Carlo computational methods, and multilevel models.},
	journal = {Methods in molecular biology (Clifton, N.J.)},
	author = {Glickman, Mark E. and Dyk, David A.},
	year = {2007},
	pmid = {18450057},
	note = {ZSCC: 0000087 
arXiv: 1011.1669v3
ISBN: 978-1-58829-531-6},
	keywords = {monte carlo simulation, posterior distribution, prior distribution, subjective},
	pages = {319--338},
	file = {Basic Bayesian Methods - Glickman_Dyk - 2007.pdf:/home/theo/Zotero/storage/QAUDWD9V/Basic Bayesian Methods - Glickman_Dyk - 2007.pdf:application/pdf},
}

@article{liuSteinVariationalGradient2016,
	title = {Stein {Variational} {Gradient} {Descent}: {A} {General} {Purpose} {Bayesian} {Inference} {Algorithm}},
	issn = {10495258},
	url = {http://arxiv.org/abs/1608.04471},
	abstract = {We propose a general purpose variational inference algorithm that forms a natural counterpart of gradient descent for optimization. Our method iteratively transports a set of particles to match the target distribution, by applying a form of functional gradient descent that minimizes the KL divergence. Empirical studies are performed on various real world models and datasets, on which our method is competitive with existing state-of-the-art methods. The derivation of our method is based on a new theoretical result that connects the derivative of KL divergence under smooth transforms with Stein's identity and a recently proposed kernelized Stein discrepancy, which is of independent interest.},
	author = {Liu, Qiang and Wang, Dilin},
	year = {2016},
	pmid = {18792489},
	note = {ZSCC: 0000270 
arXiv: 1608.04471},
	pages = {4--7},
	file = {Stein Variational Gradient Descent - Liu_Wang - 2016.pdf:/home/theo/Zotero/storage/IL7FN8XH/Stein Variational Gradient Descent - Liu_Wang - 2016.pdf:application/pdf},
}

@article{wikipediaLearnFortranMinutes2013,
	title = {Learn {Fortran} in {Y} minutes},
	volume = {95},
	author = {{Wikipedia}},
	year = {2013},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 0000000000000},
	pages = {1--13},
	file = {PDF:/home/theo/Zotero/storage/VIDI9CB7/Julia - Unknown - Learn Julia in Y minutes ()(2).pdf:application/pdf},
}

@article{chibBayesianAnalysisBinary1993,
	title = {Bayesian {Analysis} of {Binary} and {Polychotomous} {Response} {Data}},
	volume = {88},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2290350},
	number = {422},
	journal = {Journal of the American Statistical Association},
	author = {Chib, Siddhartha and Albert, James H},
	year = {1993},
	note = {ZSCC: 0003372 
Publisher: American Statistical Association},
	keywords = {binary probit, data augmentation, gibbs sampling, hierarchical bayes modeling, latent data, logit model, mul-, residual analysis, student-r link function, tinomial probit},
	pages = {669--679},
	file = {Bayesian Analysis of Binary and Polychotomous Response Data - Chib_Albert - 1993.pdf:/home/theo/Zotero/storage/EY7MHVD7/Bayesian Analysis of Binary and Polychotomous Response Data - Chib_Albert - 1993.pdf:application/pdf},
}

@article{lindermanDependentMultinomialModels2015,
	title = {Dependent {Multinomial} {Models} {Made} {Easy}: {Stick} {Breaking} with the {P}{\textbackslash}'olya-{Gamma} {Augmentation}},
	issn = {10495258},
	url = {http://arxiv.org/abs/1506.05843},
	doi = {10.1038/cdd.2016.14},
	abstract = {Many practical modeling problems involve discrete data that are best represented as draws from multinomial or categorical distributions. For example, nucleotides in a DNA sequence, children's names in a given state and year, and text documents are all commonly modeled with multinomial distributions. In all of these cases, we expect some form of dependency between the draws: the nucleotide at one position in the DNA strand may depend on the preceding nucleotides, children's names are highly correlated from year to year, and topics in text may be correlated and dynamic. These dependencies are not naturally captured by the typical Dirichlet-multinomial formulation. Here, we leverage a logistic stick-breaking representation and recent innovations in P{\textbackslash}'olya-gamma augmentation to reformulate the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods, enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead.},
	author = {Linderman, Scott W. and Johnson, Matthew J. and Adams, Ryan Prescott},
	year = {2015},
	pmid = {26891693},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1506.05843
ISBN: 1350-9047},
	file = {Dependent Multinomial Models Made Easy - Linderman et al - 2015.pdf:/home/theo/Zotero/storage/8UXAH6IM/Dependent Multinomial Models Made Easy - Linderman et al - 2015.pdf:application/pdf},
}

@article{bauerUnderstandingProbabilisticSparse2016,
	title = {Understanding {Probabilistic} {Sparse} {Gaussian} {Process} {Approximations}},
	issn = {10495258},
	url = {http://arxiv.org/abs/1606.04820},
	doi = {10.1016/S0037-0738(98)00088-8},
	abstract = {Good sparse approximations are essential for practical inference in Gaussian Processes as the computational cost of exact methods is prohibitive for large datasets. The Fully Independent Training Conditional (FITC) and the Variational Free Energy (VFE) approximations are two recent popular methods. Despite superficial similarities, these approximations have surprisingly different theoretical properties and behave differently in practice. We thoroughly investigate the two methods for regression both analytically and through illustrative examples, and draw conclusions to guide practical application.},
	author = {Bauer, Matthias and van der Wilk, Mark and Rasmussen, Carl Edward},
	year = {2016},
	note = {ZSCC: 0000102 
arXiv: 1606.04820
ISBN: 9780521549578},
	file = {Understanding Probabilistic Sparse Gaussian Process Approximations - Bauer et al - 2016.pdf:/home/theo/Zotero/storage/4F56444S/Understanding Probabilistic Sparse Gaussian Process Approximations - Bauer et al - 2016.pdf:application/pdf},
}

@article{chaiVariationalMultinomialLogit2012,
	title = {Variational {Multinomial} {Logit} {Gaussian} {Process}},
	volume = {98888},
	issn = {1532-4435},
	abstract = {Gaussian process prior with an appropriate likelihood function is a flexible non-parametric model for a variety of learning tasks. One important and standard task is multi-class classification, which is the categorization of an item into one of several fixed classes. A usual likelihood function for this is the multinomial logistic likelihood function. However, exact inference with this model has proved to be difficult because high-dimensional integrations are required. In this paper, we propose a variational approximation to this model, and we describe the optimization of the variational parameters. Experiments have shown our approximation to be tight. In addition, we provide data-independent bounds on the marginal likelihood of the model, one of which is shown to be much tighter than the existing variational mean-field bound in the experiments. We also derive a proper lower bound on the predictive likelihood that involves the Kullback-Leibler divergence between the approximating and the true posterior. We combine our approach with a recently proposed sparse approximation to give a variational sparse approximation to the Gaussian process multi-class model. We also derive criteria which can be used to select the inducing set, and we show the effectiveness of these criteria over random selection in an experiment.},
	journal = {J. Mach. Learn. Res.},
	author = {Chai, Kian Ming A.},
	year = {2012},
	note = {ZSCC: 0000033 
ISBN: 1532-4435},
	keywords = {gaussian process, multinomial logistic, probabilistic classification, proximation, sparse approximation, variational ap-},
	pages = {1745--1808},
	file = {PDF:/home/theo/Zotero/storage/VRNN6ZYW/Chai - 2012 - Variational Multinomial Logit Gaussian Process.pdf:},
}

@article{cucalaBayesianInferenceMixture2013,
	title = {Bayesian inference on a mixture model with spatial dependence},
	volume = {22},
	issn = {10618600},
	url = {http://www.tandfonline.com/doi/abs/10.1080/10618600.2013.805652},
	doi = {10.1080/10618600.2013.805652},
	abstract = {We introduce a new technique to select the number of components of a mixture model with spatial dependence. It consists in an estimation of the Integrated Completed Likelihood based on a Laplace's approximation and a new technique to deal with the normalizing constant intractability of the hidden Potts model. Our proposal is applied to a real satellite image.},
	number = {3},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Cucala, Lionel and Marin, Jean Michel},
	year = {2013},
	note = {ZSCC: 0000016},
	keywords = {Auxiliary Markov chain Monte Carlo schemes, Bayesian model choice, Hidden Gibbs random fields, Integrated completed likelihood},
	pages = {584--597},
	file = {Bayesian inference on a mixture model with spatial dependence - Cucala_Marin - 2013.pdf:/home/theo/Zotero/storage/GMMRNFG5/Bayesian inference on a mixture model with spatial dependence - Cucala_Marin - 2013.pdf:application/pdf},
}

@book{ottenChainStatistics2011,
	title = {Chain {Statistics}},
	isbn = {978-0-387-70872-0},
	author = {Otten, R. H. J. M. and van Ginneken, L. P. P. P.},
	year = {2011},
	doi = {10.1007/978-1-4613-1627-5_4},
	note = {ZSCC: NoCitationData[s0] },
	file = {Chain Statistics - Otten_van Ginneken - 2011.pdf:/home/theo/Zotero/storage/NVB4WUA2/Chain Statistics - Otten_van Ginneken - 2011.pdf:application/pdf},
}

@article{blekasMixtureModelBased2015,
	title = {Mixture model based image segmentation with spatial constraints},
	volume = {06-10-Sept},
	issn = {22195491},
	abstract = {© 2004 EUSIPCO. One of the many successful applications of Gaussian Mixture Models (GMMs) is in image segmentation, where spatially constrained mixture models have been used in conjuction with the Expectation-Maximization (EM) framework. In this paper, we propose a new methodology for the M-step of the EM algorithm that is based on a novel constrained optimization formulation. Numerical experiments using simulated and real images illustrate the superior performance of our methodology in terms of the attained maximum value of the objective function and segmentation accuracy compared to previous implementations of this approach.},
	number = {2},
	journal = {European Signal Processing Conference},
	author = {Blekas, K. and Likas, A. and Galatsanos, N. P. and Lagaris, I. E.},
	year = {2015},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 9783200001657},
	pages = {2119--2122},
	file = {PDF:/home/theo/Zotero/storage/W3XSKP8B/Blekas et al. - 2015 - Mixture model based image segmentation with spatial constraints(2).pdf:application/pdf},
}

@article{louizosStructuredEfficientVariational2016,
	title = {Structured and {Efficient} {Variational} {Deep} {Learning} with {Matrix} {Gaussian} {Posteriors}},
	volume = {48},
	url = {http://arxiv.org/abs/1603.04733},
	abstract = {We introduce a variational Bayesian neural network where the parameters are governed via a probability distribution on random matrices. Specifically, we employ a matrix variate Gaussian {\textbackslash}cite\{gupta1999matrix\} parameter posterior distribution where we explicitly model the covariance among the input and output dimensions of each layer. Furthermore, with approximate covariance matrices we can achieve a more efficient way to represent those correlations that is also cheaper than fully factorized parameter posteriors. We further show that with the "local reprarametrization trick" {\textbackslash}cite\{kingma2015variational\} on this posterior distribution we arrive at a Gaussian Process {\textbackslash}cite\{rasmussen2006gaussian\} interpretation of the hidden units in each layer and we, similarly with {\textbackslash}cite\{gal2015dropout\}, provide connections with deep Gaussian processes. We continue in taking advantage of this duality and incorporate "pseudo-data" {\textbackslash}cite\{snelson2005sparse\} in our model, which in turn allows for more efficient sampling while maintaining the properties of the original model. The validity of the proposed approach is verified through extensive experiments.},
	journal = {Icml},
	author = {Louizos, Christos and Welling, Max},
	year = {2016},
	note = {ZSCC: 0000099 
arXiv: 1603.04733
ISBN: 1603.04733},
	file = {Structured and Efficient Variational Deep Learning with Matrix Gaussian - Louizos_Welling - 2016.pdf:/home/theo/Zotero/storage/N2RNEU89/Structured and Efficient Variational Deep Learning with Matrix Gaussian - Louizos_Welling - 2016.pdf:application/pdf},
}

@article{cutajarPreconditioningKernelMatrices2016,
	title = {Preconditioning {Kernel} {Matrices}},
	url = {http://arxiv.org/abs/1602.06693},
	abstract = {The computational and storage complexity of kernel machines presents the primary barrier to their scaling to large, modern, datasets. A common way to tackle the scalability issue is to use the conjugate gradient algorithm, which relieves the constraints on both storage (the kernel matrix need not be stored) and computation (both stochastic gradients and parallelization can be used). Even so, conjugate gradient is not without its own issues: the conditioning of kernel matrices is often such that conjugate gradients will have poor convergence in practice. Preconditioning is a common approach to alleviating this issue. Here we propose preconditioned conjugate gradients for kernel machines, and develop a broad range of preconditioners particularly useful for kernel matrices. We describe a scalable approach to both solving kernel machines and learning their hyperparameters. We show this approach is exact in the limit of iterations and outperforms state-of-the-art approximations for a given computational budget.},
	journal = {Icml},
	author = {Cutajar, Kurt and Osborne, Michael A. and Cunningham, John P. and Filippone, Maurizio},
	year = {2016},
	note = {ZSCC: 0000033 
arXiv: 1602.06693
ISBN: 9781510829008},
	pages = {2529--2538},
	file = {Preconditioning Kernel Matrices - Cutajar et al - 2016.pdf:/home/theo/Zotero/storage/3Y4Z9YQA/Preconditioning Kernel Matrices - Cutajar et al - 2016.pdf:application/pdf},
}

@article{sanjay-gopalBayesianPixelClassification1998,
	title = {Bayesian pixel classification using spatially variant finite mixtures and the generalized {EM} algorithm},
	volume = {7},
	issn = {10577149},
	doi = {10.1109/83.701161},
	abstract = {A spatially variant finite mixture model is proposed for pixel labeling and image segmentation. For the case of spatially varying mixtures of Gaussian density functions with unknown means and variances, an expectation-maximization (EM) algorithm is derived for maximum likelihood estimation of the pixel labels and the parameters of the mixture densities, An a priori density function is formulated for the spatially variant mixture weights. A generalized EM algorithm for maximum a posteriori estimation of the pixel labels based upon these prior densities is derived. This algorithm incorporates a variation of gradient projection in the maximization step and the resulting algorithm takes the form of grouped coordinate ascent. Gaussian densities have been used for simplicity, but the algorithm can easily be modified to incorporate other appropriate models for the mixture model component densities. The accuracy of the algorithm is quantitatively evaluated through Monte Carlo simulation, and its performance is qualitatively assessed via experimental images from computerized tomography (CT) and magnetic resonance imaging (MRI)},
	number = {7},
	journal = {IEEE Transactions on Image Processing},
	author = {Sanjay-Gopal, S. and Hebert, Thomas J.},
	year = {1998},
	pmid = {18276317},
	note = {ZSCC: 0000268 },
	pages = {1014--1028},
	file = {Bayesian pixel classification using spatially variant finite mixtures and the - Sanjay-Gopal_Hebert - 1998.pdf:/home/theo/Zotero/storage/3MZG3UNM/Bayesian pixel classification using spatially variant finite mixtures and the - Sanjay-Gopal_Hebert - 1998.pdf:application/pdf},
}

@article{blekasSpatiallyConstrainedMixture2005,
	title = {A spatially constrained mixture model for image segmentation.},
	volume = {16},
	issn = {1045-9227},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/15787156},
	doi = {10.1109/TNN.2004.841773},
	abstract = {Gaussian mixture models (GMMs) constitute a well-known type of probabilistic neural networks. One of their many successful applications is in image segmentation, where spatially constrained mixture models have been trained using the expectation-maximization (EM) framework. In this letter, we elaborate on this method and propose a new methodology for the M-step of the EM algorithm that is based on a novel constrained optimization formulation. Numerical experiments using simulated images illustrate the superior performance of our method in terms of the attained maximum value of the objective function and segmentation accuracy compared to previous implementations of this approach.},
	number = {2},
	journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
	author = {Blekas, K and Likas, a and Galatsanos, N P and Lagaris, I E},
	year = {2005},
	pmid = {15787156},
	note = {ZSCC: 0000252 },
	keywords = {Neural Networks (Computer)},
	pages = {494--8},
	file = {A spatially constrained mixture model for image segmentation - Blekas et al - 2005.pdf:/home/theo/Zotero/storage/4AZD8GRT/A spatially constrained mixture model for image segmentation - Blekas et al - 2005.pdf:application/pdf},
}

@article{prunsterAreGibbsTypePriors2013,
	title = {Are {Gibbs}-{Type} {Priors} the {Most} {Natural} {Generalization} of the {Dirichlet} {Process}?},
	volume = {37},
	issn = {0162-8828},
	doi = {10.1109/tpami.2013.217},
	abstract = {Discrete random probability measures and the exchangeable random partitions they induce are key tools for addressing a variety of estimation and prediction problems in Bayesian inference. Here we focus on the family of Gibbs-type priors, a recent elegant generalization of the Dirichlet and the Pitman-Yor process priors. These priors share properties that are appealing both from a theoretical and an applied point of view: (i) they admit an intuitive predictive characterization justifying their use in terms of a precise assumption on the learning mechanism; (ii) they stand out in terms of mathematical tractability; (iii) they include several interesting special cases besides the Dirichlet and the Pitman-Yor processes. The goal of our paper is to provide a systematic and unified treatment of Gibbs-type priors and highlight their implications for Bayesian nonparametric inference. We deal with their distributional properties, the resulting estimators, frequentist asymptotic validation and the construction of time-dependent versions. Applications, mainly concerning mixture models and species sampling, serve to convey the main ideas. The intuition inherent to this class of priors and the neat results they lead to make one wonder whether it actually represents the most natural generalization of the Dirichlet process.},
	number = {2},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Prunster, Igor and Mena, Ramses H. and Lijoi, Antonio and Ruggiero, Matteo and Favaro, Stefano and De Blasi, Pierpaolo},
	year = {2013},
	pmid = {26353237},
	note = {ZSCC: 0000090 
arXiv: 1503.00163v1
ISBN: 0162-8828 VO - 37},
	keywords = {Nonparametric statistics, Stochastic processes},
	pages = {212--229},
	file = {Are Gibbs-Type Priors the Most Natural Generalization of the Dirichlet Process - Prunster et al - 2013.pdf:/home/theo/Zotero/storage/6IV6MIMW/Are Gibbs-Type Priors the Most Natural Generalization of the Dirichlet Process - Prunster et al - 2013.pdf:application/pdf},
}

@article{sculleyHiddenTechnicalDebt2016,
	title = {Hidden technical debt in machine learning systems},
	issn = {10495258},
	abstract = {Machine learning offers a fantastically powerful toolkit for building useful com- plex prediction systems quickly. This paper argues it is dangerous to think of these quick wins as coming for free. Using the software engineering framework of technical debt, we find it is common to incur massive ongoing maintenance costs in real-world ML systems. We explore several ML-specific risk factors to account for in system design. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, configuration issues, changes in the external world, and a variety of system-level anti-patterns.},
	journal = {Advances in Neural Information Processing Systems},
	author = {Sculley, D and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Dennison, Dan},
	year = {2016},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 0262017091, 9780262017091},
	pages = {1--9},
	file = {Hidden technical debt in machine learning systems - Sculley et al - 2016.pdf:/home/theo/Zotero/storage/6TGCEYT9/Hidden technical debt in machine learning systems - Sculley et al - 2016.pdf:},
}

@article{aitchisonBiometrikaTrustLogisticNormal2009,
	title = {Biometrika {Trust} {Logistic}-{Normal} {Distributions} : {Some} {Properties} and {Uses}},
	volume = {67},
	number = {2},
	author = {Aitchison, Author J and Shen, S M},
	year = {2009},
	note = {ZSCC: NoCitationData[s0]},
	pages = {261--272},
	file = {Biometrika Trust Logistic-Normal Distributions - Aitchison_Shen - 2009.pdf:/home/theo/Zotero/storage/KJ39KD8U/Biometrika Trust Logistic-Normal Distributions - Aitchison_Shen - 2009.pdf:application/pdf},
}

@article{halevyUnreasonableEffectivenessData2009,
	title = {The {Unreasonable} {Effectiveness} of {Data}},
	volume = {24},
	issn = {1541-1672},
	url = {http://ieeexplore.ieee.org/document/4804817/},
	doi = {10.1109/mis.2009.36},
	abstract = {At Brown University, there is excitement of having access to the Brown Corpus, containing one million English words. Since then, we have seen several notable corpora that are about 100 times larger, and in 2006, Google released a trillion-word corpus with frequency counts for all sequences up to five words long. In some ways this corpus is a step backwards from the Brown Corpus: it's taken from unfiltered Web pages and thus contains incomplete sentences, spelling errors, grammatical errors, and all sorts of other errors. It's not annotated with carefully hand-corrected part-of-speech tags. But the fact that it's a million times larger than the Brown Corpus outweighs these drawbacks. A trillion-word corpus - along with other Web-derived corpora of millions, billions, or trillions of links, videos, images, tables, and user interactions - captures even very rare aspects of human behavior. So, this corpus could serve as the basis of a complete model for certain tasks - if only we knew how to extract the model from the data.},
	number = {2},
	journal = {IEEE Intelligent Systems},
	author = {Halevy, Alon and Norvig, Peter and Pereira, Fernando},
	year = {2009},
	note = {ZSCC: 0001116 
arXiv: 1201.1832v1
ISBN: 1541-1672 VO - 24},
	pages = {8--12},
	file = {The Unreasonable Effectiveness of Data - Halevy et al - 2009.pdf:/home/theo/Zotero/storage/IPYNSBYT/The Unreasonable Effectiveness of Data - Halevy et al - 2009.pdf:application/pdf},
}

@article{zagroubaModelbasedGraphcutMethod2014,
	title = {Model-based graph-cut method for automatic flower segmentation with spatial constraints},
	volume = {32},
	issn = {02628856},
	doi = {10.1016/j.imavis.2014.08.012},
	abstract = {In this paper, we present an accelerated system for segmenting flower images based on graph-cut technique which formulates the segmentation problem as an energy function minimization. The contribution of this paper consists to propose an improvement of the classical used energy function, which is composed of a dataconsistent termand a boundary term. For this, we integrate an additional data-consistent termbased on the spatial prior and we add gradient information in the boundary term. Then, we propose an automated coarse-to-fine segmentation method composed mainly of two levels: coarse segmentation and fine segmentation. First, the coarse segmentation level is based on minimizing the proposed energy function. Then, the fine segmentation is done by optimizing the energy function through the standard graph-cut technique. Experiments were performed on a subset of Oxford flower database and the obtained results are compared to the reimplemented method of Nilsback et al. [1]. The evaluation shows that our method consumes less CPU time and it has a satisfactory accuracy compared with the mentioned method above [1].},
	number = {12},
	journal = {Image and Vision Computing},
	author = {Zagrouba, Ezzeddine and Ben Gamra, Siwar and Najjar, Asma},
	year = {2014},
	note = {ZSCC: 0000013},
	keywords = {Automatic flower image segmentation, Graph-cut, Spatial prior},
	pages = {1007--1020},
}

@article{nguyenRobustStudentSt2012,
	title = {Robust student's-t mixture model with spatial constraints and its application in medical image segmentation},
	volume = {31},
	issn = {02780062},
	doi = {10.1109/TMI.2011.2165342},
	abstract = {Finite mixture model based on the Student's-t distribution, which is heavily tailed and more robust than Gaussian, has recently received great attention for image segmentation. A new finite Student's-t mixture model (SMM) is proposed in this paper. Existing models do not explicitly incorporate the spatial relationships between pixels. First, our model exploits Dirichlet distribution and Dirichlet law to incorporate the local spatial constrains in an image. Secondly, we directly deal with the Student's-t distribution in order to estimate the model parameters, whereas, the Student's-t distributions in previous models are represented as an infinite mixture of scaled Gaussians that lead to an increase in complexity. Finally, instead of using expectation maximization (EM) algorithm, the proposed method adopts the gradient method to minimize the higher bound on the data negative log-likelihood and to optimize the parameters. The proposed model is successfully compared to the state-of-the-art finite mixture models. Numerical experiments are presented where the proposed model is tested on various simulated and real medical images.},
	number = {1},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Nguyen, Thanh Minh and Wu, Q. M.Jonathan},
	year = {2012},
	pmid = {21859612},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 0278-0062},
	keywords = {Dirichlet distribution, Dirichlet law, finite student's-t mixture model, medical image segmentation, spatial constraints},
	pages = {103--116},
	file = {Robust student's-t mixture model with spatial constraints and its application - Nguyen_Wu - 2012.pdf:/home/theo/Zotero/storage/NHMTXEZ8/Robust student's-t mixture model with spatial constraints and its application - Nguyen_Wu - 2012.pdf:application/pdf},
}

@article{zeilerADADELTAAdaptiveLearning2012,
	title = {{ADADELTA}: {An} {Adaptive} {Learning} {Rate} {Method}},
	issn = {09252312},
	url = {http://arxiv.org/abs/1212.5701},
	doi = {http://doi.acm.org.ezproxy.lib.ucf.edu/10.1145/1830483.1830503},
	abstract = {We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.},
	journal = {arXiv},
	author = {Zeiler, Matthew D.},
	year = {2012},
	note = {ZSCC: 0003988 
arXiv: 1212.5701
ISBN: 1212.5701},
	pages = {6},
	file = {PDF:/home/theo/Zotero/storage/VXDRCCRA/Zeiler - 2012 - ADADELTA An Adaptive Learning Rate Method(2).pdf:application/pdf},
}

@article{bleiCorrectionCorrelatedTopic2007,
	title = {Correction: {A} correlated topic model of {Science}},
	volume = {1},
	issn = {1932-6157},
	url = {http://projecteuclid.org/euclid.aoas/1183143727},
	doi = {10.1214/07-aoas136},
	abstract = {Correction to Annals of Applied Statistics 1 (2007) 17--35 [doi:10.1214/07-AOAS114]},
	number = {2},
	journal = {The Annals of Applied Statistics},
	author = {Blei, David M. and Lafferty, John D.},
	year = {2007},
	pmid = {9013932},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 0712.1486
ISBN: 1595933832},
	pages = {634--634},
	file = {Correction - Blei_Lafferty - 2007.pdf:/home/theo/Zotero/storage/KX835IHD/Correction - Blei_Lafferty - 2007.pdf:application/pdf},
}

@article{haoBayesianDeepLearning2016,
	title = {Towards {Bayesian} {Deep} {Learning}: {A} {Framework} and {Some} {Existing} {Methods}},
	volume = {28},
	issn = {10414347},
	doi = {10.1109/TKDE.2016.2606428},
	abstract = {While perception tasks such as visual object recognition and text understanding play an important role in human intelligence, the subsequent tasks that involve inference, reasoning and planning require an even higher level of intelligence. The past few years have seen major advances in many perception tasks using deep learning models. For higher-level inference, however, probabilistic graphical models with their Bayesian nature are still more powerful and flexible. To achieve integrated intelligence that involves both perception and inference, it is naturally desirable to tightly integrate deep learning and Bayesian models within a principled probabilistic framework, which we call Bayesian deep learning. In this unified framework, the perception of text or images using deep learning can boost the performance of higher-level inference and in return, the feedback from the inference process is able to enhance the perception of text or images. This paper proposes a general framework for Bayesian deep learning and reviews its recent applications on recommender systems, topic models, and control. In this paper, we also discuss the relationship and differences between Bayesian deep learning and other related topics like Bayesian treatment of neural networks.},
	number = {12},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Hao, Wang and Yeung, Dit Yan},
	year = {2016},
	pmid = {23064223},
	note = {ZSCC: 0000069 
arXiv: 1608.06884
ISBN: 1664-1078},
	keywords = {machine learning, Artificial intelligence, Bayesian networks, data mining, deep learning, neural networks},
	pages = {3395--3408},
	file = {Towards Bayesian Deep Learning - Hao_Yeung - 2016.pdf:/home/theo/Zotero/storage/SZIPE3J6/Towards Bayesian Deep Learning - Hao_Yeung - 2016.pdf:application/pdf},
}

@article{filipponePseudomarginalBayesianInference2014,
	title = {Pseudo-marginal {Bayesian} inference for {Gaussian} processes},
	volume = {36},
	issn = {01628828},
	doi = {10.1109/TPAMI.2014.2316530},
	abstract = {The main challenges that arise when adopting Gaussian Process priors in probabilistic modeling are how to carry out exact Bayesian inference and how to account for uncertainty on model parameters when making model-based predictions on out-of-sample data. Using probit regression as an illustrative working example, this paper presents a general and effective methodology based on the pseudo-marginal approach to Markov chain Monte Carlo that efficiently addresses both of these issues. The results presented in this paper show improvements over existing sampling methods to simulate from the posterior distribution over the parameters defining the covariance function of the Gaussian Process prior. This is particularly important as it offers a powerful tool to carry out full Bayesian inference of Gaussian Process based hierarchic statistical models in general. The results also demonstrate that Monte Carlo based integration of all model parameters is actually feasible in this class of models providing a superior quantification of uncertainty in predictions. Extensive comparisons with respect to state-of-the-art probabilistic classifiers confirm this assertion.},
	number = {11},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Filippone, Maurizio and Girolami, Mark},
	year = {2014},
	note = {ZSCC: 0000053 
arXiv: 1310.0740v2
ISBN: 0162-8828 VO  - 36},
	keywords = {approximate Bayesian inference, Gaussian processes, Hierarchic Bayesian models, Kernel methods, Markov chain Monte Carlo, pseudo-marginal Monte Carlo},
	pages = {2214--2226},
}

@article{zhangUnderstandingDeepLearning2016,
	title = {Understanding deep learning requires rethinking generalization},
	issn = {10414347},
	url = {http://arxiv.org/abs/1611.03530},
	doi = {10.1109/TKDE.2015.2507132},
	abstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.},
	author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	year = {2016},
	pmid = {88045},
	note = {ZSCC: 0001604 
arXiv: 1611.03530
ISBN: 1506.02142},
	file = {Understanding deep learning requires rethinking generalization - Zhang et al - 2016.pdf:/home/theo/Zotero/storage/5R8FWDJA/Understanding deep learning requires rethinking generalization - Zhang et al - 2016.pdf:application/pdf},
}

@article{liMaxmarginDeepGenerative2015,
	title = {Max-margin {Deep} {Generative} {Models}},
	issn = {10495258},
	url = {http://arxiv.org/abs/1504.06787},
	abstract = {Deep generative models (DGMs) are effective on learning multilayered representations of complex data and performing inference of input data by exploring the generative ability. However, little work has been done on examining or empowering the discriminative ability of DGMs on making accurate predictions. This paper presents max-margin deep generative models (mmDGMs), which explore the strongly discriminative principle of max-margin learning to improve the discriminative power of DGMs, while retaining the generative capability. We develop an efficient doubly stochastic subgradient algorithm for the piecewise linear objective. Empirical results on MNIST and SVHN datasets demonstrate that (1) max-margin learning can significantly improve the prediction performance of DGMs and meanwhile retain the generative ability; and (2) mmDGMs are competitive to the state-of-the-art fully discriminative networks by employing deep convolutional neural networks (CNNs) as both recognition and generative models.},
	journal = {Deep Learning},
	author = {Li, Chongxuan and Zhu, Jun and Shi, Tianlin and Zhang, Bo},
	year = {2015},
	note = {ZSCC: 0000028 
arXiv: 1504.06787},
	pages = {658--729},
	file = {PDF:/home/theo/Zotero/storage/WRL775JU/Li et al. - 2015 - Max-margin Deep Generative Models(2).pdf:application/pdf},
}

@article{liDeepReinforcementLearning2017,
	title = {Deep {Reinforcement} {Learning}: {An} {Overview}},
	issn = {1701.07274},
	url = {http://arxiv.org/abs/1701.07274},
	doi = {10.1007/978-3-319-56991-8_32},
	abstract = {We give an overview of recent exciting achievements of deep reinforcement learning (RL). We discuss six core elements, six important mechanisms, and twelve applications. We start with background of machine learning, deep learning and reinforcement learning. Next we discuss core RL elements, including value function, in particular, Deep Q-Network (DQN), policy, reward, model, planning, and exploration. After that, we discuss important mechanisms for RL, including attention and memory, unsupervised learning, transfer learning, multi-agent RL, hierarchical RL, and learning to learn. Then we discuss various applications of RL, including games, in particular, AlphaGo, robotics, natural language processing, including dialogue systems, machine translation, and text generation, computer vision, neural architecture design, business management, finance, healthcare, Industry 4.0, smart grid, intelligent transportation systems, and computer systems. We mention topics not reviewed yet, and list a collection of RL resources. After presenting a brief summary, we close with discussions. Please see Deep Reinforcement Learning, arXiv:1810.06339, for a significant update.},
	author = {Li, Yuxi},
	year = {2017},
	pmid = {15040217},
	note = {ZSCC: 0000380 
arXiv: 1701.07274
ISBN: 9781509011216},
	pages = {1--30},
	file = {PDF:/home/theo/Zotero/storage/ZEV6SI83/Li - 2017 - Deep Reinforcement Learning An Overview(2).pdf:application/pdf},
}

@article{lenkLogisticNormalDistribution1988,
	title = {The logistic normal distribution for bayesian, nonparametric, predictive densities},
	volume = {83},
	issn = {1537274X},
	url = {http://www.jstor.org/stable/2288870},
	doi = {10.1080/01621459.1988.10478625},
	abstract = {This article models the common density of an exchangeable sequence of observations by a generalization of the process derived from a logistic transform of a Gaussian process. The support of the logistic normal includes all distributions that are absolutely continuous with respect to the dominating measure of the observations. The logistic-normal family is closed in the prior to posterior Bayes analysis, with the observations entering the posterior distribution through the covariance function of the Gaussian process. The covariance of the Gaussian process plays the role of a smoothing kernel. Three features of the model provide a flexible structure for computing the predictive density: (a) The mean of the Gaussian process corresponds to the prior mean of the random density. (b) The prior variance of the Gaussian process controls the influence of the data in the posterior process. As the variance increases, the predictive density has greater fidelity to the data. (c) The prior covariance of the Gaussian process controls the smoothness of its sample paths and the amount of pooling of the sample information. For iid observations the empirical distribution function (edf) is a sufficient statistic for all inference. Since the human eye finds it difficult to distinguish important features of distribution functions, their densities often are plotted instead. Unfortunately, the edf does not possess a density function with respect to Lebesgue measure; consequently, many techniques have been proposed to smooth the edf so that its modification does possess a proper density. From the subjective, Bayesian perspective, the data are iid given a common but unspecified density. Beliefs about the unknown density are modeled through probability statements. When the density has a known functional form, the prior distribution concerns the density's parameters, which describe important, unknown features of the density. In this article the density is not constrained to a functional form, so it becomes the parameter of interest. Its posterior distribution becomes the mechanism for smoothing the edf so that the density estimator (the posterior mean) evaluated at a point can use nearby data.},
	number = {402},
	journal = {Journal of the American Statistical Association},
	author = {Lenk, Peter J.},
	year = {1988},
	note = {ZSCC: 0000123},
	keywords = {Lognormal distribution, Nonparametric density estimation, Smoothing},
	pages = {509--516},
	file = {PDF:/home/theo/Zotero/storage/XV434YHR/Lenk - 1988 - The logistic normal distribution for bayesian, nonparametric, predictive densities(2).pdf:application/pdf},
}

@article{chekanovProbabilityStatistics2016,
	title = {Probability and statistics},
	issn = {21978441},
	url = {papers2://publication/uuid/0D568B35-CF6C-4FAF-B994-9404C1824222},
	doi = {10.1007/978-3-319-28531-3_10},
	abstract = {The definition of the term “probability” is almost as illusive as that of the term “electricity.” Much as the average person knows that the effect of an electric current is to produce certain phenomena with which he is familiar, so he understands in a general manner what is implied by the words “the probability that an event will take place.” The term is employed colloquially in many instances in which the quantitative idea is missing. “ Kain is probable today”; “He will probably be late”; and so on. Frequently, however, some measure of probability is implicit. For example, if the odds against a specified horse are quoted as being longer than the odds against another horse, it is understood that the chances in favour of the second horse are greater than those in favour of the first. It is to be supposed that it is more probable that the second horse will win than will the first, and a certain amount of arithmetical work has been necessary in order to obtain the figures for the odds.},
	number = {9783319285290},
	journal = {Advanced Information and Knowledge Processing},
	author = {Chekanov, Sergei V.},
	year = {2016},
	pmid = {16072501},
	note = {ZSCC: 0000000 
arXiv: 1011.1669v3
ISBN: 9780321500465},
	pages = {351--397},
	file = {Probability and statistics - Chekanov - 2016.pdf:/home/theo/Zotero/storage/N7BGMWCZ/Probability and statistics - Chekanov - 2016.pdf:application/pdf},
}

@article{perkinsFastParallelSVM2015,
	title = {Fast {Parallel} {SVM} using {Data} {Augmentation}},
	url = {http://arxiv.org/abs/1512.07716},
	abstract = {As one of the most popular classifiers, linear SVMs still have challenges in dealing with very large-scale problems, even though linear or sub-linear algorithms have been developed recently on single machines. Parallel computing methods have been developed for learning large-scale SVMs. However, existing methods rely on solving local sub-optimization problems. In this paper, we develop a novel parallel algorithm for learning large-scale linear SVM. Our approach is based on a data augmentation equivalent formulation, which casts the problem of learning SVM as a Bayesian inference problem, for which we can develop very efficient parallel sampling methods. We provide empirical results for this parallel sampling SVM, and provide extensions for SVR, non-linear kernels, and provide a parallel implementation of the Crammer and Singer model. This approach is very promising in its own right, and further is a very useful technique to parallelize a broader family of general maximum-margin models.},
	journal = {arXiv preprint},
	author = {Perkins, Hugh and Xu, Minjie and Zhu, Jun and Zhang, Bo},
	year = {2015},
	note = {ZSCC: 0000003 
arXiv: 1512.07716},
	pages = {9},
	file = {Fast Parallel SVM using Data Augmentation - Perkins et al - 2015.pdf:/home/theo/Zotero/storage/7I2M4STW/Fast Parallel SVM using Data Augmentation - Perkins et al - 2015.pdf:application/pdf},
}

@article{kamReconsideringEffectsEducation2008,
	title = {Reconsidering the effects of education on political participation},
	volume = {70},
	issn = {00223816},
	url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Gibbs+Sampling+for+Logistic+Normal+Topic+Models+with+Graph-Based+Priors#0},
	doi = {10.1017/S0022381608080651},
	abstract = {The consensus in the empirical literature on political participation is that education positively correlates with political participation. Theoretical explanations posit that education confers participation-enhancing benefits that in and of themselves cause political activity. As most of the variation in educational attainment arises between high school completion and decisions to enter postsecondary institutions, we focus our inquiry on estimating the effect of higher education on political participation. Our primary purpose is to test the conventional claim that higher education causes political participation. We utilize propensity-score matching to address the nonrandom assignment process that characterizes the acquisition of higher education. After the propensity-score matching process takes into account preadult experiences and influences in place during the senior year of high school, the effects of higher education per se on participation disappear. Our results thus call for a reconsideration of how scholars understand the positive empirical relationship between higher education and participation: that higher education is a proxy for preadult experiences and influences, not a cause of political participation.},
	number = {3},
	journal = {Journal of Politics},
	author = {Kam, Cindy D. and Palmer, Carl L.},
	year = {2008},
	note = {ZSCC: 0000410},
	pages = {612--631},
	file = {Reconsidering the effects of education on political participation - Kam_Palmer - 2008.pdf:/home/theo/Zotero/storage/2T45XXLW/Reconsidering the effects of education on political participation - Kam_Palmer - 2008.pdf:application/pdf},
}

@article{kshirsagarLearningTaskClusters2017,
	title = {Learning {Task} {Clusters} via {Sparsity} {Grouped} {Multitask} {Learning}},
	volume = {10535 LNAI},
	issn = {16113349},
	url = {http://arxiv.org/abs/1705.04886%0Ahttps://arxiv.org/abs/1705.04886},
	doi = {10.1007/978-3-319-71246-8_41},
	abstract = {Sparse mapping has been a key methodology in many high-dimensional scientific problems. When multiple tasks share the set of relevant features, learning them jointly in a group drastically improves the quality of relevant feature selection. However, in practice this technique is used limitedly since such grouping information is usually hidden. In this paper, our goal is to recover the group structure on the sparsity patterns and leverage that information in the sparse learning. Toward this, we formulate a joint optimization problem in the task parameter and the group membership, by constructing an appropriate regularizer to encourage sparse learning as well as correct recovery of task groups. We further demonstrate that our proposed method recovers groups and the sparsity patterns in the task parameters accurately by extensive experiments.},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Kshirsagar, Meghana and Yang, Eunho and Lozano, Aurélie C.},
	year = {2017},
	note = {ZSCC: 0000002 
arXiv: 1705.04886
ISBN: 9783319712451},
	pages = {673--689},
	file = {Learning Task Clusters via Sparsity Grouped Multitask Learning - Kshirsagar et al - 2017.pdf:/home/theo/Zotero/storage/447UFYJX/Learning Task Clusters via Sparsity Grouped Multitask Learning - Kshirsagar et al - 2017.pdf:application/pdf},
}

@article{Chang2013,
	title = {Libsvm},
	volume = {2},
	issn = {21576904},
	doi = {10.1145/1961189.1961199},
	abstract = {LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification},
	number = {3},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	author = {Chang, Chih-Chung and Lin, Chih-Jen},
	year = {2012},
	pmid = {371},
	note = {ZSCC: 0000062 
arXiv: 0-387-31073-8
ISBN: 2157-6904},
	keywords = {classification, libsvm, optimization, regression, support vector ma-},
	pages = {1--27},
	file = {Libsvm - Chang_Lin - 2012.pdf:/home/theo/Zotero/storage/HFN7RR3H/Libsvm - Chang_Lin - 2012.pdf:application/pdf},
}

@article{buiTreestructuredGaussianProcess2014,
	title = {Tree-structured {Gaussian} {Process} {Approximations}},
	issn = {10495258},
	abstract = {Gaussian process regression can be accelerated by constructing a small pseudodataset to summarize the observed data. This idea sits at the heart of many approximation schemes, but such an approach requires the number of pseudo-datapoints to be scaled with the range of the input space if the accuracy of the approximation is to be maintained. This presents problems in time-series settings or in spatial datasets where large numbers of pseudo-datapoints are required since computation typically scales quadratically with the pseudo-dataset size. In this paper we devise an approximation whose complexity grows linearly with the number of pseudo-datapoints. This is achieved by imposing a tree or chain structure on the pseudo-datapoints and calibrating the approximation using a Kullback-Leibler (KL) minimization. Inference and learning can then be performed efficiently using the Gaussian belief propagation algorithm. We demonstrate the validity of our approach on a set of challenging regression tasks including missing data imputation for audio and spatial datasets. We trace out the speed-accuracy trade-off for the new method and show that the frontier dominates those obtained from a large number of existing approximation techniques.},
	journal = {Nips},
	author = {Bui, Thang and Turner, Richard},
	year = {2014},
	note = {ZSCC: 0000029},
	pages = {1--9},
}

@inproceedings{beckLearningStructuralKernels2015,
	title = {Learning {Structural} {Kernels} for {Natural} {Language} {Processing}},
	volume = {3},
	url = {http://arxiv.org/abs/1508.02131},
	abstract = {Structural kernels are a flexible learning paradigm that has been widely used in Natural Language Processing. However, the problem of model selection in kernel-based methods is usually overlooked. Previous approaches mostly rely on setting default values for kernel hyperparameters or using grid search, which is slow and coarse-grained. In contrast, Bayesian methods allow efficient model selection by maximizing the evidence on the training data through gradient-based methods. In this paper we show how to perform this in the context of structural kernels by using Gaussian Processes. Experimental results on tree kernels show that this procedure results in better prediction performance compared to hyperparameter optimization via grid search. The framework proposed in this paper can be adapted to other structures besides trees, e.g., strings and graphs, thereby extending the utility of kernel-based methods.},
	booktitle = {Transactions of the {Association} for {Computational} {Linguistics} (to appear)},
	author = {Beck, Daniel and Cohn, Trevor and Hardmeier, Christian and Specia, Lucia},
	year = {2015},
	note = {ZSCC: 0000014 
arXiv: 1508.02131},
	pages = {461--473},
	file = {Learning Structural Kernels for Natural Language Processing - Beck et al - 2015.pdf:/home/theo/Zotero/storage/IQ92ES9Z/Learning Structural Kernels for Natural Language Processing - Beck et al - 2015.pdf:application/pdf},
}

@misc{amiziApprentissageMachineTheorie,
	title = {Apprentissage machine \_ {De} la théorie à la pratique - {Concepts} fondamentaux en {Machine} {Learning} {Ed}.pdf},
	author = {Amizi, Massih-Reza},
	note = {ZSCC: NoCitationData[s0]},
	file = {Apprentissage machine _ De la théorie à la pratique - Concepts fondamentaux en - Amizi -.pdf:/home/theo/Zotero/storage/IA4LJBTU/Apprentissage machine _ De la théorie à la pratique - Concepts fondamentaux en - Amizi -.pdf:application/pdf;Apprentissage machine _ De la théorie à la pratique - Concepts fondamentaux en - Amizi -.pdf:/home/theo/Zotero/storage/CRKBWA3V/Apprentissage machine _ De la théorie à la pratique - Concepts fondamentaux en - Amizi -.pdf:application/pdf},
}

@article{gravesPracticalVariationalInference2012,
	title = {Practical {Variational} {Inference} for {Neural} {Networks}},
	issn = {09638687},
	doi = {10.1016/j.jsis.2013.03.002},
	abstract = {Variational methods have been previously explored as a tractable approximation to Bayesian inference for neural networks. However the approaches proposed so far have only been applicable to a few simple network architectures. This paper introduces an easy-to-implement stochastic variational method (or equivalently, minimum description length loss function) that can be applied to most neural networks. Along the way it revisits several common regularisers from a variational perspective. It also provides a simple pruning heuristic that can both drastically reduce the number of network weights and lead to improved generalisation. Experimental results are provided for a hierarchical multidimensional recurrent neural network applied to the TIMIT speech corpus.},
	journal = {Nips-2011},
	author = {Graves, Alex},
	year = {2012},
	pmid = {25218024},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1011.1669v3
ISBN: 9781618395993},
	pages = {1--9},
	file = {Practical Variational Inference for Neural Networks - Graves - 2012.pdf:/home/theo/Zotero/storage/LYH4ZHNJ/Practical Variational Inference for Neural Networks - Graves - 2012.pdf:application/pdf;Practical Variational Inference for Neural Networks - Graves - 2012.pdf:/home/theo/Zotero/storage/HBSDUIG3/Practical Variational Inference for Neural Networks - Graves - 2012.pdf:application/pdf},
}

@article{galLatentGaussianProcesses2015,
	title = {Latent {Gaussian} {Processes} for {Distribution} {Estimation} of {Multivariate} {Categorical} {Data}},
	url = {http://arxiv.org/abs/1503.02182},
	abstract = {Multivariate categorical data occur in many applications of machine learning. One of the main difficulties with these vectors of categorical variables is sparsity. The number of possible observations grows exponentially with vector length, but dataset diversity might be poor in comparison. Recent models have gained significant improvement in supervised tasks with this data. These models embed observations in a continuous space to capture similarities between them. Building on these ideas we propose a Bayesian model for the unsupervised task of distribution estimation of multivariate categorical data. We model vectors of categorical variables as generated from a non-linear transformation of a continuous latent space. Non-linearity captures multi-modality in the distribution. The continuous representation addresses sparsity. Our model ties together many existing models, linking the linear categorical latent Gaussian model, the Gaussian process latent variable model, and Gaussian process classification. We derive inference for our model based on recent developments in sampling based variational inference. We show empirically that the model outperforms its linear and discrete counterparts in imputation tasks of sparse data.},
	author = {Gal, Yarin and Chen, Yutian and Ghahramani, Zoubin},
	year = {2015},
	note = {ZSCC: 0000023 
arXiv: 1503.02182
ISBN: 9781510810587},
	file = {Latent Gaussian Processes for Distribution Estimation of Multivariate - Gal et al - 2015.pdf:/home/theo/Zotero/storage/S7KRJ2XM/Latent Gaussian Processes for Distribution Estimation of Multivariate - Gal et al - 2015.pdf:application/pdf},
}

@inproceedings{zhuScalableInferenceMaxmargin2013,
	title = {Scalable inference in max-margin topic models},
	isbn = {978-1-4503-2174-7},
	url = {http://dl.acm.org/citation.cfm?doid=2487575.2487658},
	doi = {10.1145/2487575.2487658},
	abstract = {Topic models have played a pivotal role in analyzing large collections of complex data. Besides discovering latent se-mantics, supervised topic models (STMs) can make predic-tions on unseen test data. By marrying with advanced learn-ing techniques, the predictive strengths of STMs have been dramatically enhanced, such as max-margin supervised topic models, state-of-the-art methods that integrate max-margin learning with topic models. Though powerful, max-margin STMs have a hard non-smooth learning problem. Existing algorithms rely on solving multiple latent SVM subproblems in an EM-type procedure, which can be too slow to be ap-plicable to large-scale categorization tasks. In this paper, we present a highly scalable approach to building max-margin supervised topic models. Our approach builds on three key innovations: 1) a new formulation of Gibbs max-margin supervised topic models for both multi-class and multi-label classification; 2) a simple " augment-and-collapse " Gibbs sampling algorithm without making re-stricting assumptions on the posterior distributions; 3) an efficient parallel implementation that can easily tackle data sets with hundreds of categories and millions of documents. Furthermore, our algorithm does not need to solve SVM subproblems. Though performing the two tasks of topic dis-covery and learning predictive models jointly, which signifi-cantly improves the classification performance, our methods have comparable scalability as the state-of-the-art parallel algorithms for the standard LDA topic models which per-form the single task of topic discovery only. Finally, an open-source implementation is also provided 1 .},
	booktitle = {Proceedings of the 19th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining - {KDD} '13},
	author = {Zhu, Jun and Zheng, Xun and Zhou, Li and Zhang, Bo},
	year = {2013},
	note = {ZSCC: 0000017 
arXiv: 1205.0310
ISSN: 10495258},
	pages = {964},
	file = {Scalable inference in max-margin topic models - Zhu et al - 2013.pdf:/home/theo/Zotero/storage/6ANUPAZ5/Scalable inference in max-margin topic models - Zhu et al - 2013.pdf:application/pdf},
}

@article{Baldi2014,
	title = {Searching for exotic particles in high-energy physics with deep learning},
	volume = {5},
	issn = {20411723},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/24986233},
	doi = {10.1038/ncomms5308},
	abstract = {Collisions at high-energy particle colliders are a traditionally fruitful source of exotic particle discoveries. Finding these rare particles requires solving difficult signal-versus-background classification problems, hence machine learning approaches are often used. Standard approaches have relied on `shallow' machine learning models that have a limited capacity to learn complex non-linear functions of the inputs, and rely on a pain-staking search through manually constructed non-linear features. Progress on this problem has slowed, as a variety of techniques have shown equivalent performance. Recent advances in the field of deep learning make it possible to learn more complex functions and better discriminate between signal and background classes. Using benchmark datasets, we show that deep learning methods need no manually constructed inputs and yet improve the classification metric by as much as 8{\textbackslash}\% over the best current approaches. This demonstrates that deep learning approaches can improve the power of collider searches for exotic particles.},
	journal = {Nature Communications},
	author = {Baldi, P. and Sadowski, P. and Whiteson, D.},
	year = {2014},
	pmid = {24986233},
	note = {ZSCC: 0000676 
arXiv: 1402.4735
ISBN: 2041-1723 (Electronic){\textbackslash}r2041-1723 (Linking)},
	pages = {4308},
	file = {Searching for exotic particles in high-energy physics with deep learning - Baldi et al - 2014.pdf:/home/theo/Zotero/storage/Q7PZHTJF/Searching for exotic particles in high-energy physics with deep learning - Baldi et al - 2014.pdf:application/pdf},
}

@article{pascanuRevisitingNaturalGradient2013,
	title = {Revisiting {Natural} {Gradient} for {Deep} {Networks}},
	issn = {0169-6149},
	url = {http://arxiv.org/abs/1301.3584},
	abstract = {We evaluate natural gradient, an algorithm originally proposed in Amari (1997), for learning deep models. The contributions of this paper are as follows. We show the connection between natural gradient and three other recently proposed methods for training deep models: Hessian-Free (Martens, 2010), Krylov Subspace Descent (Vinyals and Povey, 2012) and TONGA (Le Roux et al., 2008). We describe how one can use unlabeled data to improve the generalization error obtained by natural gradient and empirically evaluate the robustness of the algorithm to the ordering of the training set compared to stochastic gradient descent. Finally we extend natural gradient to incorporate second order information alongside the manifold information and provide a benchmark of the new algorithm using a truncated Newton approach for inverting the metric matrix instead of using a diagonal approximation of it.},
	author = {Pascanu, Razvan and Bengio, Yoshua},
	year = {2013},
	note = {ZSCC: 0000183 
arXiv: 1301.3584
ISBN: 1301.3584},
	pages = {1--18},
	file = {PDF:/home/theo/Zotero/storage/ZHD9CYCI/Pascanu, Bengio - 2013 - Revisiting Natural Gradient for Deep Networks(2).pdf:application/pdf},
}

@article{kingmaImprovingVariationalInference2016,
	title = {Improving {Variational} {Inference} with {Inverse} {Autoregressive} {Flow}},
	issn = {10495258},
	url = {http://arxiv.org/abs/1606.04934},
	abstract = {The framework of normalizing flows provides a general strategy for flexible variational inference of posteriors over latent variables. We propose a new type of normalizing flow, inverse autoregressive flow (IAF), that, in contrast to earlier published flows, scales well to high-dimensional latent spaces. The proposed flow consists of a chain of invertible transformations, where each transformation is based on an autoregressive neural network. In experiments, we show that IAF significantly improves upon diagonal Gaussian approximate posteriors. In addition, we demonstrate that a novel type of variational autoencoder, coupled with IAF, is competitive with neural autoregressive models in terms of attained log-likelihood on natural images, while allowing significantly faster synthesis.},
	number = {Nips},
	author = {Kingma, Diederik P. and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
	year = {2016},
	note = {ZSCC: 0000002 
arXiv: 1606.04934
ISBN: 9781611970685},
	file = {Improving Variational Inference with Inverse Autoregressive Flow - Kingma et al - 2016.pdf:/home/theo/Zotero/storage/RLTS2MYU/Improving Variational Inference with Inverse Autoregressive Flow - Kingma et al - 2016.pdf:application/pdf},
}

@article{ambikasaranFastDirectMethods2016,
	title = {Fast {Direct} {Methods} for {Gaussian} {Processes}},
	volume = {38},
	issn = {01628828},
	doi = {10.1109/TPAMI.2015.2448083},
	abstract = {A number of problems in probability and statistics can be addressed using the multivariate normal (Gaussian) distribution. In the one-dimensional case, computing the probability for a given mean and variance simply requires the evaluation of the corresponding Gaussian density. In the \$n\$-dimensional setting, however, it requires the inversion of an \$n {\textbackslash}times n\$ covariance matrix, \$C\$, as well as the evaluation of its determinant, \${\textbackslash}det(C)\$. In many cases, such as regression using Gaussian processes, the covariance matrix is of the form \$C = {\textbackslash}sigma{\textasciicircum}2 I + K\$, where \$K\$ is computed using a specified covariance kernel which depends on the data and additional parameters (hyperparameters). The matrix \$C\$ is typically dense, causing standard direct methods for inversion and determinant evaluation to require \${\textbackslash}mathcal O(n{\textasciicircum}3)\$ work. This cost is prohibitive for large-scale modeling. Here, we show that for the most commonly used covariance functions, the matrix \$C\$ can be hierarchically factored into a product of block low-rank updates of the identity matrix, yielding an \${\textbackslash}mathcal O (n{\textbackslash}log{\textasciicircum}2 n) \$ algorithm for inversion. More importantly, we show that this factorization enables the evaluation of the determinant \${\textbackslash}det(C)\$, permitting the direct calculation of probabilities in high dimensions under fairly broad assumptions on the kernel defining \$K\$. Our fast algorithm brings many problems in marginalization and the adaptation of hyperparameters within practical reach using a single CPU core. The combination of nearly optimal scaling in terms of problem size with high-performance computing resources will permit the modeling of previously intractable problems. We illustrate the performance of the scheme on standard covariance kernels.},
	number = {2},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Ambikasaran, Sivaram and Foreman-mackey, Daniel and Greengard, Leslie and Hogg, David W. and Neil, Michael O and O'Neil, Michael},
	year = {2016},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1403.6015},
	pages = {1--14},
	file = {Fast Direct Methods for Gaussian Processes - Ambikasaran et al - 2016.pdf:/home/theo/Zotero/storage/ALEYG395/Fast Direct Methods for Gaussian Processes - Ambikasaran et al - 2016.pdf:application/pdf},
}

@article{alemiInformationTheoreticAnalysisDeep2017,
	title = {An {Information}-{Theoretic} {Analysis} of {Deep} {Latent}-{Variable} {Models}},
	url = {https://arxiv.org/abs/1711.00464},
	number = {1},
	author = {Alemi, Alexander A. and Poole, Ben and Fischer, Ian and Dillon, Joshua V. and Saurous, Rif A. and Murphy, Kevin},
	year = {2017},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1711.00464},
	pages = {1--21},
	file = {An Information-Theoretic Analysis of Deep Latent-Variable Models - Alemi et al - 2017.pdf:/home/theo/Zotero/storage/FXIV2IM4/An Information-Theoretic Analysis of Deep Latent-Variable Models - Alemi et al - 2017.pdf:application/pdf},
}

@article{yaoUsingStackingAverage2017,
	title = {Using stacking to average {Bayesian} predictive distributions},
	url = {http://arxiv.org/abs/1704.02030},
	abstract = {The widely recommended procedure of Bayesian model averaging is flawed in the M-open setting in which the true data-generating process is not one of the candidate models being fit. We take the idea of stacking from the point estimation literature and generalize to the combination of predictive distributions, extending the utility function to any proper scoring rule, using Pareto smoothed importance sampling to efficiently compute the required leave-one-out posterior distributions and regularization to get more stability. We compare stacking of predictive distributions to several alternatives: stacking of means, Bayesian model averaging (BMA), pseudo-BMA using AIC-type weighting, and a variant of pseudo-BMA that is stabilized using the Bayesian bootstrap. Based on simulations and real-data applications, we recommend stacking of predictive distributions, with BB-pseudo-BMA as an approximate alternative when computation cost is an issue.},
	author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},
	year = {2017},
	note = {ZSCC: 0000003 
arXiv: 1704.02030},
	keywords = {bayesian model averaging, model combination, predictive distribution, proper scoring rule, stacking, stan},
	file = {Using stacking to average Bayesian predictive distributions - Yao et al - 2017.pdf:/home/theo/Zotero/storage/FGK9CUD4/Using stacking to average Bayesian predictive distributions - Yao et al - 2017.pdf:application/pdf},
}

@article{samoStringMembraneGaussian2015,
	title = {String and {Membrane} {Gaussian} {Processes}},
	issn = {15337928},
	abstract = {In this paper we introduce a novel framework for making exact nonparametric Bayesian inference on latent functions, that is particularly suitable for Big Data tasks. Firstly, we introduce a class of stochastic processes we refer to as string Gaussian processes (string GPs), which are not to be mistaken for Gaussian processes operating on text. We construct string GPs so that their finite-dimensional marginals exhibit suitable local conditional independence structures, which allow for scalable, distributed, and flexible nonparametric Bayesian inference, without resorting to approximations, and while ensuring some mild global regularity constraints. Furthermore, string GP priors naturally cope with heterogeneous input data, and the gradient of the learned latent function is readily available for explanatory analysis. Secondly, we provide some theoretical results relating our approach to the standard GP paradigm. In particular, we prove that some string GPs are Gaussian processes, which provides a complementary global perspective on our framework. Finally, we derive a scalable and distributed MCMC scheme for supervised learning tasks under string GP priors. The proposed MCMC scheme has computational time complexity \${\textbackslash}mathcal\{O\}(N)\$ and memory requirement \${\textbackslash}mathcal\{O\}(dN)\$, where \$N\$ is the data size and \$d\$ the dimension of the input space. We illustrate the efficacy of the proposed approach on several synthetic and real-world datasets, including a dataset with \$6\$ millions input points and \$8\$ attributes.},
	author = {Samo, Yves-Laurent Kom and Roberts, Stephen},
	year = {2015},
	note = {ZSCC: 0000000 
arXiv: 1507.06977},
}

@article{leeDeepNeuralNetworks2017,
	title = {Deep {Neural} {Networks} as {Gaussian} {Processes}},
	url = {https://arxiv.org/abs/1711.00165},
	author = {Lee, Jaehoon and Bahri, Yasaman and Novak, Roman and Schoenholz, Samuel S. and Pennington, Jeffrey and Sohl-Dickstein, Jascha},
	year = {2017},
	note = {ZSCC: 0000209 
arXiv: 1711.00165},
	pages = {1--14},
	file = {Deep Neural Networks as Gaussian Processes - Lee et al - 2017.pdf:/home/theo/Zotero/storage/6QIFWM3T/Deep Neural Networks as Gaussian Processes - Lee et al - 2017.pdf:application/pdf},
}

@article{frateModelingSmoothBackgrounds2017,
	title = {Modeling {Smooth} {Backgrounds} and {Generic} {Localized} {Signals} with {Gaussian} {Processes}},
	volume = {92697},
	url = {http://arxiv.org/abs/1709.05681},
	abstract = {We describe a procedure for constructing a model of a smooth data spectrum using Gaussian processes rather than the historical parametric description. This approach considers a fuller space of possible functions, is robust at increasing luminosity, and allows us to incorporate our understanding of the underlying physics. We demonstrate the application of this approach to modeling the background to searches for dijet resonances at the Large Hadron Collider and describe how the approach can be used in the search for generic localized signals.},
	number = {1},
	author = {Frate, Meghan and Cranmer, Kyle and Kalia, Saarik and Vandenberg-Rodes, Alexander and Whiteson, Daniel},
	year = {2017},
	note = {ZSCC: 0000020 
arXiv: 1709.05681},
	pages = {1--14},
	file = {Modeling Smooth Backgrounds and Generic Localized Signals with Gaussian - Frate et al - 2017.pdf:/home/theo/Zotero/storage/CM76F8TF/Modeling Smooth Backgrounds and Generic Localized Signals with Gaussian - Frate et al - 2017.pdf:application/pdf},
}

@article{palmerVariationalEMAlgorithms2006,
	title = {Variational {EM} algorithms for non-{Gaussian} latent variable models},
	volume = {18},
	issn = {1049-5258},
	abstract = {We consider criteria for variational representations of non-Gaussian latent variables, and derive variational EM algorithms in general form. We establish a general equivalence among convex bounding methods, evidence based methods, and ensemble learning/Variational Bayes methods, which has previously been demonstrated only for particular cases.},
	journal = {Advances in Neural Information Processing Systems},
	author = {Palmer, J. and Wipf, D. and Kreutz-Delgado, K. and Rao, B.},
	year = {2006},
	note = {ZSCC: 0000187 
ISBN: 9780262232531},
	pages = {1059},
	file = {Variational EM algorithms for non-Gaussian latent variable models - Palmer et al - 2006.pdf:/home/theo/Zotero/storage/WUJBR2NW/Variational EM algorithms for non-Gaussian latent variable models - Palmer et al - 2006.pdf:},
}

@article{klamiPolyaGammaAugmentationsFactor2014,
	title = {Polya-{Gamma} augmentations for factor models},
	volume = {39},
	abstract = {Bayesian inference for latent factor models, such as principal component and canonical correlation analysis, is easy for Gaussian likelihoods with conjugate priors using both Gibbs sampling and mean-field variational approximation. For other likelihood potentials one needs to either resort to more complex sampling schemes or to specifying dedicated forms for variational lower bounds. Recently, however, it was shown that for specific likelihoods related to the logistic function it is possible to augment the joint density with auxiliary variables following a olya-Gamma distribution, leading to closed-form updates for binary and over-dispersed count models. In this paper we describe how Gibbs sampling and mean-field variational approximation for various latent factor models can be implemented for these cases, presenting easy-to-implement and efficient inference schemas.},
	number = {1997},
	author = {Klami, Arto},
	year = {2014},
	note = {ZSCC: NoCitationData[s0]},
	keywords = {binary data, Binary data, count data, Count data, latent factor models, Latent factor models, matrix factorization, Matrix factorization},
	pages = {112--128},
	file = {Polya-Gamma augmentations for factor models - Klami - 2014.pdf:/home/theo/Zotero/storage/9P55CPSJ/Polya-Gamma augmentations for factor models - Klami - 2014.pdf:application/pdf},
}

@article{wilsonGaussianProcessKernels2013,
	title = {Gaussian {Process} {Kernels} for {Pattern} {Discovery} and {Extrapolation}},
	volume = {28},
	abstract = {Gaussian processes are rich distributions over functions, which provide a Bayesian nonparametric approach to smoothing and interpolation. We introduce simple closed form kernels that can be used with Gaussian processes to discover patterns and enable extrapolation. These kernels are derived by modelling a spectral density – the Fourier transform of a kernel – with a Gaussian mixture. The proposed kernels support a broad class of stationary covariances, but Gaussian process inference remains simple and analytic. We demonstrate the proposed kernels by discovering patterns and performing long range extrapolation on synthetic examples, as well as atmospheric CO2 trends and airline passenger data. We also show that it is possible to reconstruct several popular standard covariances within our framework.},
	number = {3},
	journal = {Proceedings of the 30th …},
	author = {Wilson, Andrew Gordon and Adams, Ryan Prescott},
	year = {2013},
	note = {ZSCC: 0000327 
arXiv: 1302.4245v3},
	file = {Gaussian Process Kernels for Pattern Discovery and Extrapolation - Wilson_Adams - 2013.pdf:/home/theo/Zotero/storage/S48CKAFU/Gaussian Process Kernels for Pattern Discovery and Extrapolation - Wilson_Adams - 2013.pdf:application/pdf},
}

@article{adamsProbabilisticBackpropagationScalable2015,
	title = {Probabilistic {Backpropagation} for {Scalable} {Learning} of {Bayesian} {Neural} {Networks}},
	volume = {37},
	abstract = {Large multilayer neural networks trained with backpropagation have recently achieved state-of-the-art results in a wide range of problems. However, using backprop for neural net learning still has some disadvantages, e.g., having to tune a large number of hyperparameters to the data, lack of calibrated probabilistic predictions, and a tendency to overfit the training data. In principle, the Bayesian approach to learning neural networks does not have these problems. However, existing Bayesian techniques lack scalability to large dataset and network sizes. In this work we present a novel scalable method for learning Bayesian neural networks, called probabilistic backpropagation (PBP). Similar to classical backpropagation, PBP works by computing a forward propagation of probabilities through the network and then doing a backward computation of gradients. A series of experiments on ten real-world datasets show that PBP is significantly faster than other techniques, while offering competitive predictive abilities. Our experiments also show that PBP provides accurate estimates of the posterior variance on the network weights.},
	journal = {Journal of Machine Learning Research},
	author = {Adams, Ryan Prescott},
	year = {2015},
	note = {ZSCC: 0000368 
arXiv: 1502.05336
ISBN: 9781510810587},
	pages = {1--6},
	file = {Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks - Adams - 2015.pdf:/home/theo/Zotero/storage/RZZEKZ5L/Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks - Adams - 2015.pdf:application/pdf},
}

@article{nguyenGaussianmixturemodelbasedSpatialNeighborhood2012,
	title = {Gaussian-mixture-model-based spatial neighborhood relationships for pixel labeling problem},
	volume = {42},
	issn = {10834419},
	doi = {10.1109/TSMCB.2011.2161284},
	abstract = {In this paper, we present a new algorithm for pixel labeling and image segmentation based on the standard Gaussian mixture model (GMM). Unlike the standard GMM where pixels themselves are considered independent of each other and the spatial relationship between neighboring pixels is not taken into account, the proposed method incorporates this spatial relationship into the standard GMM. Moreover, the proposed model requires fewer parameters compared with the models based on Markov random fields. In order to estimate model parameters from observations, instead of utilizing an expectation-maximization algorithm, we employ gradient method to minimize a higher bound on the data negative log-likelihood. The performance of the proposed model is compared with methods based on both standard GMM and Markov random fields, demonstrating the robustness, accuracy, and effectiveness of our method.},
	number = {1},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics},
	author = {Nguyen, Thanh Minh and Wu, Q. M.Jonathan},
	year = {2012},
	pmid = {21846606},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 078031901X},
	keywords = {Gaussian mixture models (GMMs), image segmentation, pixel labeling, spatial neighborhood relationships},
	pages = {193--202},
	file = {Gaussian-mixture-model-based spatial neighborhood relationships for pixel - Nguyen_Wu - 2012.pdf:/home/theo/Zotero/storage/PHGSW4YZ/Gaussian-mixture-model-based spatial neighborhood relationships for pixel - Nguyen_Wu - 2012.pdf:application/pdf;Gaussian-mixture-model-based spatial neighborhood relationships for pixel - Nguyen_Wu - 2012.pdf:/home/theo/Zotero/storage/RDIPDB5Z/Gaussian-mixture-model-based spatial neighborhood relationships for pixel - Nguyen_Wu - 2012.pdf:application/pdf},
}

@book{rasmussen2006gaussian,
	title = {Gaussian {Processes} for {Machine} {Learning}},
	volume = {1},
	isbn = {978-0-262-18253-9},
	abstract = {Gaussian processes (GPs) are natural generalisations of multivariate Gaussian random variables to infinite (countably or continuous) index sets. GPs have been applied in a large number of fields to a diverse range of ends, and very many deep theoretical analyses of various properties are available. This paper gives an introduction to Gaussian processes on a fairly elementary level with special emphasis on characteristics relevant in machine learning. It draws explicit connections to branches such as spline smoothing models and support vector machines in which similar ideas have been investigated. Gaussian process models are routinely used to solve hard machine learning problems. They are attractive because of their flexible non-parametric nature and computational simplicity. Treated within a Bayesian framework, very powerful statistical methods can be implemented which offer valid estimates of uncertainties in our predictions and generic model selection procedures cast as nonlinear optimization problems. Their main drawback of heavy computational scaling has recently been alleviated by the introduction of generic sparse approximations.13,78,31 The mathematical literature on GPs is large and often uses deep concepts which are not required to fully understand most machine learning applications. In this tutorial paper, we aim to present characteristics of GPs relevant to machine learning and to show up precise connections to other "kernel machines" popular in the community. Our focus is on a simple presentation, but references to more detailed sources are provided.},
	publisher = {MIT press Cambridge},
	author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
	year = {2018},
	pmid = {15112367},
	doi = {10.7551/mitpress/3206.001.0001},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 026218253X
Publication Title: Gaussian Processes for Machine Learning
ISSN: 0129-0657},
}

@article{kanagawaConvergenceGuaranteesKernelbased2016,
	title = {Convergence guarantees for kernel-based quadrature rules in misspecified settings},
	issn = {10495258},
	url = {http://arxiv.org/abs/1605.07254},
	abstract = {Kernel-based quadrature rules are becoming important in machine learning and statistics, as they achieve super-\${\textbackslash}sqrt\{n\}\$ convergence rates in numerical integration, and thus provide alternatives to Monte Carlo integration in challenging settings where integrands are expensive to evaluate or where integrands are high dimensional. These rules are based on the assumption that the integrand has a certain degree of smoothness, which is expressed as that the integrand belongs to a certain reproducing kernel Hilbert space (RKHS). However, this assumption can be violated in practice (e.g., when the integrand is a black box function), and no general theory has been established for the convergence of kernel quadratures in such misspecified settings. Our contribution is in proving that kernel quadratures can be consistent even when the integrand does not belong to the assumed RKHS, i.e., when the integrand is less smooth than assumed. Specifically, we derive convergence rates that depend on the (unknown) lesser smoothness of the integrand, where the degree of smoothness is expressed via powers of RKHSs or via Sobolev spaces.},
	number = {Nips},
	author = {Kanagawa, Motonobu and Sriperumbudur, Bharath K. and Fukumizu, Kenji},
	year = {2016},
	note = {ZSCC: 0000028 
arXiv: 1605.07254},
	pages = {1--15},
	file = {Convergence guarantees for kernel-based quadrature rules in misspecified - Kanagawa et al - 2016.pdf:/home/theo/Zotero/storage/B8CW49YM/Convergence guarantees for kernel-based quadrature rules in misspecified - Kanagawa et al - 2016.pdf:application/pdf},
}

@article{balogMondrianKernel2016,
	title = {The {Mondrian} {Kernel}},
	url = {http://arxiv.org/abs/1606.05241},
	abstract = {We introduce the Mondrian kernel, a fast random feature approximation to the Laplace kernel. It is suitable for both batch and online learning, and admits a fast kernel-width-selection procedure as the random features can be re-used efficiently for all kernel widths. The features are constructed by sampling trees via a Mondrian process [Roy and Teh, 2009], and we highlight the connection to Mondrian forests [Lakshminarayanan et al., 2014], where trees are also sampled via a Mondrian process, but fit independently. This link provides a new insight into the relationship between kernel methods and random forests.},
	author = {Balog, Matej and Lakshminarayanan, Balaji and Ghahramani, Zoubin and Roy, Daniel M. and Teh, Yee Whye},
	year = {2016},
	note = {ZSCC: 0000012 
arXiv: 1606.05241
ISBN: 9781510827806},
	file = {The Mondrian Kernel - Balog et al - 2016.pdf:/home/theo/Zotero/storage/NH9Q5IYA/The Mondrian Kernel - Balog et al - 2016.pdf:application/pdf},
}

@article{skujaHydrogenrelatedRadiationDefects2008,
	title = {Hydrogen-related radiation defects in {SiO2}-based glasses},
	volume = {266},
	issn = {0168583X},
	url = {http://arxiv.org/abs/1411.2581},
	doi = {10.1016/j.nimb.2008.03.150},
	abstract = {Spectroscopic properties of hydrogen atom trapped in an oxygen vacancy in SiO2 glass were studied. Samples were loaded with D2 and H2 gases to convert O vacancies to pairs of Si-D and Si-H groups, and subsequently irradiated by F2 laser in order to destroy some of these groups. Electron paramagnetic resonance, infrared absorption and visible/UV absorption spectra were measured. Proton hyperfine doublet with splitting of 1.05 mT was found in all H2-treated/irradiated samples. UV-bleaching treatment showed that this signal is independent of the other, well-known hydrogen-related signals in silica. The size of the hyperfine splitting corresponds to twice the 1H nuclear Zeeman splitting in applied magnetic field. The observed 1.05 mT doublet is tentatively attributed to the forbidden nuclear spin-flip transitions of proton trapped in an oxygen vacancy in silica. The allowed EPR transitions of this center are not resolved, possibly reflecting a variation in Si ⋯ H distance in oxygen vacancy with a trapped H atom. © 2008 Elsevier B.V. All rights reserved.},
	number = {12-13},
	journal = {Nuclear Instruments and Methods in Physics Research, Section B: Beam Interactions with Materials and Atoms},
	author = {Skuja, Linards and Kajihara, Koichi and Hirano, Masahiro and Hosono, Hideo},
	year = {2008},
	note = {ZSCC: 0000017 
arXiv: 1411.2581
ISBN: 1411.2581},
	keywords = {EPR, Oxygen vacancy, Silica glass},
	pages = {2971--2975},
	file = {Hydrogen-related radiation defects in SiO2-based glasses - Skuja et al - 2008.pdf:/home/theo/Zotero/storage/44N84D2I/Hydrogen-related radiation defects in SiO2-based glasses - Skuja et al - 2008.pdf:application/pdf},
}

@article{dilanDirichletProcessGaussian2010,
	title = {Dirichlet {Process} {Gaussian} {Mixture} {Models}: {Choise} of the {Base} {Distribution}},
	volume = {25},
	issn = {10009000},
	doi = {10.1007/s11390-010-1051-1},
	abstract = {In the Bayesian mixture modeling framework it is possible to infer the necessary number of components to model the data and therefore it is unnecessary to explicitly restrict the number of components. Nonparametric mixture models{\textbackslash}r{\textbackslash}nsidestep the problem of finding the "correct" number of mixture components by assuming infinitely many components. In this paper Dirichlet process mixture (DPM) models are cast as infinite mixture models and inference using Markov chain Monte Carlo is described. The specification of the priors on the model parameters is often guided by mathematical and practical convenience. The primary goal of this paper is to compare the choice of conjugate and non-conjugate base distributions on a particular class of DPM models which is widely used in applications, the Dirichlet process Gaussian mixture model (DPGMM). We compare computational efficiency and modeling performance of DPGMM defined using a conjugate and a conditionally conjugate base distribution. We show that better density models can result from using a wider class of priors with no or only a modest increase in computational effort.},
	number = {July},
	journal = {Journal of Computer Science and Technology},
	author = {Dilan, Görür and Rasmussen, Carl Edward},
	year = {2010},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 1000-9000},
	keywords = {bayesian nonparametrics, Bayesian nonparametrics, dirichlet processes, Dirichlet processes, gaussian mixtures, Gaussian mixtures},
	pages = {615--626},
	file = {Dirichlet Process Gaussian Mixture Models - Dilan_Rasmussen - 2010.pdf:/home/theo/Zotero/storage/ARLU4E2Q/Dirichlet Process Gaussian Mixture Models - Dilan_Rasmussen - 2010.pdf:application/pdf},
}

@article{al-shedivatLearningScalableDeep2016,
	title = {Learning {Scalable} {Deep} {Kernels} with {Recurrent} {Structure}},
	volume = {18},
	url = {http://arxiv.org/abs/1610.08936},
	abstract = {Many applications in speech, robotics, finance, and biology deal with sequential data, where ordering matters and recurrent structures are common. However, this structure cannot be easily captured by standard kernel functions. To model such structure, we propose expressive closed-form kernel functions for Gaussian processes. The resulting model, GP-LSTM, fully encapsulates the inductive biases of long short-term memory (LSTM) recurrent networks, while retaining the non-parametric probabilistic advantages of Gaussian processes. We learn the properties of the proposed kernels by optimizing the Gaussian process marginal likelihood using a new provably convergent semi-stochastic gradient procedure and exploit the structure of these kernels for scalable training and prediction. This approach provides a practical representation for Bayesian LSTMs. We demonstrate state-of-the-art performance on several benchmarks, and thoroughly investigate a consequential autonomous driving application, where the predictive uncertainties provided by GP-LSTM are uniquely valuable.},
	author = {Al-Shedivat, Maruan and Wilson, Andrew Gordon and Saatchi, Yunus and Hu, Zhiting and Xing, Eric P.},
	year = {2016},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1610.08936},
	pages = {1--37},
	file = {Learning Scalable Deep Kernels with Recurrent Structure - Al-Shedivat et al - 2016.pdf:/home/theo/Zotero/storage/ED45LUTY/Learning Scalable Deep Kernels with Recurrent Structure - Al-Shedivat et al - 2016.pdf:application/pdf},
}

@article{eijkhoutIntroductionHighPerformance2011,
	title = {Introduction to {High} {Performance} {Scientific} {Computing}},
	url = {http://www.tacc.utexas.edu/~eijkhout/istc/istc.html%5Cnhttp://www.saylor.org},
	doi = {10.5281/zenodo.49897},
	journal = {Hpc},
	author = {Eijkhout, Victor},
	year = {2011},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 978-1-257-99254-6},
	keywords = {parallel computing},
	pages = {446},
	file = {PDF:/home/theo/Zotero/storage/X22BHPQM/Eijkhout - 2011 - Introduction to High Performance Scientific Computing(2).pdf:application/pdf},
}

@article{jiangDefiningLeastCommunity2015,
	title = {Defining least community as a homogeneous group in complex networks},
	volume = {428},
	issn = {03784371},
	doi = {10.1016/j.physa.2015.02.029},
	abstract = {This paper introduces a new concept of least community that is as homogeneous as a random graph, and develops a new community detection algorithm from the perspective of homogeneity or heterogeneity. Based on this concept, we adopt head/tail breaks-a newly developed classification scheme for data with a heavy-tailed distribution-and rely on edge betweenness given its heavy-tailed distribution to iteratively partition a network into many heterogeneous and homogeneous communities. Surprisingly, the derived communities for any self-organized and/or self-evolved large networks demonstrate very striking power laws, implying that there are far more small communities than large ones. This notion of far more small things than large ones constitutes a new fundamental way of thinking for community detection.},
	journal = {Physica A: Statistical Mechanics and its Applications},
	author = {Jiang, Bin and Ma, Ding},
	year = {2015},
	note = {ZSCC: 0000008 
arXiv: 1502.02843v3
ISBN: 9781510810587},
	keywords = {Classification, Head/tail breaks, ht-index, k-means, Natural breaks, Scaling},
	pages = {154--160},
	file = {Defining least community as a homogeneous group in complex networks - Jiang_Ma - 2015.pdf:/home/theo/Zotero/storage/GPGDZRCH/Defining least community as a homogeneous group in complex networks - Jiang_Ma - 2015.pdf:application/pdf},
}

@article{ghahramaniProbabilisticMachineLearning2015,
	title = {Probabilistic machine learning and artificial intelligence},
	volume = {521},
	issn = {14764687},
	doi = {10.1038/nature14541},
	abstract = {How can a machine learn from experience? Probabilistic modelling provides a framework for understanding what learning is, and has therefore emerged as one of the principal theoretical and practical approaches for designing machines that learn from data acquired through experience. The probabilistic framework, which describes how to represent and manipulate uncertainty about models and predictions, has a central role in scientific data analysis, machine learning, robotics, cognitive science and artificial intelligence. This Review provides an introduction to this framework, and discusses some of the state-of-the-art advances in the field, namely, probabilistic programming, Bayesian optimization, data compression and automatic model discovery.},
	number = {7553},
	journal = {Nature},
	author = {Ghahramani, Zoubin},
	year = {2015},
	pmid = {26017444},
	note = {ZSCC: 0000739 
ISBN: 0028-0836},
	pages = {452--459},
	file = {Probabilistic machine learning and artificial intelligence - Ghahramani - 2015.pdf:/home/theo/Zotero/storage/84A9WGLW/Probabilistic machine learning and artificial intelligence - Ghahramani - 2015.pdf:application/pdf},
}

@phdthesis{deutschCredibilitySVMEstimates2016,
	title = {Credibility of {SVM} {Estimates}},
	author = {Deutsch, Matthaus},
	year = {2016},
	note = {ZSCC: NoCitationData[s0] 
Publication Title: Master's Thesis},
	file = {PDF:/home/theo/Zotero/storage/UFFEMYH3/Unknown - 2016 - Credibility of SVM Estimates(2).pdf:application/pdf},
}

@article{hernandez-lobatoScalableGaussianProcess2015,
	title = {Scalable {Gaussian} {Process} {Classification} via {Expectation} {Propagation}},
	url = {http://arxiv.org/abs/1507.04513},
	abstract = {Variational methods have been recently considered for scaling the training process of Gaussian process classifiers to large datasets. As an alternative, we describe here how to train these classifiers efficiently using expectation propagation. The proposed method allows for handling datasets with millions of data instances. More precisely, it can be used for (i) training in a distributed fashion where the data instances are sent to different nodes in which the required computations are carried out, and for (ii) maximizing an estimate of the marginal likelihood using a stochastic approximation of the gradient. Several experiments indicate that the method described is competitive with the variational approach.},
	author = {Hernández-Lobato, Daniel and Hernández-Lobato, José Miguel},
	year = {2015},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1507.04513},
	file = {Scalable Gaussian Process Classification via Expectation Propagation - Hernández-Lobato_Hernández-Lobato - 2015.pdf:/home/theo/Zotero/storage/RPYJCSG4/Scalable Gaussian Process Classification via Expectation Propagation - Hernández-Lobato_Hernández-Lobato - 2015.pdf:application/pdf},
}

@article{ahnGaugingVariationalInference2017,
	title = {Gauging {Variational} {Inference}},
	issn = {10495258},
	url = {http://arxiv.org/abs/1703.01056},
	abstract = {Computing partition function is the most important statistical inference task arising in applications of Graphical Models (GM). Since it is computationally intractable, approximate methods have been used to resolve the issue in practice, where mean-field (MF) and belief propagation (BP) are arguably the most popular and successful approaches of a variational type. In this paper, we propose two new variational schemes, coined Gauged-MF (G-MF) and Gauged-BP (G-BP), improving MF and BP, respectively. Both provide lower bounds for the partition function by utilizing the so-called gauge transformation which modifies factors of GM while keeping the partition function invariant. Moreover, we prove that both G-MF and G-BP are exact for GMs with a single loop of a special structure, even though the bare MF and BP perform badly in this case. Our extensive experiments, on complete GMs of relatively small size and on large GM (up-to 300 variables) confirm that the newly proposed algorithms outperform and generalize MF and BP.},
	number = {Nips},
	author = {Ahn, Sungsoo and Chertkov, Michael and Shin, Jinwoo},
	year = {2017},
	note = {ZSCC: 0000004 
arXiv: 1703.01056},
	pages = {1--10},
}

@article{wainwright2008graphical,
	title = {Graphical {Models}, {Exponential} {Families}, and {Variational} {Inference}},
	volume = {1},
	issn = {1935-8237, 1935-8245},
	doi = {10.1561/2200000001},
	number = {1--2},
	journal = {Foundations and Trends®in Machine Learning},
	author = {Wainwright, Martin J and Jordan, Michael I},
	year = {2008},
	pmid = {8812124},
	note = {ZSCC: 0003616 
Publisher: Now Publishers, Inc.
ISBN: 1601981848, 9781601981844},
	pages = {1--305},
	file = {Graphical Models, Exponential Families, and Variational Inference - Wainwright_Jordan - 2008.pdf:/home/theo/Zotero/storage/5TCZJUZJ/Graphical Models, Exponential Families, and Variational Inference - Wainwright_Jordan - 2008.pdf:application/pdf},
}

@article{tranBayesianDataAugmentation2017,
	title = {A {Bayesian} {Data} {Augmentation} {Approach} for {Learning} {Deep} {Models}},
	url = {http://arxiv.org/abs/1710.10564},
	abstract = {Data augmentation is an essential part of the training process applied to deep learning models. The motivation is that a robust training process for deep learning models depends on large annotated datasets, which are expensive to be acquired, stored and processed. Therefore a reasonable alternative is to be able to automatically generate new annotated training samples using a process known as data augmentation. The dominant data augmentation approach in the field assumes that new training samples can be obtained via random geometric or appearance transformations applied to annotated training samples, but this is a strong assumption because it is unclear if this is a reliable generative model for producing new training samples. In this paper, we provide a novel Bayesian formulation to data augmentation, where new annotated training points are treated as missing variables and generated based on the distribution learned from the training set. For learning, we introduce a theoretically sound algorithm --- generalised Monte Carlo expectation maximisation, and demonstrate one possible implementation via an extension of the Generative Adversarial Network (GAN). Classification results on MNIST, CIFAR-10 and CIFAR-100 show the better performance of our proposed method compared to the current dominant data augmentation approach mentioned above --- the results also show that our approach produces better classification results than similar GAN models.},
	number = {Nips},
	author = {Tran, Toan and Pham, Trung and Carneiro, Gustavo and Palmer, Lyle and Reid, Ian},
	year = {2017},
	note = {ZSCC: 0000071 
arXiv: 1710.10564},
	pages = {1--10},
	file = {A Bayesian Data Augmentation Approach for Learning Deep Models - Tran et al - 2017.pdf:/home/theo/Zotero/storage/GKTY3XQ8/A Bayesian Data Augmentation Approach for Learning Deep Models - Tran et al - 2017.pdf:application/pdf},
}

@article{leinsterBasicCategoryTheory2016,
	title = {Basic {Category} {Theory}},
	issn = {00221082},
	url = {http://arxiv.org/abs/1612.09375},
	doi = {10.1017/CBO9781107360068},
	abstract = {This short introduction to category theory is for readers with relatively little mathematical background. At its heart is the concept of a universal property, important throughout mathematics. After a chapter introducing the basic definitions, separate chapters present three ways of expressing universal properties: via adjoint functors, representable functors, and limits. A final chapter ties the three together. For each new categorical concept, a generous supply of examples is provided, taken from different parts of mathematics. At points where the leap in abstraction is particularly great (such as the Yoneda lemma), the reader will find careful and extensive explanations.},
	author = {Leinster, Tom},
	year = {2016},
	pmid = {6635932},
	note = {ZSCC: 0000010 
arXiv: 1612.09375
ISBN: 9781107360068},
	file = {PDF:/home/theo/Zotero/storage/TJUE29YB/Leinster - 2016 - Basic Category Theory(2).pdf:application/pdf},
}

@article{diengVariationalInferenceChi2016,
	title = {Variational {Inference} via \${\textbackslash}chi\$-{Upper} {Bound} {Minimization}},
	issn = {10495258},
	url = {http://arxiv.org/abs/1611.00328},
	doi = {10.1007/s00261-011-9795-9},
	abstract = {Variational inference (VI) is widely used as an efficient alternative to Markov chain Monte Carlo. It posits a family of approximating distributions \$q\$ and finds the closest member to the exact posterior \$p\$. Closeness is usually measured via a divergence \$D(q {\textbar}{\textbar} p)\$ from \$q\$ to \$p\$. While successful, this approach also has problems. Notably, it typically leads to underestimation of the posterior variance. In this paper we propose CHIVI, a black-box variational inference algorithm that minimizes \$D\_\{{\textbackslash}chi\}(p {\textbar}{\textbar} q)\$, the \${\textbackslash}chi\$-divergence from \$p\$ to \$q\$. CHIVI minimizes an upper bound of the model evidence, which we term the \${\textbackslash}chi\$ upper bound (CUBO). Minimizing the CUBO leads to improved posterior uncertainty, and it can also be used with the classical VI lower bound (ELBO) to provide a sandwich estimate of the model evidence. We study CHIVI on three models: probit regression, Gaussian process classification, and a Cox process model of basketball plays. When compared to expectation propagation and classical VI, CHIVI produces better error rates and more accurate estimates of posterior variance.},
	number = {Nips},
	author = {Dieng, Adji B. and Tran, Dustin and Ranganath, Rajesh and Paisley, John and Blei, David M.},
	year = {2016},
	pmid = {21904887},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1611.00328},
	file = {Variational Inference via \$-chi\$-Upper Bound Minimization - Dieng et al - 2016.pdf:/home/theo/Zotero/storage/QW4I4XEN/Variational Inference via \$-chi\$-Upper Bound Minimization - Dieng et al - 2016.pdf:application/pdf},
}

@article{mackayLocalMinimaSymmetrybreaking2001,
	title = {Local minima, symmetry-breaking, and model pruning in variational free energy minimization},
	url = {http://www.inference.phy.cam.ac.uk/mackay/minima.ps.gz},
	abstract = {Approximate inference by variational free energy minimization (also known as variational Bayes, or ensemble learning) has maximum likelihood and maximum a posteriori methods as special cases, so we might hope that it can only work better than these standard meth-ods. However, cases have been found in which degrees of freedom are 'pruned', perhaps inappropriately. This paper investigates this phenomenon in a toy example. Approximate inference by variational free energy minimization (also known as variational Bayes, or ensemble learning, or learning with noisy weights – see (MacKay 1995) for a review) has maximum likelihood and maximum a posteriori methods as special cases, so we might hope that it can only work better than these standard methods. However, cases have been found in which degrees of freedom are 'pruned', perhaps inappropriately. This paper investigates this phenomenon in a toy example. Motivations for VFE: want to incorporate uncertainty about parameters into the model-fitting process. Also worried about the electric monastry – location in parameter space where the likelihood diverges. Uncertainty is greatest (and singularities in the likelihood more prominent) when there is little data, so VFE is of most interest for small N . Problem observed by Zoubin Ghahramani (studying ensemble learning for HMMs (MacKay 1997)): extra degrees of freedom are not used. The model self-prunes. Annoying because we don't want the pruned model, we want the model we believe in – with lots of parameters, and big error bars on them! Parameter pruning is bad news because we would like predictions to take into accoutn uncertainty. Comment on spontaneous pruning: is sometimes viewed as a convenient automatic Occam's razor, but does it behave correctly? Occam effect should be very weak for small N .},
	journal = {Inference Group, Cavendish Laboratory,},
	author = {MacKay, DJC},
	year = {2001},
	note = {ZSCC: 0000033},
	pages = {1--10},
	file = {Local minima, symmetry-breaking, and model pruning in variational free energy - MacKay - 2001.pdf:/home/theo/Zotero/storage/MLBUX6YK/Local minima, symmetry-breaking, and model pruning in variational free energy - MacKay - 2001.pdf:application/pdf},
}

@article{opperPerturbationTheoryVariational2015,
	title = {Perturbation {Theory} for {Variational} {Inference}},
	abstract = {The variational approximation is known to underestimate the true variance of a probability measure, like a posterior distribution. In latent variable models whose parameters are permutation-invariant with respect to the likelihood, the variational approximation might self-prune and ignore its parameters. We view the variational free energy and its accompanying evidence lower bound as a first-order term from a perturbation of the true log partition function and derive a power series of corrections. We sketch by means of a "variational matrix factorization" example how a further term could correct for predictions from a self-pruned approximation.},
	journal = {NIPS Workshop on Approximate Inference},
	author = {Opper, Manfred and Fraccaro, Marco and Paquet, Ulrich and Susemihl, Alex and Winther, Ole},
	year = {2015},
	note = {ZSCC: 0000003},
	pages = {1--9},
	file = {Perturbation Theory for Variational Inference - Opper et al - 2015.pdf:/home/theo/Zotero/storage/EZBGMSYY/Perturbation Theory for Variational Inference - Opper et al - 2015.pdf:},
}

@article{gorbachScalableVariationalInference2017,
	title = {Scalable {Variational} {Inference} for {Dynamical} {Systems}},
	issn = {10495258},
	url = {http://arxiv.org/abs/1705.07079},
	doi = {10.1111/j.1095-8339.2010.01081.x},
	abstract = {Gradient matching is a promising tool for learning parameters and state dynamics of ordinary differential equations. It is a grid free inference approach, which, for fully observable systems is at times competitive with numerical integration. However, for many real-world applications, only sparse observations are available or even unobserved variables are included in the model description. In these cases most gradient matching methods are difficult to apply or simply do not provide satisfactory results. That is why, despite the high computational cost, numerical integration is still the gold standard in many applications. Using an existing gradient matching approach, we propose a scalable variational inference framework which can infer states and parameters simultaneously, offers computational speedups, improved accuracy and works well even under model misspecifications in a partially observable system.},
	number = {Nips},
	author = {Gorbach, Nico S. and Bauer, Stefan and Buhmann, Joachim M.},
	year = {2017},
	note = {ZSCC: 0000017 
arXiv: 1705.07079
ISBN: 0024-4074},
	file = {Scalable Variational Inference for Dynamical Systems - Gorbach et al - 2017.pdf:/home/theo/Zotero/storage/3WPMN9DR/Scalable Variational Inference for Dynamical Systems - Gorbach et al - 2017.pdf:application/pdf},
}

@article{palmerVariationalEMAlgorithm2005,
	title = {Variational {EM} {Algorithm} for {Non}-{Gaussian} {Latent} {Variable} {Models}},
	volume = {18},
	issn = {1049-5258},
	abstract = {We consider criteria for variational representations of non-Gaussian latent variables, and derive variational EM algorithms in general form. We establish a general equivalence among convex bounding methods, evidence based methods, and ensemble learning/Variational Bayes methods, which has previously been demonstrated only for particular cases.},
	journal = {Advances in Neural Information Processing Systems 18},
	author = {Palmer, J A and Kerutz-Delgado, K and Wipf, D P and Rao, B D},
	year = {2005},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 9780262232531},
	pages = {1059--1066},
	file = {Variational EM Algorithm for Non-Gaussian Latent Variable Models - Palmer et al - 2005.pdf:/home/theo/Zotero/storage/BQUCDCZL/Variational EM Algorithm for Non-Gaussian Latent Variable Models - Palmer et al - 2005.pdf:},
}

@article{csato2002sparse,
	title = {Sparse on-line {Gaussian} processes},
	volume = {14},
	issn = {0899-7667},
	doi = {10.1162/089976602317250933},
	number = {3},
	journal = {Neural computation},
	author = {Csató, Lehel and Opper, Manfred},
	year = {2002},
	note = {ZSCC: 0000751 
Publisher: MIT Press},
	pages = {641--668},
	file = {Sparse on-line Gaussian processes - Csató_Opper - 2002.pdf:/home/theo/Zotero/storage/6QZARLC9/Sparse on-line Gaussian processes - Csató_Opper - 2002.pdf:application/pdf},
}

@article{bamlerPerturbativeBlackBox2017,
	title = {Perturbative {Black} {Box} {Variational} {Inference}},
	issn = {15735052},
	url = {http://arxiv.org/abs/1709.07433},
	doi = {10.1007/s11258-017-0768-0},
	abstract = {Black box variational inference (BBVI) with reparameterization gradients triggered the exploration of divergence measures other than the Kullback-Leibler (KL) divergence, such as alpha divergences. In this paper, we view BBVI with generalized divergences as a form of estimating the marginal likelihood via biased importance sampling. The choice of divergence determines a bias-variance trade-off between the tightness of a bound on the marginal likelihood (low bias) and the variance of its gradient estimators. Drawing on variational perturbation theory of statistical physics, we use these insights to construct a family of new variational bounds. Enumerated by an odd integer order \$K\$, this family captures the standard KL bound for \$K=1\$, and converges to the exact marginal likelihood as \$K{\textbackslash}to{\textbackslash}infty\$. Compared to alpha-divergences, our reparameterization gradients have a lower variance. We show in experiments on Gaussian Processes and Variational Autoencoders that the new bounds are more mass covering, and that the resulting posterior covariances are closer to the true posterior and lead to higher likelihoods on held-out data.},
	number = {Nips},
	author = {Bamler, Robert and Zhang, Cheng and Opper, Manfred and Mandt, Stephan},
	year = {2017},
	pmid = {5478968},
	note = {ZSCC: 0000020 
arXiv: 1709.07433
ISBN: 0022-3514{\textbackslash}r1939-1315},
	file = {Perturbative Black Box Variational Inference - Bamler et al - 2017.pdf:/home/theo/Zotero/storage/E6CBH4NL/Perturbative Black Box Variational Inference - Bamler et al - 2017.pdf:application/pdf},
}

@article{hoffman2013stochastic,
	title = {Structured {Stochastic} {Variational} {Inference}},
	volume = {14},
	issn = {1532-4435},
	url = {http://arxiv.org/abs/1404.4114},
	doi = {citeulike-article-id:10852147},
	abstract = {Stochastic variational inference makes it possible to approximate posterior distributions induced by large datasets quickly using stochastic optimization. The algorithm relies on the use of fully factorized variational distributions. However, this "mean-field" independence approximation limits the fidelity of the posterior approximation, and introduces local optima. We show how to relax the mean-field approximation to allow arbitrary dependencies between global parameters and local hidden variables, producing better parameter estimates by reducing bias, sensitivity to local optima, and sensitivity to hyperparameters.},
	number = {1},
	journal = {The Journal of Machine Learning Research},
	author = {Hoffman, Matthew D. and Blei, David M.},
	year = {2014},
	pmid = {19926898},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1404.4114
Publisher: JMLR. org
ISBN: 1532-4435},
	pages = {1303--1347},
	file = {Structured Stochastic Variational Inference - Hoffman_Blei - 2014.pdf:/home/theo/Zotero/storage/944JMFVW/Structured Stochastic Variational Inference - Hoffman_Blei - 2014.pdf:application/pdf},
}

@article{ruizScalableLargeScaleClassification2017,
	title = {Scalable {Large}-{Scale} {Classification} with {Latent} {Variable} {Augmentation}},
	number = {Nips},
	journal = {Neural Information Processing Systems (NIPS)},
	author = {Ruiz, Francisco J R and Titsias, Michalis K and Blei, David M},
	year = {2017},
	note = {ZSCC: 0000000},
	file = {Scalable Large-Scale Classification with Latent Variable Augmentation - Ruiz et al - 2017.pdf:/home/theo/Zotero/storage/BZQ427CA/Scalable Large-Scale Classification with Latent Variable Augmentation - Ruiz et al - 2017.pdf:},
}

@article{villacampa-calvoScalableMultiClassGaussian2017,
	title = {Scalable {Multi}-{Class} \{{G}\}aussian {Process} {Classification} using {Expectation} {Propagation}},
	volume = {70},
	url = {http://proceedings.mlr.press/v70/villacampa-calvo17a.html},
	abstract = {This paper describes an expectation propagation (EP) method for multi-class classification with Gaussian processes that scales well to very large datasets. In such a method the estimate of the log-marginal-likelihood involves a sum across the data instances. This enables efficient training using stochastic gradients and mini-batches. When this type of training is used, the computational cost does not depend on the number of data instances N. Furthermore, extra assumptions in the approximate inference process make the memory cost independent of N. The consequence is that the proposed EP method can be used on datasets with millions of instances. We compare empirically this method with alternative approaches that approximate the required computations using variational inference. The results show that it performs similar or even better than these techniques, which sometimes give significantly worse predictive distributions in terms of the test log-likelihood. Besides this, the training process of the proposed approach also seems to converge in a smaller number of iterations.},
	journal = {Proceedings of the 34th International Conference on Machine Learning},
	author = {Villacampa-Calvo, Carlos and Hernández-Lobato, Daniel},
	year = {2017},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1706.07258},
	pages = {3550--3559},
	file = {PDF:/home/theo/Zotero/storage/VMBCH29U/Villacampa-Calvo, Hernández-Lobato - 2017 - Scalable Multi-Class G aussian Process Classification using Expectation Propagation(2).pdf:application/pdf},
}

@article{rasmussenInfiniteMixturesGaussian2001,
	title = {Infinite mixtures of {Gaussian} process experts},
	volume = {2},
	issn = {10495258},
	url = {http://books.google.com/books?hl=en&amp;lr=&amp;id=GbC8cqxGR7YC&amp;oi=fnd&amp;pg=PA881&amp;dq=Infinite+Mixtures+of+Gaussian+Process+Experts&amp;ots=ZvL5K_0yw5&amp;sig=vFBwDivSLh4OcdGbfG0vTZSb9h0},
	abstract = {We present an extension to the Mixture of Experts (ME) model, where the individual experts are Gaussian Process (GP) regression models. Using an input-dependent adaptation of the Dirichlet Process, we implement a gating network for an infinite number of Experts. Inference in this model may be done efficiently using a Markov Chain relying on Gibbs sampling. The model allows the effective covariance function to vary with the inputs, and may handle large datasets thus potentially overcoming two of the biggest hurdles with GP models. Simulations show the viability of this approach.},
	journal = {Advances in Neural Information Processing Systems 14},
	author = {Rasmussen, CE and Ghahramani, Z},
	year = {2001},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 0-262-11245-0},
	pages = {881--888},
	file = {Infinite mixtures of Gaussian process experts - Rasmussen_Ghahramani - 2001.pdf:/home/theo/Zotero/storage/6Y8TYYC8/Infinite mixtures of Gaussian process experts - Rasmussen_Ghahramani - 2001.pdf:application/pdf},
}

@article{zhangEmbarrassinglyParallelInference2017,
	title = {Embarrassingly {Parallel} {Inference} for {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/1702.08420},
	abstract = {Training Gaussian process-based models typically involves an \$ O(N{\textasciicircum}3)\$ computational bottleneck due to inverting the covariance matrix. Popular methods for overcoming this matrix inversion problem cannot adequately model all types of latent functions, and are often not parallelizable. However, judicious choice of model structure can ameliorate this problem. A mixture-of-experts model that uses a mixture of \$K\$ Gaussian processes offers modeling flexibility and opportunities for scalable inference. Our embarassingly parallel algorithm combines low-dimensional matrix inversions with importance sampling to yield a flexible, scalable mixture-of-experts model that offers comparable performance to Gaussian process regression at a much lower computational cost.},
	number = {Nips},
	author = {Zhang, Michael Minyi and Williamson, Sinead A.},
	year = {2017},
	note = {ZSCC: 0000000 
arXiv: 1702.08420},
	pages = {1--5},
	file = {Embarrassingly Parallel Inference for Gaussian Processes - Zhang_Williamson - 2017.pdf:/home/theo/Zotero/storage/BT85K6DC/Embarrassingly Parallel Inference for Gaussian Processes - Zhang_Williamson - 2017.pdf:application/pdf},
}

@article{robertsSimpleConditionsConvergence1994,
	title = {Simple conditions for the convergence of the {Gibbs} sampler and {Metropolis}-{Hastings} algorithms},
	volume = {49},
	issn = {03044149},
	doi = {10.1016/0304-4149(94)90134-1},
	abstract = {Markov chain Monte Carlo (MCMC) simulation methods are being used increasingly in statistical computation to explore and estimate features of likelihood surfaces and Bayesian posterior distributions. This paper presents simple conditions which ensure the convergence of two widely used versions of MCMC, the Gibbs sampler and Metropolis-Hastings algorithms. © 1994.},
	number = {2},
	journal = {Stochastic Processes and their Applications},
	author = {Roberts, G. O. and Smith, A. F.M.},
	year = {1994},
	note = {ZSCC: 0000419 
ISBN: 0304-4149},
	keywords = {Markov chain Monte Carlo, ergodicity, Gibbs sampler, lower semicontinuity, Metropolis-Hastings algorithm, statistical computation},
	pages = {207--216},
	file = {Simple conditions for the convergence of the Gibbs sampler and - Roberts_Smith - 1994.pdf:/home/theo/Zotero/storage/PRRYNAEJ/Simple conditions for the convergence of the Gibbs sampler and - Roberts_Smith - 1994.pdf:application/pdf},
}

@article{rainforthTighterVariationalBounds2018,
	title = {Tighter {Variational} {Bounds} are {Not} {Necessarily} {Better}},
	url = {http://arxiv.org/abs/1802.04537},
	abstract = {We provide theoretical and empirical evidence that using tighter evidence lower bounds (ELBOs) can be detrimental to the process of learning an inference network by reducing the signal-to-noise ratio of the gradient estimator. Our results call into question common implicit assumptions that tighter ELBOs are better variational objectives for simultaneous model learning and inference amortization schemes. Based on our insights, we introduce three new algorithms: the partially importance weighted auto-encoder (PIWAE), the multiply importance weighted auto-encoder (MIWAE), and the combination importance weighted auto-encoder (CIWAE), each of which includes the standard importance weighted auto-encoder (IWAE) as a special case. We show that each can deliver improvements over IWAE, even when performance is measured by the IWAE target itself. Furthermore, our results suggest that PIWAE may be able to deliver simultaneous improvements in the training of both the inference and generative networks.},
	author = {Rainforth, Tom and Kosiorek, Adam R. and Le, Tuan Anh and Maddison, Chris J. and Igl, Maximilian and Wood, Frank and Teh, Yee Whye},
	year = {2018},
	note = {ZSCC: 0000073 
arXiv: 1802.04537},
	file = {PDF:/home/theo/Zotero/storage/YK97A3E3/Rainforth et al. - 2018 - Tighter Variational Bounds are Not Necessarily Better(2).pdf:application/pdf},
}

@article{nickischApproximationsBinaryGaussian2008,
	title = {Approximations for {Binary} {Gaussian} {Process} {Classification}},
	volume = {9},
	issn = {10495258},
	abstract = {We provide a comprehensive overview of many recent algorithms for approximate inference in Gaussian process models for probabilistic binary classification. The relationships between several approaches are elucidated theoretically, and the properties of the different algorithms are corroborated by experimental results. We examine both 1) the quality of the predictive distributions and 2) the suitability of the different marginal likelihood approximations for model selection (selecting hyperparameters) and compare to a gold standard based on MCMC. Interestingly, some methods produce good predictive distributions although their marginal likelihood approximations are poor. Strong conclusions are drawn about the methods: The Expectation Propagation algorithm is almost always the method of choice unless the computational budget is very tight. We also extend existing methods in various ways, and provide unifying code implementing all approaches.},
	journal = {Machine Learning Research},
	author = {Nickisch, Hannes and Rasmussen, Carl Edward},
	year = {2008},
	note = {ZSCC: 0000308 
ISBN: 0-262-23253-7},
	keywords = {probabilistic classification, ex-, gaussian process priors, laplaces, marginal likelihood evidence, mean field methods, pectation propagation, s approximation, variational bounding},
	pages = {2035--2078},
	file = {Approximations for Binary Gaussian Process Classification - Nickisch_Rasmussen - 2008.pdf:/home/theo/Zotero/storage/F8GKAIAA/Approximations for Binary Gaussian Process Classification - Nickisch_Rasmussen - 2008.pdf:},
}

@article{gentonClassesKernelsMachine2001,
	title = {Classes of {Kernels} for {Machine} {Learning}: {A} {Statistics} {Perspective}},
	volume = {2},
	issn = {15324435},
	doi = {10.1162/15324430260185646},
	abstract = {In this paper, we present classes of kernels for machine learning from a statistics perspective. Indeed, kernels are positive definite functions and thus also covariances. After discussing key properties of kernels, as well as a new formula to construct kernels, we present several important classes of kernels: anisotropic stationary kernels, isotropic stationary kernels, compactly supported kernels, locally stationary kernels, nonstationary kernels, and sep-arable nonstationary kernels. Compactly supported kernels and separable nonstationary kernels are of prime interest because they provide a computational reduction for kernel-based methods. We describe the spectral representation of the various classes of kernels and conclude with a discussion on the characterization of nonlinear maps that reduce non-stationary kernels to either stationarity or local stationarity.},
	journal = {Journal of Machine Learning Research},
	author = {Genton, M.},
	year = {2001},
	note = {ZSCC: 0000567 
ISBN: 1532-4435},
	keywords = {aniso, compactly supported, covariance, isotropic, locally stationary, reducible, separable, stationary},
	pages = {299--312},
	file = {Classes of Kernels for Machine Learning - Genton - 2001.pdf:/home/theo/Zotero/storage/I245RYUU/Classes of Kernels for Machine Learning - Genton - 2001.pdf:application/pdf},
}

@article{heinonenNEURALNONSTATIONARYSPECTRAL2018,
	title = {{NEURAL} {NON}-{STATIONARY} {SPECTRAL} {KERNEL}},
	number = {2017},
	author = {Heinonen, Markus and Kaski, Samuel},
	year = {2018},
	note = {ZSCC: 0000001 
arXiv: 1811.10978v1},
	pages = {1--12},
	file = {NEURAL NON-STATIONARY SPECTRAL KERNEL - Heinonen_Kaski - 2018.pdf:/home/theo/Zotero/storage/BATUTFZR/NEURAL NON-STATIONARY SPECTRAL KERNEL - Heinonen_Kaski - 2018.pdf:application/pdf},
}

@article{heinonenNonStationarySpectralKernels2017,
	title = {Non-{Stationary} {Spectral} {Kernels}},
	url = {http://arxiv.org/abs/1705.08736},
	abstract = {We propose non-stationary spectral kernels for Gaussian process regression. We propose to model the spectral density of a non-stationary kernel function as a mixture of input-dependent Gaussian process frequency density surfaces. We solve the generalised Fourier transform with such a model, and present a family of non-stationary and non-monotonic kernels that can learn input-dependent and potentially long-range, non-monotonic covariances between inputs. We derive efﬁcient inference using model whitening and marginalized posterior, and show with case studies that these kernels are necessary when modelling even rather simple time series, image or geospatial data with non-stationary characteristics.},
	number = {Nips},
	journal = {arXiv:1705.08736 [cs, stat]},
	author = {Heinonen, Markus},
	year = {2017},
	note = {ZSCC: 0000034},
	file = {Non-Stationary Spectral Kernels - Heinonen - 2017.pdf:/home/theo/Zotero/storage/9DRUFCER/Non-Stationary Spectral Kernels - Heinonen - 2017.pdf:application/pdf},
}

@article{langAdaptiveNonStationaryKernel2018,
	title = {Adaptive {Non}-{Stationary} {Kernel} {Regression} for {Terrain} {Modeling}},
	doi = {10.7551/mitpress/7830.003.0012},
	abstract = {Three-dimensional digital terrain models are of fundamental importance{\textbackslash}nin many areas such as the geo-sciences and outdoor robotics. Accurate{\textbackslash}nmodeling requires the ability to deal with a varying data density{\textbackslash}nand to balance smoothing against the preservation of discontinuities.{\textbackslash}nThe latter is particularly important for robotics applications, as{\textbackslash}ndiscontinuities that arise, for example, at steps, stairs, or building{\textbackslash}nwalls are important features for path planning or terrain segmentation{\textbackslash}ntasks. In this paper, we present an extension of the well-established{\textbackslash}nGaussian process regression technique, that utilizes non-stationary{\textbackslash}ncovariance functions to locally adapt to the structure of the terrain{\textbackslash}ndata. In this way, we achieve strong smoothing in flat areas and{\textbackslash}nalong edges and at the same time preserve edges and corners. The{\textbackslash}nderived model yields predictive height distributions for arbitrary{\textbackslash}nlocations of the terrain and therefore allows us to fill gaps in{\textbackslash}ndata and to perform conservative predictions in occluded areas.},
	journal = {Robotics},
	author = {Lang, Tobias},
	year = {2018},
	note = {ZSCC: NoCitationData[s0]},
	file = {Adaptive Non-Stationary Kernel Regression for Terrain Modeling - Lang - 2018.pdf:/home/theo/Zotero/storage/FVUTRP3K/Adaptive Non-Stationary Kernel Regression for Terrain Modeling - Lang - 2018.pdf:application/pdf},
}

@article{paciorekNonstationaryCovarianceFunctions2004,
	title = {Nonstationary covariance functions for {Gaussian} process regression},
	url = {papers2://publication/uuid/8FEC5270-3B33-414F-9ED9-FCFAA79A56F4},
	abstract = {We introduce a class of nonstationary covariance functions for Gaussian process (GP) regression. Nonstationary covariance functions allow the model to adapt to functions whose smoothness varies with the inputs. The class includes a nonstationary version of the Matérn stationary co- variance, in which the differentiability of the regression function is con- trolled by a parameter, freeing one from fixing the differentiability in advance. In experiments, the nonstationary GP regression model per- forms well when the input space is two or three dimensions, outperform- ing a neural network model and Bayesian free-knot spline models, and competitive with a Bayesian neural network, but is outperformed in one dimension by a state-of-the-art Bayesian free-knot spline model. The model readily generalizes to non-Gaussian data. Use of computational methods for speeding GP fitting may allow for implementation of the method on larger datasets.},
	journal = {Advances in Neural Information Processing Systems},
	author = {Paciorek, C J and Schervish, M J},
	year = {2004},
	note = {ZSCC: 0000319},
	pages = {273},
	file = {Nonstationary covariance functions for Gaussian process regression - Paciorek_Schervish - 2004.pdf:/home/theo/Zotero/storage/J9CXK5RV/Nonstationary covariance functions for Gaussian process regression - Paciorek_Schervish - 2004.pdf:application/pdf},
}

@article{higdonNonstationarySpatialModeling1999,
	title = {Non-stationary spatial modeling},
	volume = {6},
	number = {1992},
	journal = {Bayesian Statistics},
	author = {Higdon, Dave and Swall, J and Kern, J},
	year = {1999},
	note = {ZSCC: 0000410},
	keywords = {markov chain, non-stationarity, spatial covariance modeling, spatial statistics},
	pages = {761--768},
	file = {Non-stationary spatial modeling - Higdon et al - 1999.pdf:/home/theo/Zotero/storage/7G5DQQM2/Non-stationary spatial modeling - Higdon et al - 1999.pdf:application/pdf},
}

@article{vonoAsymptoticallyExactData2019,
	title = {Asymptotically exact data augmentation: models, properties and algorithms},
	url = {http://arxiv.org/abs/1902.05754},
	abstract = {Data augmentation, by the introduction of auxiliary variables, has become an ubiquitous technique to improve mixing/convergence properties, simplify the implementation or reduce the computational time of inference methods such as Markov chain Monte Carlo. Nonetheless, introducing appropriate auxiliary variables while preserving the initial target probability distribution cannot be conducted in a systematic way but highly depends on the considered problem. To deal with such issues, this paper draws a unified framework, namely asymptotically exact data augmentation (AXDA), which encompasses several well-established but also more recent approximate augmented models. Benefiting from a much more general perspective, it delivers some additional qualitative and quantitative insights concerning these schemes. In particular, general properties of AXDA along with non-asymptotic theoretical results on the approximation that is made are stated. Close connections to existing Bayesian methods (e.g. mixture modeling, robust Bayesian models and approximate Bayesian computation) are also drawn. All the results are illustrated with examples and applied to standard statistical learning problems.},
	author = {Vono, Maxime and Dobigeon, Nicolas and Chainais, Pierre},
	year = {2019},
	note = {ZSCC: 0000004 
arXiv: 1902.05754},
	keywords = {approximation, auxiliary variables, bayesian inference, divide-and-conquer, ro-},
	pages = {1--48},
	file = {Asymptotically exact data augmentation - Vono et al - 2019.pdf:/home/theo/Zotero/storage/GF4QXIU2/Asymptotically exact data augmentation - Vono et al - 2019.pdf:application/pdf},
}

@article{hennigExactSamplingDeterminantal2016,
	title = {Exact {Sampling} from {Determinantal} {Point} {Processes}},
	url = {http://arxiv.org/abs/1609.06840},
	abstract = {Determinantal point processes (DPPs) are an important concept in random matrix theory and combinatorics. They have also recently attracted interest in the study of numerical methods for machine learning, as they offer an elegant "missing link" between independent Monte Carlo sampling and deterministic evaluation on regular grids, applicable to a general set of spaces. This is helpful whenever an algorithm explores to reduce uncertainty, such as in active learning, Bayesian optimization, reinforcement learning, and marginalization in graphical models. To draw samples from a DPP in practice, existing literature focuses on approximate schemes of low cost, or comparably inefficient exact algorithms like rejection sampling. We point out that, for many settings of relevance to machine learning, it is also possible to draw exact samples from DPPs on continuous domains. We start from an intuitive example on the real line, which is then generalized to multivariate real vector spaces. We also compare to previously studied approximations, showing that exact sampling, despite higher cost, can be preferable where precision is needed.},
	number = {Nips},
	author = {Hennig, Philipp and Garnett, Roman},
	year = {2016},
	note = {ZSCC: 0000008 
arXiv: 1609.06840},
	file = {Exact Sampling from Determinantal Point Processes - Hennig_Garnett - 2016.pdf:/home/theo/Zotero/storage/JJUCCWVM/Exact Sampling from Determinantal Point Processes - Hennig_Garnett - 2016.pdf:application/pdf},
}

@article{yangOnlineSparseMultiOutput2018,
	title = {Online {Sparse} {Multi}-{Output} {Gaussian} {Process} {Regression} and {Learning}},
	issn = {2373776X},
	doi = {10.1109/TSIPN.2018.2885925},
	abstract = {This paper proposes an approach for online training of a sparse multi-output Gaussian process (GP) model using sequentially obtained data. The considered model combines linearly multiple latent sparse GPs to produce correlated output variables. Each latent GP has its own set of inducing points to achieve sparsity. We show that given the model hyperparameters, the posterior over the inducing points is Gaussian under Gaussian noise since they are linearly related to the model outputs. However , the inducing points from different latent GPs would become correlated, leading to a full covariance matrix cumbersome to handle. Variational inference is thus applied and an approximate regression technique is obtained, with which the posteriors over different inducing point sets can always factorize. As the model outputs are non-linearly dependent on the hyperparameters, a novel marginalized particle filer (MPF)-based algorithm is proposed for the online inference of the inducing point values and hyperparameters. The approximate regression technique is incorporated in the MPF and its distributed realization is presented. Algorithm validation using synthetic and real data is conducted, and promising results are obtained. Index Terms-Multi-output Gaussian Processes, Sparse approximation , online regression and learning, marginalized particle filter, Kullback-Leibler divergence.},
	journal = {IEEE Transactions on Signal and Information Processing over Networks},
	author = {Yang, Le and Wang, Ke and Mihaylova, Lyudmila S.},
	year = {2018},
	note = {ZSCC: 0000004},
	keywords = {Kullback-Leibler divergence, marginalized particle filter, Multi-output Gaussian Processes, online regression and learning, Sparse approximation},
	file = {Online Sparse Multi-Output Gaussian Process Regression and Learning - Yang et al - 2018.pdf:/home/theo/Zotero/storage/U2SRLDXW/Online Sparse Multi-Output Gaussian Process Regression and Learning - Yang et al - 2018.pdf:application/pdf},
}

@article{yuanSparseposteriorGaussianProcesses2010,
	title = {Sparse-posterior {Gaussian} {Processes} for general likelihoods},
	abstract = {Gaussian processes (GPs) provide a probabilistic nonparametric representation of functions in re- gression, classification, and other problems. Un- fortunately, exact learning with GPs is intractable for large datasets. A variety of approximate GP methods have been proposed that essentially map the large dataset into a small set of basis points. Among them, two state-of-the-art methods are sparse pseudo-input Gaussian process (SPGP) (Snelson and Ghahramani, 2006) and variable- sigma GP (VSGP) Walder et al. (2008), which generalizes SPGP and allows each basis point to have its own length scale. However, VSGP was only derived for regression. In this paper, we pro- pose a new sparse GP framework that uses expec- tation propagation to directly approximate gen- eral GP likelihoods using a sparse and smooth basis. It includes both SPGP and VSGP for re- gression as special cases. Plus as an EP algo- rithm, it inherits the ability to process data on- line. As a particular choice of approximating family, we blur each basis point with a Gaus- sian distribution that has a full covariance ma- trix representing the data distribution around that basis point; as a result, we can summarize local data manifold information with a small set of ba- sis points. Our experiments demonstrate that this framework outperforms previous GP classifica- tion methods on benchmark datasets in terms of minimizing divergence to the non-sparse GP so- lution as well as lower misclassification rate.},
	journal = {Proceedings of the 26th conference on uncertainty in artificial intelligence},
	author = {{Yuan} and {Qi} and Abdel-Gawad, Ahmed H and Minka, Thomas P},
	year = {2010},
	note = {ZSCC: 0000022},
	keywords = {cs.LG, stat.ML},
	pages = {450--457},
	file = {Sparse-posterior Gaussian Processes for general likelihoods - Yuan et al - 2010.pdf:/home/theo/Zotero/storage/RYHRKRUU/Sparse-posterior Gaussian Processes for general likelihoods - Yuan et al - 2010.pdf:application/pdf},
}

@article{belabbasSpectralMethodsMachine2009,
	title = {Spectral methods in machine learning and new strategies for very large datasets},
	volume = {106},
	issn = {0027-8424},
	doi = {10.1073/pnas.0810600105},
	abstract = {Spectral methods are of fundamental importance in statistics and machine learning, because they underlie algorithms from classical principal components analysis to more recent approaches that exploit manifold structure. In most cases, the core technical problem can be reduced to computing a low-rank approximation to a positive-definite kernel. For the growing number of applications dealing with very large or high-dimensional datasets, however, the optimal approximation afforded by an exact spectral decomposition is too costly, because its complexity scales as the cube of either the number of training examples or their dimensionality. Motivated by such applications, we present here 2 new algorithms for the approximation of positive-semidefinite kernels, together with error bounds that improve on results in the literature. We approach this problem by seeking to determine, in an efficient manner, the most informative subset of our data relative to the kernel approximation task at hand. This leads to two new strategies based on the Nyström method that are directly applicable to massive datasets. The first of these-based on sampling-leads to a randomized algorithm whereupon the kernel induces a probability distribution on its set of partitions, whereas the latter approach-based on sorting-provides for the selection of a partition in a deterministic way. We detail their numerical implementation and provide simulation results for a variety of representative problems in statistical data analysis, each of which demonstrates the improved performance of our approach relative to existing methods.},
	number = {2},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Belabbas, M.-A. and Wolfe, P. J.},
	year = {2009},
	note = {ZSCC: 0000144},
	pages = {369--374},
	file = {Spectral methods in machine learning and new strategies for very large datasets - Belabbas_Wolfe - 2009.pdf:/home/theo/Zotero/storage/FK4KNHQN/Spectral methods in machine learning and new strategies for very large datasets - Belabbas_Wolfe - 2009.pdf:application/pdf},
}

@article{bijlOnlineSparseGaussian2015,
	title = {Online sparse {Gaussian} process regression using {FITC} and {PITC} approximations},
	issn = {24058963},
	doi = {10.1016/j.ifacol.2015.12.212},
	abstract = {We provide a method which allows for online updating of sparse Gaussian Process (GP) regression algorithms for any set of inducing inputs. This method is derived both for the Fully Independent Training Conditional (FITC) and the Partially Independent Training Conditional (PITC) approximation, and it allows the inclusion of a new measurement point xn+1 in O(m2) time, with m denoting the size of the set of inducing inputs. Due to the online nature of the algorithms, it is possible to forget earlier measurement data, which means that also the memory space required is O(m2), both for FITC and PITC. We show that this method is able to efficiently apply GP regression to a large data set with accurate results.},
	journal = {IFAC-PapersOnLine},
	author = {Bijl, Hildo and van Wingerden, Jan Willem and B. Schön, Thomas and Verhaegen, Michel},
	year = {2015},
	note = {ZSCC: 0000027},
}

@article{liuNonParametricVariationalInference2018,
	title = {Non-{Parametric} {Variational} {Inference} with {Graph} {Convolutional} {Networks} for {Gaussian} {Processes}},
	volume = {89},
	url = {http://arxiv.org/abs/1809.02838},
	abstract = {Inference for GP models with non-Gaussian noises is computationally expensive when dealing with large datasets. Many recent inference methods approximate the posterior distribution with a simpler distribution defined on a small number of inducing points. The inference is accurate only when data points have strong correlation with these inducing points. In this paper, we consider the inference problem in a different direction: GP function values in the posterior are mostly correlated in short distance. We construct a variational distribution such that the inference for a data point considers only its neighborhood. With this construction, the variational lower bound is highly decomposible, hence we can run stochastic optimization with very small batches. We then train Graph Convolutional Networks as a reusable model to identify variational parameters for each data point. Model reuse greatly reduces the number of parameters and the number of iterations needed in optimization. The proposed method significantly speeds up the inference and often gets more accurate results than previous methods.},
	author = {Liu, Linfeng and Liu, Liping},
	year = {2018},
	note = {ZSCC: 0000000 
arXiv: 1809.02838},
	file = {Non-Parametric Variational Inference with Graph Convolutional Networks for - Liu_Liu - 2018.pdf:/home/theo/Zotero/storage/8QNC6DPR/Non-Parametric Variational Inference with Graph Convolutional Networks for - Liu_Liu - 2018.pdf:application/pdf},
}

@article{amariFisherInformationNatural2018,
	title = {Fisher {Information} and {Natural} {Gradient} {Learning} of {Random} {Deep} {Networks}},
	volume = {89},
	url = {http://arxiv.org/abs/1808.07172},
	abstract = {A deep neural network is a hierarchical nonlinear model transforming input signals to output signals. Its input-output relation is considered to be stochastic, being described for a given input by a parameterized conditional probability distribution of outputs. The space of parameters consisting of weights and biases is a Riemannian manifold, where the metric is defined by the Fisher information matrix. The natural gradient method uses the steepest descent direction in a Riemannian manifold, so it is effective in learning, avoiding plateaus. It requires inversion of the Fisher information matrix, however, which is practically impossible when the matrix has a huge number of dimensions. Many methods for approximating the natural gradient have therefore been introduced. The present paper uses statistical neurodynamical method to reveal the properties of the Fisher information matrix in a net of random connections under the mean field approximation. We prove that the Fisher information matrix is unit-wise block diagonal supplemented by small order terms of off-block-diagonal elements, which provides a justification for the quasi-diagonal natural gradient method by Y. Ollivier. A unitwise block-diagonal Fisher metrix reduces to the tensor product of the Fisher information matrices of single units. We further prove that the Fisher information matrix of a single unit has a simple reduced form, a sum of a diagonal matrix and a rank 2 matrix of weight-bias correlations. We obtain the inverse of Fisher information explicitly. We then have an explicit form of the natural gradient, without relying on the numerical matrix inversion, which drastically speeds up stochastic gradient learning.},
	author = {Amari, Shun-ichi and Karakida, Ryo and Oizumi, Masafumi},
	year = {2018},
	note = {ZSCC: 0000011 
arXiv: 1808.07172},
	file = {Fisher Information and Natural Gradient Learning of Random Deep Networks - Amari et al - 2018.pdf:/home/theo/Zotero/storage/QKHAXGHE/Fisher Information and Natural Gradient Learning of Random Deep Networks - Amari et al - 2018.pdf:application/pdf},
}

@article{kazlauskaiteGaussianProcessLatent2018,
	title = {Gaussian {Process} {Latent} {Variable} {Alignment} {Learning}},
	volume = {89},
	url = {http://arxiv.org/abs/1803.02603},
	abstract = {We present a model that can automatically learn alignments between high-dimensional data in an unsupervised manner. Our proposed method casts alignment learning in a framework where both alignment and data are modelled simultaneously. Further, we automatically infer groupings of different types of sequences within the same dataset. We derive a probabilistic model built on non-parametric priors that allows for flexible warps while at the same time providing means to specify interpretable constraints. We demonstrate the efficacy of our approach with superior quantitative performance to the state-of-the-art approaches and provide examples to illustrate the versatility of our model in automatic inference of sequence groupings, absent from previous approaches, as well as easy specification of high level priors for different modalities of data.},
	author = {Kazlauskaite, Ieva and Ek, Carl Henrik and Campbell, Neill D. F.},
	year = {2018},
	note = {ZSCC: 0000006 
arXiv: 1803.02603},
	file = {Gaussian Process Latent Variable Alignment Learning - Kazlauskaite et al - 2018.pdf:/home/theo/Zotero/storage/43NGEGT6/Gaussian Process Latent Variable Alignment Learning - Kazlauskaite et al - 2018.pdf:application/pdf},
}

@article{Kulesza2012,
	title = {Determinantal point processes for machine learning},
	issn = {1935-8237},
	url = {http://arxiv.org/abs/1207.6083%0Ahttp://dx.doi.org/10.1561/2200000044},
	doi = {10.1561/2200000044},
	abstract = {Determinantal point processes (DPPs) are elegant probabilistic models of repulsion that arise in quantum physics and random matrix theory. In contrast to traditional structured models like Markov random fields, which become intractable and hard to approximate in the presence of negative correlations, DPPs offer efficient and exact algorithms for sampling, marginalization, conditioning, and other inference tasks. We provide a gentle introduction to DPPs, focusing on the intuitions, algorithms, and extensions that are most relevant to the machine learning community, and show how DPPs can be applied to real-world applications like finding diverse sets of high-quality search results, building informative summaries by selecting diverse sentences from documents, modeling non-overlapping human poses in images or video, and automatically building timelines of important news stories.},
	author = {Kulesza, Alex and Taskar, Ben},
	year = {2012},
	note = {ZSCC: 0000516 
arXiv: 1207.6083
ISBN: 9781601986283},
	pages = {1--120},
	file = {Kulesza and Taskar - 2012 - Determinantal point processes for machine learning.pdf:/home/theo/Zotero/storage/6GLIB227/Kulesza, Taskar - 2012 - Determinantal point processes for machine learning(2).pdf:application/pdf},
}

@article{burtRatesConvergenceSparse2019,
	title = {Rates of {Convergence} for {Sparse} {Variational} {Gaussian} {Process} {Regression}},
	url = {http://arxiv.org/abs/1903.03571},
	abstract = {Excellent variational approximations to Gaussian process posteriors have been developed which avoid the \${\textbackslash}mathcal\{O\}{\textbackslash}left(N{\textasciicircum}3{\textbackslash}right)\$ scaling with dataset size \$N\$. They reduce the computational cost to \${\textbackslash}mathcal\{O\}{\textbackslash}left(NM{\textasciicircum}2{\textbackslash}right)\$, with \$M{\textbackslash}ll N\$ being the number of inducing variables, which summarise the process. While the computational cost seems to be linear in \$N\$, the true complexity of the algorithm depends on how \$M\$ must increase to ensure a certain quality of approximation. We address this by characterising the behavior of an upper bound on the KL divergence to the posterior. We show that with high probability the KL divergence can be made arbitrarily small by growing \$M\$ more slowly than \$N\$. A particular case of interest is that for regression with normally distributed inputs in D-dimensions with the popular Squared Exponential kernel, \$M={\textbackslash}mathcal\{O\}({\textbackslash}log{\textasciicircum}D N)\$ is sufficient. Our results show that as datasets grow, Gaussian process posteriors can truly be approximated cheaply, and provide a concrete rule for how to increase \$M\$ in continual learning scenarios.},
	author = {Burt, David R. and Rasmussen, Carl E. and van der Wilk, Mark},
	year = {2019},
	note = {ZSCC: 0000024 
arXiv: 1903.03571},
	file = {Rates of Convergence for Sparse Variational Gaussian Process Regression - Burt et al - 2019.pdf:/home/theo/Zotero/storage/8DQKQGQ3/Rates of Convergence for Sparse Variational Gaussian Process Regression - Burt et al - 2019.pdf:application/pdf},
}

@article{hugginsScalableGaussianProcess2018,
	title = {Scalable {Gaussian} {Process} {Inference} with {Finite}-data {Mean} and {Variance} {Guarantees}},
	volume = {89},
	url = {http://arxiv.org/abs/1806.10234},
	abstract = {Gaussian processes (GPs) offer a flexible class of priors for nonparametric Bayesian regression, but popular GP posterior inference methods are typically prohibitively slow or lack desirable finite-data guarantees on quality. We develop an approach to scalable approximate GP regression with finite-data guarantees on the accuracy of pointwise posterior mean and variance estimates. Our main contribution is a novel objective for approximate inference in the nonparametric setting: the preconditioned Fisher (pF) divergence. We show that unlike the Kullback--Leibler divergence (used in variational inference), the pF divergence bounds the 2-Wasserstein distance, which in turn provides tight bounds the pointwise difference of the mean and variance functions. We demonstrate that, for sparse GP likelihood approximations, we can minimize the pF divergence efficiently. Our experiments show that optimizing the pF divergence has the same computational requirements as variational sparse GPs while providing comparable empirical performance--in addition to our novel finite-data quality guarantees.},
	author = {Huggins, Jonathan H. and Campbell, Trevor and Kasprzak, Mikołaj and Broderick, Tamara},
	year = {2018},
	note = {ZSCC: 0000008 
arXiv: 1806.10234},
	file = {Scalable Gaussian Process Inference with Finite-data Mean and Variance - Huggins et al - 2018.pdf:/home/theo/Zotero/storage/8AKI4J8F/Scalable Gaussian Process Inference with Finite-data Mean and Variance - Huggins et al - 2018.pdf:application/pdf},
}

@article{paananenModelSelectionGaussian2017,
	title = {Model selection for {Gaussian} processes utilizing sensitivity of posterior predictive distribution},
	volume = {89},
	url = {http://arxiv.org/abs/1712.08048},
	abstract = {We propose two novel methods for simplifying Gaussian process (GP) models by examining the predictions of a full model in the vicinity of the training points and thereby ordering the covariates based on their predictive relevance. Our results on synthetic and real world data sets demonstrate improved variable selection compared to automatic relevance determination (ARD) in terms of consistency and predictive performance. We expect our proposed methods to be useful in interpreting and understanding complex Gaussian process models.},
	author = {Paananen, Topi and Piironen, Juho and Andersen, Michael Riis and Vehtari, Aki},
	year = {2017},
	note = {ZSCC: 0000001 
arXiv: 1712.08048},
	file = {Model selection for Gaussian processes utilizing sensitivity of posterior - Paananen et al - 2017.pdf:/home/theo/Zotero/storage/M5ZUQFVU/Model selection for Gaussian processes utilizing sensitivity of posterior - Paananen et al - 2017.pdf:application/pdf},
}

@article{zheScalableHighOrderGaussian2019,
	title = {Scalable {High}-{Order} {Gaussian} {Process} {Regression}},
	volume = {89},
	author = {Zhe, Shandian and Xing, Wei and Kirby, Robert M},
	year = {2019},
	note = {ZSCC: 0000005},
	file = {PDF:/home/theo/Zotero/storage/X7UCI7RE/Zhe, Xing, Kirby - 2019 - Scalable High-Order Gaussian Process Regression(2).pdf:application/pdf},
}

@article{liImplicitKernelLearning2019,
	title = {Implicit {Kernel} {Learning}},
	volume = {89},
	url = {http://arxiv.org/abs/1902.10214},
	abstract = {Kernels are powerful and versatile tools in machine learning and statistics. Although the notion of universal kernels and characteristic kernels has been studied, kernel selection still greatly influences the empirical performance. While learning the kernel in a data driven way has been investigated, in this paper we explore learning the spectral distribution of kernel via implicit generative models parametrized by deep neural networks. We called our method Implicit Kernel Learning (IKL). The proposed framework is simple to train and inference is performed via sampling random Fourier features. We investigate two applications of the proposed IKL as examples, including generative adversarial networks with MMD (MMD GAN) and standard supervised learning. Empirically, MMD GAN with IKL outperforms vanilla predefined kernels on both image and text generation benchmarks; using IKL with Random Kitchen Sinks also leads to substantial improvement over existing state-of-the-art kernel learning algorithms on popular supervised learning benchmarks. Theory and conditions for using IKL in both applications are also studied as well as connections to previous state-of-the-art methods.},
	author = {Li, Chun-Liang and Chang, Wei-Cheng and Mroueh, Youssef and Yang, Yiming and Póczos, Barnabás},
	year = {2019},
	note = {ZSCC: 0000007 
arXiv: 1902.10214},
	file = {Implicit Kernel Learning - Li et al - 2019.pdf:/home/theo/Zotero/storage/46Q8GGDW/Implicit Kernel Learning - Li et al - 2019.pdf:application/pdf},
}

@article{shekharMultiscaleGaussianProcess2019,
	title = {Multiscale {Gaussian} {Process} {Level} {Set} {Estimation}},
	url = {http://arxiv.org/abs/1902.09682},
	abstract = {In this paper, the problem of estimating the level set of a black-box function from noisy and expensive evaluation queries is considered. A new algorithm for this problem in the Bayesian framework with a Gaussian Process (GP) prior is proposed. The proposed algorithm employs a hierarchical sequence of partitions to explore different regions of the search space at varying levels of detail depending upon their proximity to the level set boundary. It is shown that this approach results in the algorithm having a low complexity implementation whose computational cost is significantly smaller than the existing algorithms for higher dimensional search space \${\textbackslash}X\$. Furthermore, high probability bounds on a measure of discrepancy between the estimated level set and the true level set for the the proposed algorithm are obtained, which are shown to be strictly better than the existing guarantees for a large class of GPs. In the process, a tighter characterization of the information gain of the proposed algorithm is obtained which takes into account the structured nature of the evaluation points. This approach improves upon the existing technique of bounding the information gain with maximum information gain.},
	number = {2013},
	author = {Shekhar, Shubhanshu and Javidi, Tara},
	year = {2019},
	note = {ZSCC: 0000001 
arXiv: 1902.09682},
	file = {PDF:/home/theo/Zotero/storage/XDYH9VII/Shekhar, Javidi - 2019 - Multiscale Gaussian Process Level Set Estimation(2).pdf:application/pdf},
}

@book{grassmannComputationalProbability,
	title = {Computational {Probability}},
	isbn = {978-1-4419-5100-7},
	author = {Grassmann, Winfried K.},
	note = {ZSCC: 0000055},
}

@book{gelman2013bayesian,
	title = {Bayesian data analysis},
	publisher = {Chapman and Hall/CRC},
	author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
	year = {2013},
	note = {ZSCC: 0026291 },
}

@article{brooks1998general,
	title = {General methods for monitoring convergence of iterative simulations},
	volume = {7},
	number = {4},
	journal = {Journal of computational and graphical statistics},
	author = {Brooks, Stephen P and Gelman, Andrew},
	year = {1998},
	note = {ZSCC: 0004946 
Publisher: Taylor \& Francis Group},
	pages = {434--455},
}

@book{devroye1986nonuniform,
	title = {Nonuniform random variate generation},
	publisher = {Springer-Verlag},
	author = {Devroye, Luc},
	year = {1986},
	note = {ZSCC: NoCitationData[s0] },
}

@article{GProbot,
	title = {Stable {Gaussian} {Process} based {Tracking} {Control} of {Euler}-{Lagrange} {Systems}},
	number = {103},
	journal = {Automatica},
	author = {Beckers, T and Kulić, D and Hirche, S},
	year = {2019},
	note = {ZSCC: 0000012 },
	pages = {390--397},
}

@inproceedings{ge2018t,
	title = {Turing: a language for flexible probabilistic inference},
	url = {http://proceedings.mlr.press/v84/ge18b.html},
	booktitle = {International {Conference} on {Artificial} {Intelligence} and {Statistics}, \{{AISTATS}\}},
	author = {Ge, Hong and Xu, Kai and Ghahramani, Zoubin},
	year = {2018},
	note = {ZSCC: 0000033 },
	pages = {1682--1690},
}

@book{pinkus1997fourier,
	title = {Fourier series and integral transforms},
	publisher = {Cambridge University Press},
	author = {Pinkus, Allan and Zafrany, Samy},
	year = {1997},
	note = {ZSCC: 0000097 },
}

@article{mohamed2019monte,
	title = {Monte {Carlo} {Gradient} {Estimation} in {Machine} {Learning}},
	journal = {arXiv preprint arXiv:1906.10652},
	author = {Mohamed, Shakir and Rosca, Mihaela and Figurnov, Michael and Mnih, Andriy},
	year = {2019},
	note = {ZSCC: 0000024 },
}

@article{heidelberger1983simulation,
	title = {Simulation run length control in the presence of an initial transient},
	volume = {31},
	number = {6},
	journal = {Operations Research},
	author = {Heidelberger, Philip and Welch, Peter D},
	year = {1983},
	note = {ZSCC: 0001358 
Publisher: INFORMS},
	pages = {1109--1144},
}

@book{debnath2014integral,
	title = {Integral transforms and their applications},
	publisher = {Chapman and Hall/CRC},
	author = {Debnath, Lokenath and Bhatta, Dambaru},
	year = {2014},
	note = {ZSCC: 0001291 },
}

@inproceedings{wenzel2017bayesian,
	title = {Bayesian nonlinear support vector machines for big data},
	copyright = {All rights reserved},
	booktitle = {Joint {European} {Conference} on {Machine} {Learning} and {Knowledge} {Discovery} in {Databases}},
	publisher = {Springer},
	author = {Wenzel, Florian and Galy-Fajou, Théo and Deutsch, Matthäus and Kloft, Marius},
	year = {2017},
	note = {ZSCC: 0000020 },
	pages = {307--322},
}

@misc{Dua:2019,
	title = {\{{UCI}\} {Machine} {Learning} {Repository}},
	url = {http://archive.ics.uci.edu/ml},
	publisher = {University of California, Irvine, School of Information and Computer Sciences},
	author = {Dua, Dheeru and Graff, Casey},
	year = {2017},
	note = {ZSCC: 0000771 },
}

@inproceedings{minka2001expectation,
	title = {Expectation propagation for approximate {Bayesian} inference},
	booktitle = {Proceedings of the {Seventeenth} conference on {Uncertainty} in artificial intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Minka, Thomas P},
	year = {2001},
	note = {ZSCC: 0000004 },
	pages = {362--369},
}

@article{harrison1978hedonic,
	title = {Hedonic housing prices and the demand for clean air},
	volume = {5},
	number = {1},
	journal = {Journal of environmental economics and management},
	author = {Harrison Jr, David and Rubinfeld, Daniel L},
	year = {1978},
	note = {ZSCC: 0001726 
Publisher: Elsevier},
	pages = {81--102},
}

@article{ridout2009generating,
	title = {Generating random numbers from a distribution specified by its {Laplace} transform},
	volume = {19},
	number = {4},
	journal = {Statistics and Computing},
	author = {Ridout, Martin S},
	year = {2009},
	note = {ZSCC: 0000049 
Publisher: Springer},
	pages = {439},
}

@article{betancourt2017conceptual,
	title = {A conceptual introduction to {Hamiltonian} {Monte} {Carlo}},
	journal = {arXiv preprint arXiv:1701.02434},
	author = {Betancourt, Michael},
	year = {2017},
	note = {ZSCC: 0000306 },
}

@book{cohen2007numerical,
	title = {Numerical methods for {Laplace} transform inversion},
	volume = {5},
	publisher = {Springer Science \& Business Media},
	author = {Cohen, Alan M},
	year = {2007},
	note = {ZSCC: 0000404 },
}

@inproceedings{arthur2007k,
	title = {k-means++: {The} advantages of careful seeding},
	booktitle = {Proceedings of the eighteenth annual {ACM}-{SIAM} symposium on {Discrete} algorithms},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Arthur, David and Vassilvitskii, Sergei},
	year = {2007},
	note = {ZSCC: NoCitationData[s0] },
	pages = {1027--1035},
}

@article{eleftheriadis2017tip,
	title = {Gaussian {Process} {Domain} {Experts} for {Modeling} of {Facial} {Affect}},
	volume = {26},
	number = {10},
	journal = {IEEE Transactions on Image Processing},
	author = {Eleftheriadis, S and Rudovic, O and Deisenroth, M P and Pantic, M},
	year = {2017},
	note = {ZSCC: 0000011 
Publisher: IEEE},
	pages = {4697--4711},
}

@article{saemundssonMetaReinforcementLearning2018a,
	title = {Meta {Reinforcement} {Learning} with {Latent} {Variable} {Gaussian} {Processes}},
	journal = {Uncertainty in Artificial Intelligence (\{UAI\})},
	author = {Sæmundsson, Steindór and Hofmann, Katja and Deisenroth, Marc Peter},
	year = {2018},
	note = {ZSCC: 0000044},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/PRAPCYFK/1803.html:text/html;Meta Reinforcement Learning with Latent Variable Gaussian Processes - Sæmundsson et al - 2018.pdf:/home/theo/Zotero/storage/9YJQVWAI/Meta Reinforcement Learning with Latent Variable Gaussian Processes - Sæmundsson et al - 2018.pdf:application/pdf},
}

@article{hoffman2014no,
	title = {The {No}-{U}-{Turn} sampler: adaptively setting path lengths in {Hamiltonian} {Monte} {Carlo}.},
	volume = {15},
	number = {1},
	journal = {Journal of Machine Learning Research},
	author = {Hoffman, Matthew D and Gelman, Andrew},
	year = {2014},
	note = {ZSCC: 0001680 },
	pages = {1593--1623},
}

@article{mercer1909xvi,
	title = {Xvi. {Functions} of positive and negative type, and their connection the theory of integral equations},
	volume = {209},
	number = {441-458},
	journal = {Philosophical transactions of the royal society of London. Series A, containing papers of a mathematical or physical character},
	author = {Mercer, James},
	year = {1909},
	note = {ZSCC: 0002593 
Publisher: The Royal Society London},
	pages = {415--446},
}

@phdthesis{palmer2006variational,
	title = {Variational and scale mixture representations of non-{Gaussian} densities for estimation in the {Bayesian} linear model: {Sparse} coding, independent component analysis, and minimum entropy segmentation},
	school = {UC San Diego},
	author = {Palmer, Jason Allan},
	year = {2006},
	note = {ZSCC: 0000014 },
}

@article{RePEc:eee:appene:v:218:y:2018:i:c:p:159-172,
	title = {Residential probabilistic load forecasting: {A} method using {Gaussian} process designed for electric load data},
	volume = {218},
	number = {C},
	journal = {Applied Energy},
	author = {Shepero, Mahmoud and van der Meer, Dennis and Munkhammar, Joakim and Widén, Joakim},
	year = {2018},
	note = {ZSCC: 0000029 },
	pages = {159--172},
}

@incollection{abate2000introduction,
	title = {An introduction to numerical transform inversion and its application to probability models},
	booktitle = {Computational probability},
	publisher = {Springer},
	author = {Abate, Joseph and Choudhury, Gagan L and Whitt, Ward},
	year = {2000},
	note = {ZSCC: 0000261 },
	pages = {257--323},
}

@article{ranganathAdaptiveLearningRate2013,
	title = {An {Adaptive} {Learning} {Rate} for {Stochastic} {Variational} {Inference}},
	volume = {28},
	url = {http://jmlr.org/proceedings/papers/v28/ranganath13.html},
	journal = {Icml},
	author = {Ranganath, Rajesh and Wang, Chong and David, Blei and Xing, Eric},
	year = {2013},
	note = {ZSCC: 0000078},
	pages = {298--306},
	file = {An Adaptive Learning Rate for Stochastic Variational Inference - Ranganath et al - 2013.pdf:/home/theo/Zotero/storage/I4IPFIMI/An Adaptive Learning Rate for Stochastic Variational Inference - Ranganath et al - 2013.pdf:application/pdf},
}

@article{archambeauMultipleGaussianProcess2011,
	title = {Multiple {Gaussian} {Process} {Models}},
	url = {http://arxiv.org/abs/1110.5238},
	abstract = {We consider a Gaussian process formulation of the multiple kernel learning problem. The goal is to select the convex combination of kernel matrices that best explains the data and by doing so improve the generalisation on unseen data. Sparsity in the kernel weights is obtained by adopting a hierarchical Bayesian approach: Gaussian process priors are imposed over the latent functions and generalised inverse Gaussians on their associated weights. This construction is equivalent to imposing a product of heavy-tailed process priors over function space. A variational inference algorithm is derived for regression and binary classification.},
	journal = {Docmltuberlinde},
	author = {Archambeau, Cedric and Bach, Francis},
	year = {2011},
	note = {ZSCC: 0000018 
arXiv: 1110.5238},
	pages = {2--7},
	file = {Multiple Gaussian Process Models - Archambeau_Bach - 2011.pdf:/home/theo/Zotero/storage/NGANGGII/Multiple Gaussian Process Models - Archambeau_Bach - 2011.pdf:application/pdf},
}

@article{fanFastSecondOrderStochastic2015,
	title = {Fast {Second}-{Order} {Stochastic} {Backpropagation} for {Variational} {Inference}},
	url = {http://arxiv.org/abs/1509.02866},
	abstract = {We propose a second-order (Hessian or Hessian-free) based optimization method for variational inference inspired by Gaussian backpropagation, and argue that quasi-Newton optimization can be developed as well. This is accomplished by generalizing the gradient computation in stochastic backpropagation via a reparametrization trick with lower complexity. As an illustrative example, we apply this approach to the problems of Bayesian logistic regression and variational auto-encoder (VAE). Additionally, we compute bounds on the estimator variance of intractable expectations for the family of Lipschitz continuous function. Our method is practical, scalable and model free. We demonstrate our method on several real-world datasets and provide comparisons with other stochastic gradient methods to show substantial enhancement in convergence rates.},
	journal = {Nips},
	author = {Fan, Kai and Wang, Ziteng and Beck, Jeff and Kwok, James and Heller, Katherine},
	year = {2015},
	note = {ZSCC: 0000029 
arXiv: 1509.02866},
	pages = {1--10},
	file = {Fast Second-Order Stochastic Backpropagation for Variational Inference - Fan et al - 2015.pdf:/home/theo/Zotero/storage/7X4SS9ZM/Fast Second-Order Stochastic Backpropagation for Variational Inference - Fan et al - 2015.pdf:application/pdf},
}

@article{mnihNeuralVariationalInference2014,
	title = {Neural {Variational} {Inference} and {Learning} in {Belief} {Networks}},
	volume = {32},
	issn = {10636919},
	url = {http://arxiv.org/abs/1402.0030},
	doi = {10.1117/12.526813},
	abstract = {Highly expressive directed latent variable models, such as sigmoid belief networks, are difficult to train on large datasets because exact inference in them is intractable and none of the approximate inference methods that have been applied to them scale well. We propose a fast non-iterative approximate inference method that uses a feedforward network to implement efficient exact sampling from the variational posterior. The model and this inference network are trained jointly by maximizing a variational lower bound on the log-likelihood. Although the naive estimator of the inference model gradient is too high-variance to be useful, we make it practical by applying several straightforward model-independent variance reduction techniques. Applying our approach to training sigmoid belief networks and deep autoregressive networks, we show that it outperforms the wake-sleep algorithm on MNIST and achieves state-of-the-art results on the Reuters RCV1 document dataset.},
	number = {October},
	journal = {ArXiv stat.ML},
	author = {Mnih, Andriy and Gregor, Karol},
	year = {2014},
	pmid = {19273048},
	note = {ZSCC: 0000496 
arXiv: 1402.0030
ISBN: 9781634393973},
	keywords = {deep learning, belief networks, variational inference, belief networks, deep learn},
	pages = {1--20},
	file = {Neural Variational Inference and Learning in Belief Networks - Mnih_Gregor - 2014.pdf:/home/theo/Zotero/storage/KR9NW5E4/Neural Variational Inference and Learning in Belief Networks - Mnih_Gregor - 2014.pdf:application/pdf},
}

@article{sollichProbabilisticInterpretationsBayesian2005,
	title = {Probabilistic interpretations and bayesian methods for support vector machines},
	volume = {1999},
	url = {http://digital-library.theiet.org/content/conferences/10.1049/cp_19991090},
	doi = {10.1049/cp:19991090},
	abstract = {SVMs can be interpreted as MAP-solutions to inference{\textbackslash}nproblems with Gaussian Process priors. I show how this{\textbackslash}nhelps with the intuitive interpretation of SVM kernels; it{\textbackslash}nalso allows Bayesian methods to be used for SVMs (tuning{\textbackslash}nhyper-parameters by maximizing evidence, defining error{\textbackslash}nbars etc).},
	number = {46},
	journal = {9th International Conference on Artificial Neural Networks: ICANN '99},
	author = {Sollich, P.},
	year = {2005},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 0 85296 721 7},
	keywords = {bayesian inference, evidence, gaussian processes, hyperparameter tuning, probabilistic predictions, support vector machines},
	pages = {91--96},
	file = {PDF:/home/theo/Zotero/storage/Z6AYV2H9/Sollich - 2005 - Probabilistic interpretations and bayesian methods for support vector machines(2).pdf:application/pdf},
}

@book{zhengEvaluatingMachineLearning2015,
	title = {Evaluating {Machine} {Learning} {Algorithms}},
	isbn = {978-1-4919-3246-9},
	abstract = {Whenever we want to teach the computer to perform a particular task, we distinguish between two phases: training and testing. In the training phase, we feed the computer labeled examples, which the computer can use to associate patterns in the data with the output labels it needs to learn to classify . In the testing phase , we then give the computer unseen examples which it needs to classify correctly . Inourmatchmakingexamplethismeansthatthecomputerlearnstheoptimaldecisiontreeinthetrainingphaseandappliesthisdecisiontreetonew,unseenexamplesinthetestingphase.Wewouldofcourseliketomakesurethatwecanactuallycheckwhetherornotthecomputerpredictedthecorrectanswers—yesornoinourmatchmakingcase.Thismeansweneedtohavethecorrectanswersforourtestcases.Astandardwayofevaluatingmachinelearningalgorithmsisbydividingourdatasetupintoatrainingsetandatestset.Wewantthetrainingsettobesufficientlylarge,sowecanbesurethealgorithmhasseenmanydifferentexamplesandthedecisiontreeisabletogeneralizewellenough.Forexample,wecouldreserve80\%ofourdatasetfortraining,withtheremaining20\%usedfortesting.Thetrainingsetisfedtothecomputertolearnadecisiontreeon.The10\%testsetthenservesasoursetofunseenexamples.Tosimulatethatwehaveneverseentheseinstancesbefore,weactasifwedon'tknowthefinalclassification.Then,afterthecomputerhasgeneratedpredictionsforeachtestinstance,wecomparethistotheoriginallabelsweknowtobetrue.Bycheckinghowmanylabelsthealgorithmmanagedtopredictcorrectly,weareabletosaysomethingabouthowwellamachinelearningalgorithmhaslearnedthetask.},
	author = {Zheng, Alice},
	year = {2015},
	note = {ZSCC: NoCitationData[s0] 
Publication Title: Springer},
	file = {Evaluating Machine Learning Algorithms - Zheng - 2015.pdf:/home/theo/Zotero/storage/9BE4GER2/Evaluating Machine Learning Algorithms - Zheng - 2015.pdf:application/pdf},
}

@article{stanleyEvolvingNeuralNetworks2002,
	title = {Evolving neural networks through augmenting topologies},
	volume = {10},
	issn = {10636560},
	url = {http://www.mitpressjournals.org/doi/abs/10.1162/089892903321208141},
	doi = {10.1162/106365602320169811},
	abstract = {The ventral visual pathway implements object recognition and categorization in a hierarchy of processing areas with neuronal selectivities of increasing complexity. The presence of massive feedback connections within this hierarchy raises the possibility that normal visual processing relies on the use of computational loops. It is not known, however, whether object recognition can be performed at all without such loops (i.e., in a purely feed-forward mode). By analyzing the time course of reaction times in a masked natural scene categorization paradigm, we show that the human visual system can generate selective motor responses based on a single feed-forward pass. We confirm these results using a more constrained letter discrimination task, in which the rapid succession of a target and mask is actually perceived as a distractor. We show that a masked stimulus presented for only 26 msecand often not consciously perceivedcan fully determine the earliest selective motor responses: The neural representations of the stimulus and mask are thus kept separated during a short period corresponding to the feedforward sweep. Therefore, feedback loops do not appear to be mandatory for visual processing. Rather, we found that such loops allow the masked stimulus to reverberate in the visual system and affect behavior for nearly 150 msec after the feed-forward sweep.},
	number = {2},
	journal = {Evolutionary Computation},
	author = {Stanley, Kenneth O. and Miikkulainen, Risto},
	year = {2002},
	pmid = {12180173},
	note = {ZSCC: 0002752 
arXiv: 1407.0576
ISBN: 1063-6560},
	keywords = {Competing conventions, Genetic algorithms, Network topologies, Neural networks, Neuroevolution, Speciation},
	pages = {99--127},
	file = {Evolving neural networks through augmenting topologies - Stanley_Miikkulainen - 2002.pdf:/home/theo/Zotero/storage/MCY7WJ52/Evolving neural networks through augmenting topologies - Stanley_Miikkulainen - 2002.pdf:application/pdf},
}

@article{johnsonStochasticVariationalInference2014,
	title = {Stochastic {Variational} {Inference} for {Bayesian} {Time} {Series} {Models}},
	url = {http://machinelearning.wustl.edu/mlpapers/papers/icml2014c2_johnson14},
	abstract = {1) Mini-batch - set of independent series{\textbackslash}r{\textbackslash}n2) Dependencies do not need to be broken},
	journal = {Proceedings of the 31st International Conference on Machine Learning (ICML-14)},
	author = {Johnson, Matthew and Willsky, Alan},
	year = {2014},
	note = {ZSCC: 0000067 
ISBN: 9781634393973},
	pages = {1854--1862},
	file = {Stochastic Variational Inference for Bayesian Time Series Models - Johnson_Willsky - 2014.pdf:/home/theo/Zotero/storage/HBVWJFI7/Stochastic Variational Inference for Bayesian Time Series Models - Johnson_Willsky - 2014.pdf:application/pdf},
}

@article{duchiRandomizedSmoothingParallel2012,
	title = {Randomized smoothing for (parallel) stochastic optimization},
	volume = {12},
	issn = {01912216},
	url = {http://jmlr.org/papers/v12/duchi11a.html},
	doi = {10.1109/CDC.2012.6426698},
	abstract = {We analyze convergence rates of stochastic optimization procedures for non-smooth convex optimization problems. By combining randomized smoothing techniques with accelerated gradient methods, we obtain convergence rates of stochastic optimization procedures, both in expectation and with high probability, that have optimal dependence on the variance of the gradient estimates. To the best of our knowledge, these are the first variance-based rates for non-smooth optimization. We give several applications of our results to statistical estimation problems, and provide experimental results that demonstrate the effectiveness of the proposed algorithms. We also describe how a combination of our algorithm with recent work on decentralized optimization yields a distributed stochastic optimization algorithm that is order-optimal.},
	journal = {Proceedings of the IEEE Conference on Decision and Control},
	author = {Duchi, John C. and Bartlett, Peter L. and Wainwright, Martin J.},
	year = {2012},
	note = {ZSCC: 0000006 
arXiv: 1103.4296v1
ISBN: 978-1-4673-2066-5},
	keywords = {adaptivity, online learning, stochastic convex optimization, subgradient methods},
	pages = {5442--5444},
	file = {Randomized smoothing for (parallel) stochastic optimization - Duchi et al - 2012.pdf:/home/theo/Zotero/storage/7ZKNVLXP/Randomized smoothing for (parallel) stochastic optimization - Duchi et al - 2012.pdf:application/pdf},
}

@article{snelsonSparseGaussianProcesses2009,
	title = {Sparse {Gaussian} {Processes} using {Pseudo}-inputs},
	issn = {1049-5258},
	abstract = {We present a new Gaussian process (GP) regression model whose co-variance is parameterized by the the locations of M pseudo-input points, which we learn by a gradient based optimization. We take M N , where N is the number of real data points, and hence obtain a sparse regression method which has O(M 2 N) training cost and O(M 2) prediction cost per test case. We also find hyperparameters of the covari-ance function in the same joint optimization. The method can be viewed as a Bayesian regression model with particular input dependent noise. The method turns out to be closely related to several other sparse GP approaches , and we discuss the relation in detail. We finally demonstrate its performance on some large data sets, and make a direct comparison to other sparse GP methods. We show that our method can match full GP performance with small M , i.e. very sparse solutions, and it significantly outperforms other approaches in this regime.},
	journal = {Advances in Neural Information Processing Systems 18},
	author = {Snelson, Edward and Ghahramani, Zoubin},
	year = {2009},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 9780262232531},
	pages = {1--24},
	file = {Sparse Gaussian Processes using Pseudo-inputs - Snelson_Ghahramani - 2009.pdf:/home/theo/Zotero/storage/JXLZ62CG/Sparse Gaussian Processes using Pseudo-inputs - Snelson_Ghahramani - 2009.pdf:},
}

@article{bolkerMatrixCookbook2007,
	title = {Matrix {Cookbook}},
	volume = {16},
	issn = {09621083},
	doi = {10.1111/j.1365-294X.2006.03161.x},
	abstract = {These pages are a collection of facts (identities, approxima- tions, inequalities, relations, ...) about matrices and matters relating to them. It is collected in this form for the convenience of anyone who wants a quick desktop reference .},
	number = {4},
	journal = {Molecular Ecology},
	author = {Bolker, Benjamin M. and Okuyama, Toshinori and Bjorndal, Karen A. and Bolten, Alan B.},
	year = {2007},
	pmid = {17284204},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 0962-1083 (Print){\textbackslash}r0962-1083 (Linking)},
	keywords = {Bayesian hierarchical model, Chelonia mydas, Connectivity, Mixed-stock analysis, mtDNA haplotype, Spatial population structure},
	pages = {685--695},
	file = {Matrix Cookbook - Bolker et al - 2007.pdf:/home/theo/Zotero/storage/E3YNRKLJ/Matrix Cookbook - Bolker et al - 2007.pdf:application/pdf},
}

@article{sollichBayesianMethodsSupport2002,
	title = {Bayesian methods for support vector machines: {Evidence} and predictive class probabilities},
	volume = {46},
	issn = {08856125},
	doi = {10.1023/A:1012489924661},
	abstract = {I describe a framework for interpreting Support Vector Machines (SVMs) as maximum a posteriori (MAP) solutions to inference problems with Gaussian Process priors. This probabilistic interpretation can provide intuitive guidelines for choosing a 'good' SVM kernel. Beyond this, it allows Bayesian methods to be used for tackling two of the outstanding challenges in SVM classification: how to tune hyperparameters—the misclassi-fication penalty C, and any parameters specifying the kernel—and how to obtain predictive class probabilities rather than the conventional deterministic class label predictions. Hyperparameters can be set by maximizing the evidence; I explain how the latter can be defined and properly normalized. Both analytical approximations and numerical methods (Monte Carlo chaining) for estimating the evidence are discussed. I also compare different methods of estimating class probabilities, ranging from simple evaluation at the MAP or at the posterior average to full averaging over the posterior. A simple toy application illustrates the various concepts and techniques.},
	number = {1-3},
	journal = {Machine Learning},
	author = {Sollich, Peter},
	year = {2002},
	note = {ZSCC: 0000258 
ISBN: 0885-6125},
	keywords = {Gaussian processes, Bayesian inference, Evidence, Hyperparameter tuning, Probabilistic predictions, Support vector machines},
	pages = {21--52},
	file = {Bayesian methods for support vector machines - Sollich - 2002.pdf:/home/theo/Zotero/storage/S7YI4NNH/Bayesian methods for support vector machines - Sollich - 2002.pdf:application/pdf},
}

@phdthesis{galy-fajouJetReconstructionKinematic2015,
	title = {Jet {Reconstruction} and {Kinematic} {Fitting} of the {Top} {Quark} {Pair} {Production} at {CLIC} at /s = 3 {TeV}},
	abstract = {Top quark physics, due to its possible link with new physics, is a critical topic now that the Standard Model has been experimentally verified. A complete method to reconstruct top quarks pairs at the proposed Compact LInear Collider project is presented here. In this study, MC generated events of e + e ! tt have been used to tune and optimize algorithms in order to reconstruct faithfully the decay products of the top quarks. An emphasis is made on the flavour identification of the jets since it is critical to identify correctly identify the jets to remove most of the background. The reconstructed jets are fitted to the topology with the KLFitter algorithms that have been adapted for CLIC. Using a multi-variable analysis, it finds the best permutation of jets with the best set of parameters using the kinematics of the event. The results of this technique applied on a sample of 49500 e + e ! tt events (corresponding to 850 fb 1 at p s = 3 TeV) is presented here.},
	author = {Galy-Fajou, Théo},
	year = {2015},
	note = {ZSCC: 0000000},
	file = {Jet Reconstruction and Kinematic Fitting of the Top Quark Pair Production at - Galy-Fajou - 2015.pdf:/home/theo/Zotero/storage/3IBLX8PP/Jet Reconstruction and Kinematic Fitting of the Top Quark Pair Production at - Galy-Fajou - 2015.pdf:application/pdf},
}

@article{bleiVariationalInferenceIPdf2002,
	title = {Variational-{Inference}-{I}.{Pdf}},
	issn = {00237205},
	doi = {10.16373/j.cnki.ahr.150049},
	author = {Blei, David M.},
	year = {2002},
	pmid = {22352717},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1610.05683v1
ISBN: 0894-0282},
	pages = {1--12},
	file = {Variational-Inference-I - Blei - 2002.pdf:/home/theo/Zotero/storage/9S8SJU4V/Variational-Inference-I - Blei - 2002.pdf:},
}

@article{lutsMeanFieldVariational2014,
	title = {Mean field variational {Bayesian} inference for support vector machine classification},
	volume = {73},
	issn = {01679473},
	url = {http://arxiv.org/abs/1305.2667},
	doi = {10.1016/j.csda.2013.10.030},
	abstract = {A mean field variational Bayes approach to support vector machines (SVMs) using the latent variable representation on Polson and Scott (2012) is presented. This representation allows circumvention of many of the shortcomings associated with classical SVMs including automatic penalty parameter selection, the ability to handle dependent samples, missing data and variable selection. We demonstrate on simulated and real datasets that our approach is easily extendable to non-standard situations and outperforms the classical SVM approach whilst remaining computationally efficient. © 2013 Published by Elsevier B.V. All rights reserved.},
	number = {2000},
	journal = {Computational Statistics and Data Analysis},
	author = {Luts, Jan and Ormerod, John T.},
	year = {2014},
	note = {ZSCC: 0000018 
arXiv: 1305.2667},
	keywords = {Markov chain Monte Carlo, Approximate Bayesian inference, Missing data, Mixed model, Variable selection},
	pages = {163--176},
	file = {Mean field variational Bayesian inference for support vector machine - Luts_Ormerod - 2014.pdf:/home/theo/Zotero/storage/2U7IWMEB/Mean field variational Bayesian inference for support vector machine - Luts_Ormerod - 2014.pdf:application/pdf},
}

@article{bambrickSupportVectorMachines2016,
	title = {Support {Vector} {Machines} for dummies; {A} {Simple} {Explanation}},
	abstract = {In this post, we are going to introduce you to the Support Vector Machine (SVM) machine learning algorithm. We will follow a similar process to our recent post Naive Bayes for Dummies; A Simple Explanation by keeping it short and not overly-technical. The aim is to give those of you who are new to machine learning a basic understanding of the key concepts of this algorithm.},
	journal = {Aylien},
	author = {Bambrick, Noel},
	year = {2016},
	note = {ZSCC: 0000008},
	keywords = {support vector machines, S, support vector machine},
	file = {Support Vector Machines for dummies\; A Simple Explanation - Bambrick - 2016.pdf:/home/theo/Zotero/storage/7MYB3TXK/Support Vector Machines for dummies\; A Simple Explanation - Bambrick - 2016.pdf:application/pdf},
}

@article{henaoBayesianNonlinearSupport2014,
	title = {Bayesian {Nonlinear} {Support} {Vector} {Machines} and {Discriminative} {Factor} {Modeling}},
	abstract = {A new Bayesian formulation is developed for nonlinear support vector machines (SVMs), based on a Gaussian process and with the SVM hinge loss expressed as a scaled mixture of normals. We then integrate the Bayesian SVM into a factor model, in which feature learning and nonlinear classifier design are performed jointly; almost all previous work on such discriminative feature learning has as-sumed a linear classifier. Inference is performed with expectation conditional maximization (ECM) and Markov Chain Monte Carlo (MCMC). An extensive set of experiments demonstrate the utility of using a nonlinear Bayesian SVM within discriminative feature learning and factor modeling, from the standpoints of accuracy and interpretability.},
	number = {Mcmc},
	journal = {Nips},
	author = {Henao, Ricardo and Yuan, Xin and Carin, Lawrence},
	year = {2014},
	note = {ZSCC: 0000028},
	pages = {1--9},
	file = {Bayesian Nonlinear Support Vector Machines and Discriminative Factor Modeling - Henao et al - 2014.pdf:/home/theo/Zotero/storage/RQJ87LLZ/Bayesian Nonlinear Support Vector Machines and Discriminative Factor Modeling - Henao et al - 2014.pdf:application/pdf},
}

@article{kassAssesingApproximateInference2005,
	title = {Assesing {Approximate} {Inference} for {Binary} {Gaussian} {Process} {Classification}},
	volume = {6},
	issn = {1533-7928},
	url = {papers2://publication/uuid/67B9EB91-0490-49E5-8944-285FB6198997},
	doi = {10.1016/j.cmet.2012.12.017},
	abstract = {Gaussian process priors can be used to define flexible, probabilistic classification models. Unfor- tunately exact Bayesian inference is analytically intractable and various approximation techniques have been proposed. In this work we review and compare Laplace’s method and Expectation Prop- agation for approximate Bayesian inference in the binary Gaussian process classification model. We present a comprehensive comparison of the approximations, their predictive performance and marginal likelihood estimates to results obtained byMCMC sampling. We explain theoretically and corroborate empirically the advantages of Expectation Propagation compared to Laplace’s method.},
	journal = {Journal of Machine Learning Research},
	author = {Kass, Malte and Rasmussen, Carl Edward},
	year = {2005},
	pmid = {23395175},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 1532-4435},
	keywords = {probabilistic classification, gaussian process priors, s approximation, evidence, expec-, laplace, marginal likelihood, mcmc, tation propagation},
	pages = {1679--1704},
	file = {PDF:/home/theo/Zotero/storage/XV6JUXAH/Kass, Rasmussen - 2005 - Assesing Approximate Inference for Binary Gaussian Process Classification(2).pdf:application/pdf},
}

@article{osborneGaussianProcessesGlobal2009,
	title = {Gaussian {Processes} for {Global} {Optimization}},
	issn = {11698330},
	doi = {10.1016/S1169-8330(12)70063-7},
	abstract = {We introduce a novel Bayesian approach to global optimiza- tion using Gaussian processes. We frame the optimization of both noisy and noiseless functions as sequential decision problems, and introduce myopic and non-myopic solutions to them. Here our solutions can be tai- lored to exactly the degree of confidence we require of them. The use of Gaussian processes allows us to benefit from the incorporation of prior knowledge about our objective function, and also from any derivative observations. Using this latter fact, we introduce an innovative method to combat conditioning problems. Our algorithm demonstrates a signif- icant improvement over its competitors in overall performance across a wide range of canonical test problems.},
	number = {x},
	journal = {Lion '09},
	author = {Osborne, Michael A and Garnett, Roman and Roberts, Stephen J},
	year = {2009},
	note = {ZSCC: 0000221},
	keywords = {Bayesian Methods, Decision Theory, Gaussian Processes, Global Optimization, Noisy Optimization, Non-convex Optimization},
	pages = {15},
	file = {Gaussian Processes for Global Optimization - Osborne et al - 2009.pdf:/home/theo/Zotero/storage/HXDK2UIH/Gaussian Processes for Global Optimization - Osborne et al - 2009.pdf:},
}

@article{goodfellowGenerativeAdversarialNetworks2014,
	title = {Generative {Adversarial} {Networks}},
	issn = {10495258},
	url = {http://arxiv.org/abs/1406.2661},
	doi = {10.1017/CBO9781139058452},
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	journal = {arXiv preprint arXiv: …},
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	year = {2014},
	pmid = {1000183096},
	note = {ZSCC: 0000212 
arXiv: 1406.2661
ISBN: 1406.2661},
	pages = {1--9},
	file = {Generative Adversarial Networks - Goodfellow et al - 2014.pdf:/home/theo/Zotero/storage/IKIXZ7G8/Generative Adversarial Networks - Goodfellow et al - 2014.pdf:application/pdf},
}

@article{hintonImprovingNeuralNetworks2012,
	title = {Improving neural networks by preventing co-adaptation of feature detectors},
	issn = {9781467394673},
	url = {http://arxiv.org/abs/1207.0580},
	doi = {arXiv:1207.0580},
	abstract = {When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This "overfitting" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random "dropout" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.},
	journal = {ArXiv e-prints},
	author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
	year = {2012},
	pmid = {1000104337},
	note = {ZSCC: 0004899 
arXiv: 1207.0580
ISBN: 9781467394673},
	pages = {1--18},
	file = {Improving neural networks by preventing co-adaptation of feature detectors - Hinton et al - 2012.pdf:/home/theo/Zotero/storage/AKVDBXY9/Improving neural networks by preventing co-adaptation of feature detectors - Hinton et al - 2012.pdf:application/pdf},
}

@article{nealSliceSampling2003,
	title = {Slice sampling},
	volume = {31},
	issn = {00905364},
	doi = {10.1214/aos/1056562461},
	abstract = {Markov chain sampling methods that automatically adapt to characteristics of the distribution being sampled can be constructed by exploiting the principle that one can sample from a distribution by sampling uniformly from the region under the plot of its density function. A Markov chain that converges to this uniform distribution can be constructed by alternating uniform sampling in the vertical direction with uniform sampling from the horizontal `slice' defined by the current vertical position, or more generally, with some update that leaves the uniform distribution over this slice invariant. Variations on such `slice sampling' methods are easily implemented for univariate distributions, and can be used to sample from a multivariate distribution by updating each variable in turn. This approach is often easier to implement than Gibbs sampling, and more efficient than simple Metropolis updates, due to the ability of slice sampling to adaptively choose the magnitude of changes made. It is therefore attractive for routine and automated use. Slice sampling methods that update all variables simultaneously are also possible. These methods can adaptively choose the magnitudes of changes made to each variable, based on the local properties of the density function. More ambitiously, such methods could potentially allow the sampling to adapt to dependencies between variables by constructing local quadratic approximations. Another approach is to improve sampling efficiency by suppressing random walks. This can be done using `overrelaxed' versions of univariate slice sampling procedures, or by using `reflective' multivariate slice sampling methods, which bounce off the edges of the slice.},
	number = {3},
	journal = {Annals of Statistics},
	author = {Neal, Radford M.},
	year = {2003},
	note = {ZSCC: 0001947 
arXiv: 1003.3201v1
ISBN: 00905364},
	keywords = {Markov chain Monte Carlo, Adaptive methods, Auxiliary variables, Dynamical methods, Gibbs sampling, Metropolis algorithm, Overrelaxation},
	pages = {705--741},
	file = {PDF:/home/theo/Zotero/storage/U7XSEN85/Neal - 2003 - Slice sampling(2).pdf:application/pdf},
}

@article{murraySliceSamplingCovariance2010,
	title = {Slice sampling covariance hyperparameters of latent {Gaussian} models},
	volume = {2},
	url = {http://arxiv.org/abs/1006.0868},
	abstract = {The Gaussian process (GP) is a popular way to specify dependencies between random variables in a probabilistic model. In the Bayesian framework the covariance structure can be specified using unknown hyperparameters. Integrating over these hyperparameters considers different possible explanations for the data when making predictions. This integration is often performed using Markov chain Monte Carlo (MCMC) sampling. However, with non-Gaussian observations standard hyperparameter sampling approaches require careful tuning and may converge slowly. In this paper we present a slice sampling approach that requires little tuning while mixing well in both strong- and weak-data regimes.},
	number = {1},
	journal = {Advances in Neural Information Processing …},
	author = {Murray, Iain and Adams, Ryan Prescott},
	year = {2010},
	note = {ZSCC: 0000199 
arXiv: 1006.0868
ISBN: 9781617823800},
	pages = {9},
	file = {Slice sampling covariance hyperparameters of latent Gaussian models - Murray_Adams - 2010.pdf:/home/theo/Zotero/storage/DT9PUPYL/Slice sampling covariance hyperparameters of latent Gaussian models - Murray_Adams - 2010.pdf:application/pdf},
}

@article{zhangBayesianMulticategorySupport2006,
	title = {Bayesian {Multicategory} {Support} {Vector} {Machines}},
	abstract = {We show that the multi-class support vector machine (MSVM) proposed by Lee et al. (2004) can be viewed as a MAP estimation procedure under an appropriate probabilistic interpretation of the classifier. We also show that this interpretation can be extended to a hierarchical Bayesian architecture and to a fully-Bayesian inference procedure for multi-class classification based on data augmentation. We present empirical results that show that the advantages of the Bayesian formalism are obtained without a loss in classification accuracy.},
	journal = {22nd Conference on Uncertainty in Artificial Intelligence},
	author = {Zhang, Zhihua and Jordan, Michael I},
	year = {2006},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1206.6863
ISBN: 0-9749039-2-2},
	pages = {1--8},
	file = {Bayesian Multicategory Support Vector Machines - Zhang_Jordan - 2006.pdf:/home/theo/Zotero/storage/8NKDCALB/Bayesian Multicategory Support Vector Machines - Zhang_Jordan - 2006.pdf:},
}

@article{gonenBayesianEfficientMultiple2012,
	title = {Bayesian {Efficient} {Multiple} {Kernel} {Learning}},
	url = {http://arxiv.org/abs/1206.6465},
	abstract = {Multiple kernel learning algorithms are proposed to combine kernels in order to obtain a better similarity measure or to integrate feature representations coming from different data sources. Most of the previous research on such methods is focused on the computational efficiency issue. However, it is still not feasible to combine many kernels using existing Bayesian approaches due to their high time complexity. We propose a fully conjugate Bayesian formulation and derive a deterministic variational approximation, which allows us to combine hundreds or thousands of kernels very efficiently. We briefly explain how the proposed method can be extended for multiclass learning and semi-supervised learning. Experiments with large numbers of kernels on benchmark data sets show that our inference method is quite fast, requiring less than a minute. On one bioinformatics and three image recognition data sets, our method outperforms previously reported results with better generalization performance.},
	number = {1},
	journal = {Proceedings of the 29st International Conference on Machine Learning (ICML-12)},
	author = {Gonen, Mehmet},
	year = {2012},
	note = {ZSCC: 0000070 
arXiv: 1206.6465
ISBN: 978-1-4503-1285-1},
	file = {Bayesian Efficient Multiple Kernel Learning - Gonen - 2012.pdf:/home/theo/Zotero/storage/JAVVCEV6/Bayesian Efficient Multiple Kernel Learning - Gonen - 2012.pdf:application/pdf},
}

@article{Bachem2016,
	title = {Fast and {Provably} {Good} {Seedings} for k-{Means}},
	issn = {10495258},
	doi = {10.1109/tmtt.2005.863818},
	abstract = {Seeding - the task of finding initial cluster centers - is critical in obtaining high-quality clusterings for k-Means. However, k-means++ seeding, the state of the art algorithm, does not scale well to massive datasets as it is inherently sequential and requires k full passes through the data. It was recently shown that Markov chain Monte Carlo sampling can be used to efficiently approximate the seeding step of k-means++. However, this result requires assumptions on the data generating distribution. We propose a simple yet fast seeding algorithm that produces *provably* good clusterings even *without assumptions* on the data. Our analysis shows that the algorithm allows for a favourable trade-off between solution quality and computational cost, speeding up k-means++ seeding by up to several orders of magnitude. We validate our theoretical results in extensive experiments on a variety of real-world data sets.},
	number = {Nips},
	journal = {Advances in Neural Information Processing Systems 29},
	author = {Bachem, Olivier and Lucic, Mario and Hassani, S Hamed and Krause, Andreas},
	year = {2016},
	note = {ZSCC: 0000084 
ISBN: 0018-9480},
	pages = {55--63},
	file = {Fast and Provably Good Seedings for k-Means - Bachem et al - 2016.pdf:/home/theo/Zotero/storage/UQDW84V4/Fast and Provably Good Seedings for k-Means - Bachem et al - 2016.pdf:},
}

@article{zhangStochasticVariationalInference2016,
	title = {Stochastic {Variational} {Inference} for the {HDP}-{HMM}},
	abstract = {We derive a variational inference algorithm for the HDP-HMM based on the two-level stick breaking construction. This construction has pre-viously been applied to the hierarchical Dirich-let processes (HDP) for mixed membership mod-els, allowing for efficient handling of the cou-pled weight parameters. However, the same al-gorithm is not directly applicable to HDP-based infinite hidden Markov models (HDP-HMM) be-cause of extra sequential dependencies in the Markov chain. In this paper we provide a solu-tion to this problem by deriving a variational in-ference algorithm for the HDP-HMM, as well as its stochastic extension, for which all parameter updates are in closed form. We apply our algo-rithm to sequential text analysis and audio signal analysis, comparing our results with the beam-sampled iHMM, the parametric HMM, and other variational inference approximations.},
	number = {Nips},
	journal = {Proc. Artificial Intelligence and Statistics},
	author = {Zhang, Aonan and Gultekin, San and Paisley, John},
	year = {2016},
	note = {ZSCC: 0000015},
	pages = {1--3},
}

@article{lancasterSemiSupervisedLearningLadder1989,
	title = {Semi-{Supervised} {Learning} with {Ladder} {Network}},
	volume = {53},
	issn = {1098-6596},
	url = {http://ebooks.cambridge.org/ref/id/CBO9781107415324A009},
	doi = {10.1017/CBO9781107415324.004},
	abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-α-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 Å for the interface backbone atoms) increased from 21\% with default Glide SP settings to 58\% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63\% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40\% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
	journal = {Climate Change 2013 - The Physical Science Basis},
	author = {Lancaster, M},
	year = {1989},
	pmid = {25246403},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1011.1669v3
ISBN: 9788578110796},
	keywords = {icle},
	pages = {1--30},
	file = {Semi-Supervised Learning with Ladder Network - Lancaster - 1989.pdf:/home/theo/Zotero/storage/EMKLMPA9/Semi-Supervised Learning with Ladder Network - Lancaster - 1989.pdf:application/pdf},
}

@article{damianouDeepGaussianProcesses2013,
	title = {Deep {Gaussian} {Processes}},
	volume = {31},
	issn = {15337928},
	doi = {10.1002/nme.1296},
	abstract = {In this paper we introduce deep Gaussian process (GP) models. Deep GPs are a deep belief net- work based on Gaussian process mappings. The data is modeled as the output of a multivariate GP. The inputs to that Gaussian process are then governed by another GP. A single layer model is equivalent to a standard GP or the GP latent vari- able model (GP-LVM).We perform inference in the model by approximate variational marginal- ization. This results in a strict lower bound on the marginal likelihood of the model which we use for model selection (number of layers and nodes per layer). Deep belief networks are typically ap- plied to relatively large data sets using stochas- tic gradient descent for optimization. Our fully Bayesian treatment allows for the application of deep models even when data is scarce. Model se- lection by our variational bound shows that a five layer hierarchy is justified even when modelling a digit data set containing only 150 examples.},
	journal = {International Conference on Artificial Intelligence and Statistics},
	author = {Damianou, Andreas C and Lawrence, Neil D.},
	year = {2013},
	note = {ZSCC: 0000518 
arXiv: arXiv preprint arXiv:1211.0358
ISBN: 026218253X},
	pages = {207--215},
	file = {Deep Gaussian Processes - Damianou_Lawrence - 2013.pdf:/home/theo/Zotero/storage/S2CM44JN/Deep Gaussian Processes - Damianou_Lawrence - 2013.pdf:application/pdf},
}

@article{blumOptimizationGaussianProcess2013,
	title = {Optimization of {Gaussian} {Process} {Hyperparameters} using {Rprop}},
	abstract = {Gaussian processes are a powerful tool for non-parametric regression. Training can be realized by maximizing the likelihood of the data given the model. We show that Rprop, a fast and accurate gradient-based optimization technique originally designed for neural network learning, can outperform more elaborate unconstrained optimization methods on real world data sets, where it is able to converge more quickly and reliably to the optimal solution.},
	number = {x},
	journal = {European Symposium on Artificial Neural Networks Computational Intelligence and Machine Learning},
	author = {Blum, Manuel and Riedmiller, Martin},
	year = {2013},
	note = {ZSCC: 0000038 
ISBN: 9782874190810},
	keywords = {neural networks, and machine learning, available from http, belgium, bruges, com, com publ, computational intelligence, en, european symposium on artificial, gcoi, i6doc, livre, nn 2013 proceedings, optimization of gaussian process},
	pages = {24--26},
	file = {PDF:/home/theo/Zotero/storage/VFGSSCSX/Blum, Riedmiller - 2013 - Optimization of Gaussian Process Hyperparameters using Rprop(2).pdf:application/pdf},
}

@article{schaulNoMorePesky2012,
	title = {No {More} {Pesky} {Learning} {Rates}},
	volume = {28},
	issn = {1938-7228},
	url = {http://arxiv.org/abs/1206.1106},
	doi = {10.1029/2011GC003989},
	abstract = {The performance of stochastic gradient descent (SGD) depends critically on how learning rates are tuned and decreased over time. We propose a method to automatically adjust multiple learning rates so as to minimize the expected error at any one time. The method relies on local gradient variations across samples. In our approach, learning rates can increase as well as decrease, making it suitable for non-stationary problems. Using a number of convex and non-convex learning tasks, we show that the resulting algorithm matches the performance of SGD or other adaptive approaches with their best settings obtained through systematic search, and effectively removes the need for learning rate tuning.},
	number = {2},
	journal = {Icml},
	author = {Schaul, Tom and Zhang, Sixin and LeCun, Yann},
	year = {2012},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1206.1106
ISBN: 1206.1106},
	pages = {343--351},
	file = {PDF:/home/theo/Zotero/storage/WSPT6C89/Schaul, Zhang, LeCun - 2012 - No More Pesky Learning Rates(2).pdf:application/pdf},
}

@article{toussaintLectureNotesGaussian2008,
	title = {Lecture {Notes} : {Gaussian} identities},
	journal = {October},
	author = {Toussaint, Marc},
	year = {2008},
	note = {ZSCC: NoCitationData[s0]},
	pages = {1--3},
	file = {Lecture Notes - Toussaint - 2008.pdf:/home/theo/Zotero/storage/5KUW2XMW/Lecture Notes - Toussaint - 2008.pdf:application/pdf},
}

@article{naish-guzmanGeneralizedFITCApproximation2007,
	title = {The {Generalized} {FITC} {Approximation}.},
	volume = {20},
	abstract = {We present an efficient generalization of the sparse pseudo-input Gaussian process (SPGP) model developed by Snelson and Ghahramani [1], applying it to binary classification problems. By taking advantage of the SPGP prior covariance structure, we derive a numerically stable algorithm with O(NM2 ) training complexity—asymptotically the same as related sparse methods such as the informative vector machine [2], but which more faithfully represents the posterior. We present experimental results for several benchmark problems showing that in many cases this allows an exceptional degree of sparsity without compromising accuracy. Following [1], we locate pseudo-inputs by gradient ascent on the marginal likelihood, but exhibit occasions when this is likely to fail, for which we suggest alternative solutions.},
	number = {Ivm},
	journal = {Advances in Neural Information Processing Systems (NIPS)},
	author = {Naish-Guzman, a and Holden, Sb},
	year = {2007},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 160560352X},
	pages = {1--8},
	file = {The Generalized FITC Approximation - Naish-Guzman_Holden - 2007.pdf:/home/theo/Zotero/storage/42U9ZGPH/The Generalized FITC Approximation - Naish-Guzman_Holden - 2007.pdf:},
}

@article{lawrenceFastSparseGaussian2003,
	title = {Fast {Sparse} {Gaussian} {Process} {Methods}: {The} {Informative} {Vector} {Machine}},
	volume = {15},
	issn = {10495258},
	doi = {10.1073/pnas.1010647108},
	abstract = {We present a framework for sparse Gaussian process (GP) methods which uses forward selection with criteria based on informationtheoretic principles, previously suggested for active learning. Our goal is not only to learn dsparse predictors (which can be evaluated in O(d) rather than O(n), d n, n the number of training points), but also to perform training under strong restrictions on time and memory requirements. The scaling of our method is at most O(n d2), and in large real-world classi cation experiments we show that it can match prediction performance of the popular support vector machine (SVM), yet can be signi cantly faster in training. In contrast to the SVM, our approximation produces estimates of predictive probabilities (`error bars'), allows for Bayesian model selection and is less complex in implementation.},
	journal = {Advances in Neural Information Processing Systems},
	author = {Lawrence, Neil and Seeger, Matthias and Herbrich, Ralf},
	year = {2003},
	pmid = {21368163},
	note = {ZSCC: 0000558 
ISBN: 0262025507},
	pages = {609--616},
	file = {Fast Sparse Gaussian Process Methods - Lawrence et al - 2003.pdf:/home/theo/Zotero/storage/2KJ9NAW7/Fast Sparse Gaussian Process Methods - Lawrence et al - 2003.pdf:},
}

@article{Titsias2009,
	title = {Variational {Learning} of {Inducing} {Variables} in {Sparse} {Gaussian} {Processes}},
	volume = {5},
	issn = {15324435},
	url = {http://eprints.pascal-network.org/archive/00006353/},
	abstract = {Sparse Gaussian process methods that use inducing variables require the selection of the inducing inputs and the kernel hyperparameters. We introduce a variational formulation for sparse approximations that jointly infers the inducing inputs and the kernel hyperparameters by maximizing a lower bound of the true log marginal likelihood. The key property of this formulation is that the inducing inputs are defined to be variational parameters which are selected by minimizing the Kullback-Leibler divergence between the variational distribution and the exact posterior distribution over the latent function values. We apply this technique to regression and we compare it with other approaches in the literature.},
	journal = {Aistats},
	author = {Titsias, Michalis},
	year = {2009},
	note = {ZSCC: 0000724 },
	keywords = {Learning/Statistics \& Optimisation, Theory \& Algorithms},
	pages = {567--574},
	file = {Variational Learning of Inducing Variables in Sparse Gaussian Processes - Titsias - 2009.pdf:/home/theo/Zotero/storage/CYDPNW5X/Variational Learning of Inducing Variables in Sparse Gaussian Processes - Titsias - 2009.pdf:application/pdf},
}

@article{launayExactSamplingDeterminantal2018,
	title = {Exact {Sampling} of {Determinantal} {Point} {Processes} without {Eigendecomposition}},
	url = {http://arxiv.org/abs/1802.08429},
	abstract = {Determinantal point processes (DPPs) enable the modelling of repulsion: they provide diverse sets of points. This repulsion is encoded in a kernel K that we can see as a matrix storing the similarity between points. The usual algorithm to sample DPPs is exact but it uses the spectral decomposition of K, a computation that becomes costly when dealing with a high number of points. Here, we present an alternative exact algorithm that avoids the eigenvalues and the eigenvectors computation and that is, for some applications, faster than the original algorithm.},
	journal = {ArXiv e-prints},
	author = {Launay, Claire and Galerne, Bruno and Desolneux, Agnès},
	year = {2018},
	note = {ZSCC: 0000003 
arXiv: 1802.08429},
	keywords = {Statistics - Machine Learning},
	file = {Exact Sampling of Determinantal Point Processes without Eigendecomposition - Launay et al - 2018.pdf:/home/theo/Zotero/storage/DCYUPGYT/Exact Sampling of Determinantal Point Processes without Eigendecomposition - Launay et al - 2018.pdf:application/pdf},
}

@article{yaoYesDidIt2018,
	title = {Yes, but {Did} {It} {Work}?: {Evaluating} {Variational} {Inference}},
	url = {http://arxiv.org/abs/1802.02538},
	abstract = {While it's always possible to compute a variational approximation to a posterior distribution, it can be difficult to discover problems with this approximation. We propose two diagnostic algorithms to alleviate this problem. The Pareto-smoothed importance sampling (PSIS) diagnostic gives a goodness of fit measurement for joint distributions, while simultaneously improving the error in the estimate. The variational simulation-based calibration (VSBC) assesses the average performance of point estimates.},
	author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},
	year = {2018},
	note = {arXiv: 1802.02538},
	file = {Yes, but Did It Work - Yao et al - 2018.pdf:/home/theo/Zotero/storage/NV2S9RHH/Yes, but Did It Work - Yao et al - 2018.pdf:application/pdf},
}

@article{noviinverardiDiscreteDistributionsMoment2006,
	title = {Discrete distributions from moment generating function},
	volume = {182},
	issn = {00963003},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0096300306003262},
	doi = {10/dpc6k9},
	language = {en},
	number = {1},
	urldate = {2021-10-04},
	journal = {Applied Mathematics and Computation},
	author = {Novi Inverardi, P.L. and Tagliani, A.},
	month = nov,
	year = {2006},
	note = {ZSCC: 0000009},
	pages = {200--209},
	file = {Discrete distributions from moment generating function - Novi Inverardi_Tagliani - 2006.pdf:/home/theo/Zotero/storage/NXFA84BE/Discrete distributions from moment generating function - Novi Inverardi_Tagliani - 2006.pdf:application/pdf},
}

@misc{MomentGeneratingFunction,
	title = {The moment generating function has its moments - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/abs/pii/0378375886901436},
	urldate = {2021-10-04},
	file = {The moment generating function has its moments - ScienceDirect:/home/theo/Zotero/storage/6JVA26FD/0378375886901436.html:text/html},
}

@article{curtissNoteTheoryMoment1942,
	title = {A {Note} on the {Theory} of {Moment} {Generating} {Functions}},
	volume = {13},
	issn = {0003-4851},
	url = {https://www.jstor.org/stable/2235846},
	doi = {10/cgh58c},
	number = {4},
	urldate = {2021-10-04},
	journal = {The Annals of Mathematical Statistics},
	author = {Curtiss, J. H.},
	year = {1942},
	note = {ZSCC: 0000189 
Publisher: Institute of Mathematical Statistics},
	pages = {430--433},
	file = {A Note on the Theory of Moment Generating Functions - Curtiss - 1942.pdf:/home/theo/Zotero/storage/YCCLXJPR/A Note on the Theory of Moment Generating Functions - Curtiss - 1942.pdf:application/pdf;Curtiss - 1942 - A Note on the Theory of Moment Generating Function.pdf:/home/theo/Zotero/storage/BWR568NW/Curtiss - 1942 - A Note on the Theory of Moment Generating Function.pdf:application/pdf},
}

@article{virgolinoGaussianProcessesLogistic2020,
	title = {Gaussian processes with logistic mean function for modeling wind turbine power curves},
	volume = {162},
	issn = {09601481},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960148120309150},
	doi = {10/gmz5hg},
	language = {en},
	urldate = {2021-10-01},
	journal = {Renewable Energy},
	author = {Virgolino, Gustavo C.M. and Mattos, César L.C. and Magalhães, José Augusto F. and Barreto, Guilherme A.},
	month = dec,
	year = {2020},
	note = {ZSCC: 0000004},
	pages = {458--465},
}

@inproceedings{lazaro2011variational,
  title     = {Variational heteroscedastic Gaussian process regression},
  author    = {L{\'a}zaro-Gredilla, Miguel and Titsias, Michalis K},
  booktitle = {ICML},
  year      = {2011}
}

@misc{PracticalHeteroscedasticGaussian,
	title = {Practical {Heteroscedastic} {Gaussian} {Process} {Modeling} for {Large} {Simulation} {Experiments}: {Journal} of {Computational} and {Graphical} {Statistics}: {Vol} 27, {No} 4},
	url = {https://www.tandfonline.com/doi/abs/10.1080/10618600.2018.1458625?journalCode=ucgs20},
	urldate = {2021-09-24},
}

@article{zhangImprovedMostLikely2020,
	title = {Improved {Most} {Likely} {Heteroscedastic} {Gaussian} {Process} {Regression} via {Bayesian} {Residual} {Moment} {Estimator}},
	volume = {68},
	issn = {1941-0476},
	doi = {10/gmwhc2},
	abstract = {This paper proposes an improved most likely heteroscedastic Gaussian process (MLHGP) algorithm to handle a kind of nonlinear regression problems involving input-dependent noise. The improved MLHGP follows the same learning scheme as the current algorithm by use of two Gaussian processes (GPs), with the first GP for recovering the unknown function and the second GP for modeling the input-dependent noise. Unlike the current MLHGP pursuing an empirical estimate of the noise level which is provably biased in most of local noise cases, the improved algorithm gives rise to an approximately unbiased estimate of the input-dependent noise. The approximately unbiased noise estimate is elicited from Bayesian residuals by the method of moments. As a by-product of this improvement, the expectation maximization (EM)-like procedure in the current MLHGP is avoided such that the improved algorithm requires only standard GP learnings to be performed twice. Four benchmark experiments, consisting of two synthetic cases and two real-world datasets, demonstrate that the improved MLHGP algorithm outperforms the current version not only in accuracy and stability, but also in computational efficiency.},
	journal = {IEEE Transactions on Signal Processing},
	author = {Zhang, Qiu-Hu and Ni, Yi-Qing},
	year = {2020},
	note = {ZSCC: 0000006 
Conference Name: IEEE Transactions on Signal Processing},
	keywords = {Gaussian processes, Approximation algorithms, Bayes methods, Bayesian residual, Computational efficiency, Gaussian process regression, input-dependent noise, method of moments, most likely heteroscedastic Gaussian process, Noise level, Signal processing algorithms, Standards},
	pages = {3450--3460},
	file = {IEEE Xplore Abstract Record:/home/theo/Zotero/storage/XM5VJ4VJ/9103623.html:text/html;Improved Most Likely Heteroscedastic Gaussian Process Regression via Bayesian - Zhang_Ni - 2020.pdf:/home/theo/Zotero/storage/BSDBVAKD/Improved Most Likely Heteroscedastic Gaussian Process Regression via Bayesian - Zhang_Ni - 2020.pdf:application/pdf},
}

@inproceedings{leHeteroscedasticGaussianProcess2005,
	address = {Bonn, Germany},
	title = {Heteroscedastic {Gaussian} process regression},
	isbn = {978-1-59593-180-1},
	url = {http://portal.acm.org/citation.cfm?doid=1102351.1102413},
	doi = {10/bbftqs},
	abstract = {This paper presents an algorithm to estimate simultaneously both mean and variance of a non parametric regression problem. The key point is that we are able to estimate variance locally unlike standard Gaussian Process regression or SVMs. This means that our estimator adapts to the local noise. The problem is cast in the setting of maximum a posteriori estimation in exponential families. Unlike previous work, we obtain a convex optimization problem which can be solved via Newton’s method.},
	language = {en},
	urldate = {2021-09-23},
	booktitle = {Proceedings of the 22nd international conference on {Machine} learning  - {ICML} '05},
	publisher = {ACM Press},
	author = {Le, Quoc V. and Smola, Alex J. and Canu, Stéphane},
	year = {2005},
	note = {ZSCC: 0000155},
	pages = {489--496},
	file = {Le et al. - 2005 - Heteroscedastic Gaussian process regression.pdf:/home/theo/Zotero/storage/RFHPR3PY/Le et al. - 2005 - Heteroscedastic Gaussian process regression.pdf:application/pdf},
}

@article{liGaussianProcessRegression2020,
	title = {Gaussian process regression with heteroscedastic noises — {A} machine-learning predictive variance approach},
	volume = {157},
	issn = {0263-8762},
	url = {https://www.sciencedirect.com/science/article/pii/S0263876220300952},
	doi = {10/gmwhcz},
	abstract = {Gaussian process regression (GPR) is one of the most important data analytic tools in modelling processes. It has attracted increasing interest in chemical engineering applications due to its superior performance in dealing with complex modelling problems such as high-dimensional and nonlinear data. However, traditional GPR has the main limitation in that it considers an independent identically distributed (i.i.d.) noise at every sample point. Modern chemical processes typically have a more complex data structure and noise properties. The assumption of i.i.d. noise is not realistic. Thus, there is a growing interest in solving a heteroscedastic noise problem that does not satisfy the i.i.d. condition. The most common heteroscedastic noise is the noise with varying variance. This paper proposes a novel machine learning variance prediction method to solve the heteroskedastic GPR problem. By considering not only the input-dependent noise variance but also the input-output-dependent noise variance, a regression model based on support vector regression (SVR) and extreme learning machine (ELM) method is proposed for both noise variance prediction and smoothing. Compared with the existing weighted Gaussian process regression (W-GPR) of the literature, the proposed method not only expands the use of W-GPR but also improves the prediction performance of heteroscedastic GPR models. Finally, the proposed algorithm is verified by two numerical examples and tested in a real polyester polymerization process. The results all demonstrate the effectiveness of the proposed approach.},
	language = {en},
	urldate = {2021-09-23},
	journal = {Chemical Engineering Research and Design},
	author = {Li, Zhenxing and Hong, Xiaodan and Hao, Kuangrong and Chen, Lei and Huang, Biao},
	month = may,
	year = {2020},
	note = {ZSCC: 0000005},
	keywords = {Heteroscedastic Gaussian process regression, Input-output-dependent noise, The polyester polymerization process, Variance prediction model},
	pages = {162--173},
	file = {ScienceDirect Snapshot:/home/theo/Zotero/storage/BY8TMQDJ/S0263876220300952.html:text/html},
}

@inproceedings{kerstingMostLikelyHeteroscedastic2007,
	address = {New York, NY, USA},
	series = {{ICML} '07},
	title = {Most likely heteroscedastic {Gaussian} process regression},
	isbn = {978-1-59593-793-3},
	url = {https://doi.org/10.1145/1273496.1273546},
	doi = {10/fc49cc},
	abstract = {This paper presents a novel Gaussian process (GP) approach to regression with input-dependent noise rates. We follow Goldberg et al.'s approach and model the noise variance using a second GP in addition to the GP governing the noise-free output value. In contrast to Goldberg et al., however, we do not use a Markov chain Monte Carlo method to approximate the posterior noise variance but a most likely noise approach. The resulting model is easy to implement and can directly be used in combination with various existing extensions of the standard GPs such as sparse approximations. Extensive experiments on both synthetic and real-world data, including a challenging perception problem in robotics, show the effectiveness of most likely heteroscedastic GP regression.},
	urldate = {2021-09-23},
	booktitle = {Proceedings of the 24th international conference on {Machine} learning},
	publisher = {Association for Computing Machinery},
	author = {Kersting, Kristian and Plagemann, Christian and Pfaff, Patrick and Burgard, Wolfram},
	month = jun,
	year = {2007},
	note = {ZSCC: 0000324},
	pages = {393--400},
	file = {Most likely heteroscedastic Gaussian process regression - Kersting et al - 2007.pdf:/home/theo/Zotero/storage/VWN3ASWX/Most likely heteroscedastic Gaussian process regression - Kersting et al - 2007.pdf:application/pdf},
}

@article{wangGaussianProcessRegression2012,
	title = {Gaussian {Process} {Regression} with {Heteroscedastic} or {Non}-{Gaussian} {Residuals}},
	url = {http://arxiv.org/abs/1212.6246},
	abstract = {Gaussian Process (GP) regression models typically assume that residuals are Gaussian and have the same variance for all observations. However, applications with input-dependent noise (heteroscedastic residuals) frequently arise in practice, as do applications in which the residuals do not have a Gaussian distribution. In this paper, we propose a GP Regression model with a latent variable that serves as an additional unobserved covariate for the regression. This model (which we call GPLC) allows for heteroscedasticity since it allows the function to have a changing partial derivative with respect to this unobserved covariate. With a suitable covariance function, our GPLC model can handle (a) Gaussian residuals with input-dependent variance, or (b) non-Gaussian residuals with input-dependent variance, or (c) Gaussian residuals with constant variance. We compare our model, using synthetic datasets, with a model proposed by Goldberg, Williams and Bishop (1998), which we refer to as GPLV, which only deals with case (a), as well as a standard GP model which can handle only case (c). Markov Chain Monte Carlo methods are developed for both modelsl. Experiments show that when the data is heteroscedastic, both GPLC and GPLV give better results (smaller mean squared error and negative log-probability density) than standard GP regression. In addition, when the residual are Gaussian, our GPLC model is generally nearly as good as GPLV, while when the residuals are non-Gaussian, our GPLC model is better than GPLV.},
	urldate = {2021-09-23},
	journal = {arXiv:1212.6246 [cs, stat]},
	author = {Wang, Chunyi and Neal, Radford M.},
	month = dec,
	year = {2012},
	note = {ZSCC: 0000044 
arXiv: 1212.6246},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/92QQ8U9R/1212.html:text/html;Gaussian Process Regression with Heteroscedastic or Non-Gaussian Residuals - Wang_Neal - 2012.pdf:/home/theo/Zotero/storage/3AQZ6QTR/Gaussian Process Regression with Heteroscedastic or Non-Gaussian Residuals - Wang_Neal - 2012.pdf:application/pdf},
}

@article{bleiVariationalInferenceReview2017,
	title = {Variational {Inference}: {A} {Review} for {Statisticians}},
	volume = {112},
	issn = {0162-1459, 1537-274X},
	shorttitle = {Variational {Inference}},
	url = {http://arxiv.org/abs/1601.00670},
	doi = {10/gb2dc6},
	abstract = {One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.},
	number = {518},
	urldate = {2021-08-27},
	journal = {Journal of the American Statistical Association},
	author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
	month = apr,
	year = {2017},
	note = {ZSCC: 0002421 
arXiv: 1601.00670},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Computation},
	pages = {859--877},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/7ECYNTL9/1601.html:text/html;Blei et al_2017_Variational Inference.pdf:/home/theo/Zotero/storage/9GPUGSI5/Blei et al_2017_Variational Inference.pdf:application/pdf},
}

@inproceedings{knowlesNonconjugateVariationalMessage2011,
	title = {Non-conjugate {Variational} {Message} {Passing} for {Multinomial} and {Binary} {Regression}},
	volume = {24},
	url = {https://proceedings.neurips.cc/paper/2011/hash/5c936263f3428a40227908d5a3847c0b-Abstract.html},
	urldate = {2021-08-27},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Knowles, David and Minka, Tom},
	year = {2011},
	note = {ZSCC: 0000124},
	keywords = {⛔ No DOI found},
	file = {Knowles_Minka_2011_Non-conjugate Variational Message Passing for Multinomial and Binary Regression.pdf:/home/theo/Zotero/storage/93BUSAZH/Knowles_Minka_2011_Non-conjugate Variational Message Passing for Multinomial and Binary Regression.pdf:application/pdf},
}

@article{zhangTheoreticalComputationalGuarantees2020,
	title = {Theoretical and computational guarantees of mean field variational inference for community detection},
	volume = {48},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-48/issue-5/Theoretical-and-computational-guarantees-of-mean-field-variational-inference-for/10.1214/19-AOS1898.full},
	doi = {10/gmqxcs},
	abstract = {The mean field variational Bayes method is becoming increasingly popular in statistics and machine learning. Its iterative coordinate ascent variational inference algorithm has been widely applied to large scale Bayesian inference. See Blei et al. (2017) for a recent comprehensive review. Despite the popularity of the mean field method, there exist remarkably little fundamental theoretical justifications. To the best of our knowledge, the iterative algorithm has never been investigated for any high-dimensional and complex model. In this paper, we study the mean field method for community detection under the stochastic block model. For an iterative batch coordinate ascent variational inference algorithm, we show that it has a linear convergence rate and converges to the minimax rate within \${\textbackslash}log n\$ iterations. This complements the results of Bickel et al. (2013) which studied the global minimum of the mean field variational Bayes and obtained asymptotic normal estimation of global model parameters. In addition, we obtain similar optimality results for Gibbs sampling and an iterative procedure to calculate maximum likelihood estimation, which can be of independent interest.},
	number = {5},
	urldate = {2021-08-27},
	journal = {The Annals of Statistics},
	author = {Zhang, Anderson Y. and Zhou, Harrison H.},
	month = oct,
	year = {2020},
	note = {ZSCC: 0000049 
Publisher: Institute of Mathematical Statistics},
	keywords = {60G05, Bayesian, Community detection, Mean field, Stochastic block model, variational inference},
	pages = {2575--2598},
	file = {Zhang_Zhou_2020_Theoretical and computational guarantees of mean field variational inference.pdf:/home/theo/Zotero/storage/JIVZ32JL/Zhang_Zhou_2020_Theoretical and computational guarantees of mean field variational inference.pdf:application/pdf;Snapshot:/home/theo/Zotero/storage/RDE7JYUC/19-AOS1898.html:text/html},
}

@article{bickelAsymptoticNormalityMaximum2013,
	title = {Asymptotic normality of maximum likelihood and its variational approximation for stochastic blockmodels},
	volume = {41},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-41/issue-4/Asymptotic-normality-of-maximum-likelihood-and-its-variational-approximation-for/10.1214/13-AOS1124.full},
	doi = {10/gktdwh},
	abstract = {Variational methods for parameter estimation are an active research area, potentially offering computationally tractable heuristics with theoretical performance bounds. We build on recent work that applies such methods to network data, and establish asymptotic normality rates for parameter estimates of stochastic blockmodel data, by either maximum likelihood or variational estimation. The result also applies to various sub-models of the stochastic blockmodel found in the literature.},
	number = {4},
	urldate = {2021-08-27},
	journal = {The Annals of Statistics},
	author = {Bickel, Peter and Choi, David and Chang, Xiangyu and Zhang, Hai},
	month = aug,
	year = {2013},
	note = {ZSCC: 0000178 
Publisher: Institute of Mathematical Statistics},
	keywords = {62F12, maximum likelihood, Network statistics, stochastic blockmodeling, variational methods},
	pages = {1922--1943},
	file = {Snapshot:/home/theo/Zotero/storage/V2FPK4FT/13-AOS1124.html:text/html;Bickel et al_2013_Asymptotic normality of maximum likelihood and its variational approximation.pdf:/home/theo/Zotero/storage/LZM36878/Bickel et al_2013_Asymptotic normality of maximum likelihood and its variational approximation.pdf:application/pdf},
}

@article{titteringtonConvergencePropertiesGeneral2006,
	title = {Convergence properties of a general algorithm for calculating variational {Bayesian} estimates for a normal mixture model},
	volume = {1},
	issn = {1936-0975, 1931-6690},
	url = {https://projecteuclid.org/journals/bayesian-analysis/volume-1/issue-3/Convergence-properties-of-a-general-algorithm-for-calculating-variational-Bayesian/10.1214/06-BA121.full},
	doi = {10/chctfp},
	abstract = {In this paper we propose a generalised iterative algorithm for calculating variational Bayesian estimates for a normal mixture model and investigate its convergence properties. It is shown theoretically that the variational Bayesian estimator converges locally to the maximum likelihood estimator at the rate of \$O(1/\{n\})\$ in the large sample limit.},
	number = {3},
	urldate = {2021-08-27},
	journal = {Bayesian Analysis},
	author = {Titterington, D. M. and Wang, Bo},
	month = sep,
	year = {2006},
	note = {ZSCC: 0000132 
Publisher: International Society for Bayesian Analysis},
	keywords = {Laplace approximation, local convergence, mixture model, variational Bayes},
	pages = {625--650},
	file = {Snapshot:/home/theo/Zotero/storage/WKNPEELB/06-BA121.html:text/html;Titterington_Wang_2006_Convergence properties of a general algorithm for calculating variational.pdf:/home/theo/Zotero/storage/4JGRZLJL/Titterington_Wang_2006_Convergence properties of a general algorithm for calculating variational.pdf:application/pdf},
}

@article{chuEquivalenceSteinVariational2020,
	title = {The equivalence between {Stein} variational gradient descent and black-box variational inference},
	url = {http://arxiv.org/abs/2004.01822},
	abstract = {We formalize an equivalence between two popular methods for Bayesian inference: Stein variational gradient descent (SVGD) and black-box variational inference (BBVI). In particular, we show that BBVI corresponds precisely to SVGD when the kernel is the neural tangent kernel. Furthermore, we interpret SVGD and BBVI as kernel gradient flows; we do this by leveraging the recent perspective that views SVGD as a gradient flow in the space of probability distributions and showing that BBVI naturally motivates a Riemannian structure on that space. We observe that kernel gradient flow also describes dynamics found in the training of generative adversarial networks (GANs). This work thereby unifies several existing techniques in variational inference and generative modeling and identifies the kernel as a fundamental object governing the behavior of these algorithms, motivating deeper analysis of its properties.},
	urldate = {2021-08-02},
	journal = {arXiv:2004.01822 [cs, stat]},
	author = {Chu, Casey and Minami, Kentaro and Fukumizu, Kenji},
	month = apr,
	year = {2020},
	note = {ZSCC: 0000002 
arXiv: 2004.01822},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/76DCIU7F/2004.html:text/html;Chu et al_2020_The equivalence between Stein variational gradient descent and black-box.pdf:/home/theo/Zotero/storage/F8U64CXH/Chu et al_2020_The equivalence between Stein variational gradient descent and black-box.pdf:application/pdf},
}

@inproceedings{jaakkolaVariationalApproachBayesian1997,
	title = {A {Variational} {Approach} to {Bayesian} {Logistic} {Regression} {Models} and their {Extensions}},
	url = {https://proceedings.mlr.press/r1/jaakkola97a.html},
	abstract = {We consider a logistic regression model with a Gaussian prior distribution over the parameters. We show that accurate variational techniques can be used to obtain a closed form posterior distributi...},
	language = {en},
	urldate = {2021-08-30},
	booktitle = {Sixth {International} {Workshop} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Jaakkola, Tommi S. and Jordan, Michael I.},
	month = jan,
	year = {1997},
	note = {ZSCC: 0000268 
ISSN: 2640-3498},
	pages = {283--294},
	file = {Snapshot:/home/theo/Zotero/storage/53YV4Q6H/jaakkola97a.html:text/html;Jaakkola_Jordan_1997_A Variational Approach to Bayesian Logistic Regression Models and their.pdf:/home/theo/Zotero/storage/USR7X2U3/Jaakkola_Jordan_1997_A Variational Approach to Bayesian Logistic Regression Models and their.pdf:application/pdf},
}

@article{plummerDynamicsCoordinateAscent2020,
	title = {Dynamics of {Coordinate} {Ascent} {Variational} {Inference}: {A} {Case} {Study} in {2D} {Ising} {Models}},
	volume = {22},
	shorttitle = {Dynamics of {Coordinate} {Ascent} {Variational} {Inference}},
	doi = {10.3390/e22111263},
	abstract = {Variational algorithms have gained prominence over the past two decades as a scalable computational environment for Bayesian inference. In this article, we explore tools from the dynamical systems literature to study the convergence of coordinate ascent algorithms for mean field variational inference. Focusing on the Ising model defined on two nodes, we fully characterize the dynamics of the sequential coordinate ascent algorithm and its parallel version. We observe that in the regime where the objective function is convex, both the algorithms are stable and exhibit convergence to the unique fixed point. Our analyses reveal interesting discordances between these two versions of the algorithm in the region when the objective function is non-convex. In fact, the parallel version exhibits a periodic oscillatory behavior which is absent in the sequential version. Drawing intuition from the Markov chain Monte Carlo literature, we empirically show that a parameter expansion of the Ising model, popularly called the Edward–Sokal coupling, leads to an enlargement of the regime of convergence to the global optima.},
	journal = {Entropy},
	author = {Plummer, Sean and Pati, Debdeep and Bhattacharya, Anirban},
	month = nov,
	year = {2020},
	pages = {1263},
	file = {Plummer et al_2020_Dynamics of Coordinate Ascent Variational Inference.pdf:/home/theo/Zotero/storage/Z6JUSEGD/Plummer et al_2020_Dynamics of Coordinate Ascent Variational Inference.pdf:application/pdf},
}

@article{zhangTheoreticalComputationalGuarantees2020a,
	title = {Theoretical and computational guarantees of mean field variational inference for community detection},
	volume = {48},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-48/issue-5/Theoretical-and-computational-guarantees-of-mean-field-variational-inference-for/10.1214/19-AOS1898.full},
	doi = {10.1214/19-AOS1898},
	abstract = {The mean field variational Bayes method is becoming increasingly popular in statistics and machine learning. Its iterative coordinate ascent variational inference algorithm has been widely applied to large scale Bayesian inference. See Blei et al. (2017) for a recent comprehensive review. Despite the popularity of the mean field method, there exist remarkably little fundamental theoretical justifications. To the best of our knowledge, the iterative algorithm has never been investigated for any high-dimensional and complex model. In this paper, we study the mean field method for community detection under the stochastic block model. For an iterative batch coordinate ascent variational inference algorithm, we show that it has a linear convergence rate and converges to the minimax rate within \${\textbackslash}log n\$ iterations. This complements the results of Bickel et al. (2013) which studied the global minimum of the mean field variational Bayes and obtained asymptotic normal estimation of global model parameters. In addition, we obtain similar optimality results for Gibbs sampling and an iterative procedure to calculate maximum likelihood estimation, which can be of independent interest.},
	number = {5},
	urldate = {2021-08-27},
	journal = {The Annals of Statistics},
	author = {Zhang, Anderson Y. and Zhou, Harrison H.},
	month = oct,
	year = {2020},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {60G05, Bayesian, Community detection, Mean field, Stochastic block model, variational inference},
	pages = {2575--2598},
	file = {Snapshot:/home/theo/Zotero/storage/SRDE79XH/19-AOS1898.html:text/html;Zhang_Zhou_2020_Theoretical and computational guarantees of mean field variational inference.pdf:/home/theo/Zotero/storage/EWZDW4WN/Zhang_Zhou_2020_Theoretical and computational guarantees of mean field variational inference.pdf:application/pdf},
}

@incollection{kijimaGeneratingFunctionsLaplace1997,
	address = {Boston, MA},
	title = {Generating functions and {Laplace} transforms},
	isbn = {978-0-412-60660-1 978-1-4899-3132-0},
	url = {http://link.springer.com/10.1007/978-1-4899-3132-0_7},
	language = {en},
	urldate = {2021-07-22},
	booktitle = {Markov {Processes} for {Stochastic} {Modeling}},
	publisher = {Springer US},
	author = {Kijima, Masaaki},
	collaborator = {Kijima, Masaaki},
	year = {1997},
	doi = {10.1007/978-1-4899-3132-0_7},
	note = {ZSCC: 0000000 },
	pages = {303--312},
	file = {Kijima - 1997 - Generating functions and Laplace transforms.pdf:/home/theo/Zotero/storage/ANJ5U29Z/Kijima - 1997 - Generating functions and Laplace transforms.pdf:application/pdf},
}

@book{rachevMethodsDistancesTheory2013,
	address = {New York, NY},
	title = {The {Methods} of {Distances} in the {Theory} of {Probability} and {Statistics}},
	isbn = {978-1-4614-4868-6 978-1-4614-4869-3},
	url = {http://link.springer.com/10.1007/978-1-4614-4869-3},
	language = {en},
	urldate = {2021-07-22},
	publisher = {Springer New York},
	author = {Rachev, Svetlozar T. and Klebanov, Lev B. and Stoyanov, Stoyan V. and Fabozzi, Frank},
	year = {2013},
	doi = {10.1007/978-1-4614-4869-3},
	note = {ZSCC: 0000130 },
	file = {Rachev et al. - 2013 - The Methods of Distances in the Theory of Probabil.pdf:/home/theo/Zotero/storage/PTSGHKNF/Rachev et al. - 2013 - The Methods of Distances in the Theory of Probabil.pdf:application/pdf},
}

@inproceedings{arbelAnnealedFlowTransport2021,
	title = {Annealed {Flow} {Transport} {Monte} {Carlo}},
	url = {http://proceedings.mlr.press/v139/arbel21a.html},
	language = {en},
	urldate = {2021-07-22},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Arbel, Michael and Matthews, Alex and Doucet, Arnaud},
	month = jul,
	year = {2021},
	note = {ZSCC: 0000001 
ISSN: 2640-3498},
	pages = {318--330},
	file = {Annealed Flow Transport Monte Carlo - Arbel et al - 2021.pdf:/home/theo/Zotero/storage/X7NC5V4Z/Annealed Flow Transport Monte Carlo - Arbel et al - 2021.pdf:application/pdf;Annealed Flow Transport Monte Carlo - Arbel et al - 2021.pdf:/home/theo/Zotero/storage/QP9G8FD5/Annealed Flow Transport Monte Carlo - Arbel et al - 2021.pdf:application/pdf},
}

@article{prekopaRelationshipDiscreteContinuous2016,
	title = {On the relationship between the discrete and continuous bounding moment problems and their numerical solutions},
	volume = {238},
	issn = {1572-9338},
	url = {https://doi.org/10.1007/s10479-015-1995-1},
	doi = {10/f8f5zj},
	abstract = {We present a brief survey of some of the basic results related to the classical continuous moment problems (CMP) and the recently developed discrete moment problems (DMP), clarifying their relationship and propose new methods for the solution of univariate continuous and discrete power moment problems. In the classical as well as in the recently developed discrete moment problems the coefficient function in the objective is supposed to be higher order convex (in the entire interval or part of it), or constant in an interval while zero elsewhere, or equal to a constant at some point and zero elsewhere. The concept of a regenerative block (of points) is introduced, for the case of the DMP, that makes it possible to create lower and upper bounds for other functions in the objective. The CMP are solved by discretization and sequential application of dual type algorithm. Numerical results are presented with moments of order up to 40 and various applications are mentioned.},
	language = {en},
	number = {1},
	urldate = {2021-07-12},
	journal = {Annals of Operations Research},
	author = {Prékopa, András and Ninh, Anh and Alexe, Gabriela},
	month = mar,
	year = {2016},
	pages = {521--575},
	file = {On the relationship between the discrete and continuous bounding moment problems and their numerical solutions:/home/theo/Zotero/storage/M6HMSHCM/10.1007@s10479-015-1995-1.pdf:application/pdf;Prékopa et al_2016_On the relationship between the discrete and continuous bounding moment.pdf:/home/theo/Zotero/storage/J5A8CYHJ/Prékopa et al_2016_On the relationship between the discrete and continuous bounding moment.pdf:application/pdf},
}

@article{sahaNonasymptoticConvergenceCyclic2013,
	title = {On the {Nonasymptotic} {Convergence} of {Cyclic} {Coordinate} {Descent} {Methods}},
	volume = {23},
	issn = {1052-6234, 1095-7189},
	url = {http://epubs.siam.org/doi/10.1137/110840054},
	doi = {10/f4tfmd},
	abstract = {Cyclic coordinate descent is a classic optimization method that has witnessed a resurgence of interest in signal processing, statistics, and machine learning. Reasons for this renewed interest include the simplicity, speed, and stability of the method, as well as its competitive performance on 1 regularized smooth optimization problems. Surprisingly, very little is known about its nonasymptotic convergence behavior on these problems. Most existing results either just prove convergence or provide asymptotic rates. We ﬁll this gap in the literature by proving O(1/k) convergence rates (where k is the iteration count) for two variants of cyclic coordinate descent under an isotonicity assumption. Our analysis proceeds by comparing the objective values attained by the two variants with each other, as well as with the gradient descent algorithm. We show that the iterates generated by the cyclic coordinate descent methods remain better than those of gradient descent uniformly over time.},
	language = {en},
	number = {1},
	urldate = {2021-07-06},
	journal = {SIAM Journal on Optimization},
	author = {Saha, Ankan and Tewari, Ambuj},
	month = jan,
	year = {2013},
	note = {ZSCC: 0000124},
	pages = {576--601},
	file = {On the Nonasymptotic Convergence of Cyclic Coordinate Descent Methods - Saha_Tewari - 2013.pdf:/home/theo/Zotero/storage/L3333CMK/On the Nonasymptotic Convergence of Cyclic Coordinate Descent Methods - Saha_Tewari - 2013.pdf:application/pdf;On the Nonasymptotic Convergence of Cyclic Coordinate Descent Methods - Saha and Tewari - 2013 - .pdf:/home/theo/Zotero/storage/V6E4F39A/On the Nonasymptotic Convergence of Cyclic Coordinate Descent Methods - Saha and Tewari - 2013 - .pdf:application/pdf},
}

@article{nesterovEfficiencyCoordinateDescent2012,
	title = {Efficiency of {Coordinate} {Descent} {Methods} on {Huge}-{Scale} {Optimization} {Problems}},
	volume = {22},
	issn = {1052-6234},
	url = {https://epubs.siam.org/doi/abs/10.1137/100802001},
	doi = {10/f346jr},
	abstract = {In this paper we propose new methods for solving huge-scale optimization problems. For problems of this size, even the simplest full-dimensional vector operations are very expensive. Hence, we propose to apply an optimization technique based on random partial update of decision variables. For these methods, we prove the global estimates for the rate of convergence. Surprisingly, for certain classes of objective functions, our results are better than the standard worst-case bounds for deterministic algorithms. We present constrained and unconstrained versions of the method and its accelerated variant. Our numerical test confirms a high efficiency of this technique on problems of very big size.},
	number = {2},
	urldate = {2021-07-06},
	journal = {SIAM Journal on Optimization},
	author = {Nesterov, Yu.},
	month = jan,
	year = {2012},
	note = {ZSCC: 0001238 
Publisher: Society for Industrial and Applied Mathematics},
	pages = {341--362},
	file = {Efficiency of Coordinate Descent Methods on Huge-Scale Optimization Problems - Nesterov - 2012.pdf:/home/theo/Zotero/storage/5BWRZGGJ/Efficiency of Coordinate Descent Methods on Huge-Scale Optimization Problems - Nesterov - 2012.pdf:application/pdf;Snapshot:/home/theo/Zotero/storage/RPATPP4A/100802001.html:text/html;Efficiency of Coordinate Descent Methods on Huge-Scale Optimization Problems - Nesterov - 2012 - .pdf:/home/theo/Zotero/storage/WC5KSHUJ/Efficiency of Coordinate Descent Methods on Huge-Scale Optimization Problems - Nesterov - 2012 - .pdf:application/pdf},
}

@article{richtarikIterationComplexityRandomized2011,
	title = {Iteration {Complexity} of {Randomized} {Block}-{Coordinate} {Descent} {Methods} for {Minimizing} a {Composite} {Function}},
	url = {http://arxiv.org/abs/1107.2848},
	abstract = {In this paper we develop a randomized block-coordinate descent method for minimizing the sum of a smooth and a simple nonsmooth block-separable convex function and prove that it obtains an \${\textbackslash}epsilon\$-accurate solution with probability at least \$1-{\textbackslash}rho\$ in at most \$O({\textbackslash}tfrac\{n\}\{{\textbackslash}epsilon\} {\textbackslash}log {\textbackslash}tfrac\{1\}\{{\textbackslash}rho\})\$ iterations, where \$n\$ is the number of blocks. For strongly convex functions the method converges linearly. This extends recent results of Nesterov [Efficiency of coordinate descent methods on huge-scale optimization problems, CORE Discussion Paper \#2010/2], which cover the smooth case, to composite minimization, while at the same time improving the complexity by the factor of 4 and removing \${\textbackslash}epsilon\$ from the logarithmic term. More importantly, in contrast with the aforementioned work in which the author achieves the results by applying the method to a regularized version of the objective function with an unknown scaling factor, we show that this is not necessary, thus achieving true iteration complexity bounds. In the smooth case we also allow for arbitrary probability vectors and non-Euclidean norms. Finally, we demonstrate numerically that the algorithm is able to solve huge-scale \${\textbackslash}ell\_1\$-regularized least squares and support vector machine problems with a billion variables.},
	urldate = {2021-07-06},
	journal = {arXiv:1107.2848 [math, stat]},
	author = {Richtárik, Peter and Takáč, Martin},
	month = jul,
	year = {2011},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1107.2848},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found, G.1.6, Mathematics - Optimization and Control},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/GTP28BF7/1107.html:text/html;Richtárik_Takáč_2011_Iteration Complexity of Randomized Block-Coordinate Descent Methods for.pdf:/home/theo/Zotero/storage/AKXSZPQG/Richtárik_Takáč_2011_Iteration Complexity of Randomized Block-Coordinate Descent Methods for.pdf:application/pdf},
}

@article{sampsonCharacterizingExponentialFamily1975,
	title = {Characterizing {Exponential} {Family} {Distributions} by {Moment} {Generating} {Functions}},
	volume = {3},
	issn = {0090-5364},
	url = {https://www.jstor.org/stable/2958446},
	doi = {10/gg3543},
	abstract = {It is shown that if T has an unknown exponential family distribution with natural parameter θ, then G(θ) = ET uniquely specifies the moment generating function. The converse is proved, namely, if \{Tθ\} is a family of random variables with moment generating functions of a certain form, then it must be an exponential family. Moreover, several necessary and sufficient conditions are given so that a function can be the mean value function of an exponential family distribution.},
	number = {3},
	urldate = {2021-07-08},
	journal = {The Annals of Statistics},
	author = {Sampson, Allan R.},
	year = {1975},
	note = {ZSCC: 0000015 
Publisher: Institute of Mathematical Statistics},
	pages = {747--753},
	file = {Sampson_1975_Characterizing Exponential Family Distributions by Moment Generating Functions.pdf:/home/theo/Zotero/storage/9NG7IN8K/Sampson_1975_Characterizing Exponential Family Distributions by Moment Generating Functions.pdf:application/pdf},
}

@article{wrightCoordinateDescentAlgorithms2015,
	title = {Coordinate descent algorithms},
	volume = {151},
	issn = {0025-5610, 1436-4646},
	url = {http://link.springer.com/10.1007/s10107-015-0892-3},
	doi = {10/gfwqbp},
	abstract = {Coordinate descent algorithms solve optimization problems by successively performing approximate minimization along coordinate directions or coordinate hyperplanes. They have been used in applications for many years, and their popularity continues to grow because of their usefulness in data analysis, machine learning, and other areas of current interest. This paper describes the fundamentals of the coordinate descent approach, together with variants and extensions and their convergence properties, mostly with reference to convex objectives. We pay particular attention to a certain problem structure that arises frequently in machine learning applications, showing that eﬃcient implementations of accelerated coordinate descent algorithms are possible for problems of this type. We also present some parallel variants and discuss their convergence properties under several models of parallel execution.},
	language = {en},
	number = {1},
	urldate = {2021-07-06},
	journal = {Mathematical Programming},
	author = {Wright, Stephen J.},
	month = jun,
	year = {2015},
	note = {ZSCC: 0000915},
	pages = {3--34},
	file = {Coordinate descent algorithms - Wright - 2015.pdf:/home/theo/Zotero/storage/23QJIPIU/Coordinate descent algorithms - Wright - 2015.pdf:application/pdf;Coordinate descent algorithms - Wright - 2015 - .pdf:/home/theo/Zotero/storage/CD8AJKJG/Coordinate descent algorithms - Wright - 2015 - .pdf:application/pdf},
}

@article{neumanINEQUALITIESINVOLVINGLOGARITHMICALLY2006,
	title = {{INEQUALITIES} {INVOLVING} {A} {LOGARITHMICALLY} {CONVEX} {FUNCTION} {AND} {THEIR} {APPLICATIONS} {TO} {SPECIAL} {FUNCTIONS}},
	abstract = {It has been shown that if f is a differentiable, logarithmically convex function on nonnegative semi-axis, then the function [f (x)]a/f (ax), (a ≥ 1) is decreasing on its domain. Applications to inequalities involving gamma function, Riemann’s zeta function, and the complete elliptic integrals of the ﬁrst kind are included.},
	language = {en},
	author = {Neuman, Edward},
	year = {2006},
	note = {ZSCC: 0000027},
	keywords = {⛔ No DOI found},
	pages = {4},
	file = {INEQUALITIES INVOLVING A LOGARITHMICALLY CONVEX FUNCTION AND THEIR APPLICATIONS TO SPECIAL FUNCTIONS - Neuman - 2006 - .pdf:/home/theo/Zotero/storage/FV44DWIC/INEQUALITIES INVOLVING A LOGARITHMICALLY CONVEX FUNCTION AND THEIR APPLICATIONS TO SPECIAL FUNCTIONS - Neuman - 2006 - .pdf:application/pdf},
}

@article{agrawalSKIMFAKernelHighDimensional2021,
	title = {The {SKIM}-{FA} {Kernel}: {High}-{Dimensional} {Variable} {Selection} and {Nonlinear} {Interaction} {Discovery} in {Linear} {Time}},
	shorttitle = {The {SKIM}-{FA} {Kernel}},
	url = {http://arxiv.org/abs/2106.12408},
	abstract = {Many scientific problems require identifying a small set of covariates that are associated with a target response and estimating their effects. Often, these effects are nonlinear and include interactions, so linear and additive methods can lead to poor estimation and variable selection. The Bayesian framework makes it straightforward to simultaneously express sparsity, nonlinearity, and interactions in a hierarchical model. But, as for the few other methods that handle this trifecta, inference is computationally intractable - with runtime at least quadratic in the number of covariates, and often worse. In the present work, we solve this computational bottleneck. We first show that suitable Bayesian models can be represented as Gaussian processes (GPs). We then demonstrate how a kernel trick can reduce computation with these GPs to O(\# covariates) time for both variable selection and estimation. Our resulting fit corresponds to a sparse orthogonal decomposition of the regression function in a Hilbert space (i.e., a functional ANOVA decomposition), where interaction effects represent all variation that cannot be explained by lower-order effects. On a variety of synthetic and real datasets, our approach outperforms existing methods used for large, high-dimensional datasets while remaining competitive (or being orders of magnitude faster) in runtime.},
	urldate = {2021-07-01},
	journal = {arXiv:2106.12408 [stat]},
	author = {Agrawal, Raj and Broderick, Tamara},
	month = jun,
	year = {2021},
	note = {ZSCC: 0000000 
arXiv: 2106.12408},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found, Statistics - Computation, Statistics - Methodology},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/33ZSX4KD/2106.html:text/html;The SKIM-FA Kernel - Agrawal_Broderick - 2021.pdf:/home/theo/Zotero/storage/RSRH3XUY/The SKIM-FA Kernel - Agrawal_Broderick - 2021.pdf:application/pdf},
}

@article{wangVariationalInferenceNonconjugate2013,
	title = {Variational {Inference} in {Nonconjugate} {Models}},
	url = {http://arxiv.org/abs/1209.4360},
	abstract = {Mean-field variational methods are widely used for approximate posterior inference in many probabilistic models. In a typical application, mean-field methods approximately compute the posterior with a coordinate-ascent optimization algorithm. When the model is conditionally conjugate, the coordinate updates are easily derived and in closed form. However, many models of interest---like the correlated topic model and Bayesian logistic regression---are nonconjuate. In these models, mean-field methods cannot be directly applied and practitioners have had to develop variational algorithms on a case-by-case basis. In this paper, we develop two generic methods for nonconjugate models, Laplace variational inference and delta method variational inference. Our methods have several advantages: they allow for easily derived variational algorithms with a wide class of nonconjugate models; they extend and unify some of the existing algorithms that have been derived for specific models; and they work well on real-world datasets. We studied our methods on the correlated topic model, Bayesian logistic regression, and hierarchical Bayesian logistic regression.},
	urldate = {2021-06-29},
	journal = {arXiv:1209.4360 [stat]},
	author = {Wang, Chong and Blei, David M.},
	month = mar,
	year = {2013},
	note = {ZSCC: 0000220 
arXiv: 1209.4360},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/KPPFP5F9/1209.html:text/html;Wang_Blei_2013_Variational Inference in Nonconjugate Models.pdf:/home/theo/Zotero/storage/AAHFNGX4/Wang_Blei_2013_Variational Inference in Nonconjugate Models.pdf:application/pdf},
}

@article{zhangPropertiesLogconvexFunction2012,
	title = {Some properties of log-convex function and applications for the exponential function},
	doi = {10/fz34zz},
	abstract = {In this paper, some properties of log-convex function are researched, and integral inequalities of log-convex functions are proved. As an application, an estimation formula of remainder terms in Taylor series expansion is given.},
	language = {en},
	author = {Zhang, Xiaoming},
	year = {2012},
	pages = {6},
	file = {Zhang - 2012 - Some properties of log-convex function and applica.pdf:/home/theo/Zotero/storage/TRH6LQZG/Zhang - 2012 - Some properties of log-convex function and applica.pdf:application/pdf},
}

@article{cressieMOMENTGENERATINGFUNCTION,
	title = {{THE} {MOMENT} {GENERATING} {FUNCTION} {HAS} {ITS} {MOMENTS}},
	doi = {10/fs2b3n},
	abstract = {Traditionally, the moment generating function of a random variable X, is used to generate (positive integer) moments of X. However, moments of quite general transformations of X can be obtained by judicious differentiations and weighted integration of the moment generating function. The particular case of X r, - {\textasciitilde} {\textless} y {\textless} oo, is treated in detail, and applications are given.},
	language = {en},
	author = {Cressie, Noel and Borkent, Marinus},
	note = {ZSCC: 0000041},
	pages = {8},
	file = {Cressie and Borkent - THE MOMENT GENERATING FUNCTION HAS ITS MOMENTS.pdf:/home/theo/Zotero/storage/FWW3J2ST/Cressie and Borkent - THE MOMENT GENERATING FUNCTION HAS ITS MOMENTS.pdf:application/pdf},
}

@misc{PII0378375886,
	title = {{PII}: 0378-3758(86)90143-6 {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {{PII}},
	url = {https://reader.elsevier.com/reader/sd/pii/0378375886901436?token=AF7E7AC8DD92EA1884A3BBC88761D6F442B184237E17816D824D48398B5E257067F60B9BB213FD7B4CD42AEC2BE46F65&originRegion=eu-west-1&originCreation=20210628133909},
	language = {en},
	urldate = {2021-06-28},
	doi = {10.1016/0378-3758(86)90143-6},
	note = {ISSN: 0378-3758},
	file = {Snapshot:/home/theo/Zotero/storage/RVEV8JHT/0378375886901436.html:text/html},
}

@article{haberNeverLookBack2018,
	title = {Never look back - {A} modified {EnKF} method and its application to the training of neural networks without back propagation},
	url = {http://arxiv.org/abs/1805.08034},
	abstract = {In this work, we present a new derivative-free optimization method and investigate its use for training neural networks. Our method is motivated by the Ensemble Kalman Filter (EnKF), which has been used successfully for solving optimization problems that involve large-scale, highly nonlinear dynamical systems. A key benefit of the EnKF method is that it requires only the evaluation of the forward propagation but not its derivatives. Hence, in the context of neural networks, it alleviates the need for back propagation and reduces the memory consumption dramatically. However, the method is not a pure "black-box" global optimization heuristic as it efficiently utilizes the structure of typical learning problems. Promising first results of the EnKF for training deep neural networks have been presented recently by Kovachki and Stuart. We propose an important modification of the EnKF that enables us to prove convergence of our method to the minimizer of a strongly convex function. Our method also bears similarity with implicit filtering and we demonstrate its potential for minimizing highly oscillatory functions using a simple example. Further, we provide numerical examples that demonstrate the potential of our method for training deep neural networks.},
	urldate = {2021-06-15},
	journal = {arXiv:1805.08034 [cs, math]},
	author = {Haber, Eldad and Lucka, Felix and Ruthotto, Lars},
	month = may,
	year = {2018},
	note = {ZSCC: 0000011 
arXiv: 1805.08034},
	keywords = {⛔ No DOI found, Computer Science - Machine Learning, 65K10, 65M32, Computer Science - Neural and Evolutionary Computing, Mathematics - Numerical Analysis},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/DSXUN7TT/1805.html:text/html;Haber et al_2018_Never look back - A modified EnKF method and its application to the training of.pdf:/home/theo/Zotero/storage/7XHUI5X6/Haber et al_2018_Never look back - A modified EnKF method and its application to the training of.pdf:application/pdf},
}

@inproceedings{chenApproximateBayesianNeural2019,
	title = {Approximate {Bayesian} {Neural} {Network} {Trained} with {Ensemble} {Kalman} {Filter}},
	doi = {10/gksntr},
	abstract = {Neural networks have achieved significant success in many areas. Nevertheless, conventional neural networks lack uncertainty information, which plays an important role especially in critical-safety applications such as self-driving cars. When uncertainty is characterized using probability the main modeling approach is the construction of Bayesian neural networks. Obtaining the posterior distribution for these models is computationally intensive and analytical solutions are intractable. In this work, we propose a novel algorithm to infer the weights for Bayesian neural networks based on the ensemble Kalman filter. To evaluate the performance of the algorithm, we use ten regression datasets from University of California at Irvine machine learning repository, and a natural language dataset. The results suggest that EnKF can be used as a gradient-free alternative to training deep neural networks to capture prediction uncertainty.},
	booktitle = {2019 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Chen, Chao and Lin, Xiao and Huang, Yuan and Terejanu, Gabriel},
	month = jul,
	year = {2019},
	note = {ZSCC: 0000001 
ISSN: 2161-4407},
	keywords = {Neural networks, Approximation algorithms, Bayes methods, Kalman filters, Noise measurement, Training, Uncertainty},
	pages = {1--8},
	file = {Approximate Bayesian Neural Network Trained with Ensemble Kalman Filter - Chen et al - 2019.pdf:/home/theo/Zotero/storage/3Z5US3EI/Approximate Bayesian Neural Network Trained with Ensemble Kalman Filter - Chen et al - 2019.pdf:application/pdf;IEEE Xplore Abstract Record:/home/theo/Zotero/storage/M6TQ8WL6/8851742.html:text/html},
}

@article{kovachkiEnsembleKalmanInversion2019,
	title = {Ensemble {Kalman} {Inversion}: {A} {Derivative}-{Free} {Technique} {For} {Machine} {Learning} {Tasks}},
	volume = {35},
	issn = {0266-5611, 1361-6420},
	shorttitle = {Ensemble {Kalman} {Inversion}},
	url = {http://arxiv.org/abs/1808.03620},
	doi = {10/ggktsv},
	abstract = {The standard probabilistic perspective on machine learning gives rise to empirical risk-minimization tasks that are frequently solved by stochastic gradient descent (SGD) and variants thereof. We present a formulation of these tasks as classical inverse or filtering problems and, furthermore, we propose an efficient, gradient-free algorithm for finding a solution to these problems using ensemble Kalman inversion (EKI). Applications of our approach include offline and online supervised learning with deep neural networks, as well as graph-based semi-supervised learning. The essence of the EKI procedure is an ensemble based approximate gradient descent in which derivatives are replaced by differences from within the ensemble. We suggest several modifications to the basic method, derived from empirically successful heuristics developed in the context of SGD. Numerical results demonstrate wide applicability and robustness of the proposed algorithm.},
	number = {9},
	urldate = {2021-06-15},
	journal = {Inverse Problems},
	author = {Kovachki, Nikola B. and Stuart, Andrew M.},
	month = sep,
	year = {2019},
	note = {ZSCC: 0000046 
arXiv: 1808.03620},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Mathematics - Optimization and Control, 68T20, 65L09, 65K10, 49M15, I.2.6},
	pages = {095005},
	file = {Ensemble Kalman Inversion - Kovachki_Stuart - 2019.pdf:/home/theo/Zotero/storage/P2DK3K9A/Ensemble Kalman Inversion - Kovachki_Stuart - 2019.pdf:application/pdf;arXiv.org Snapshot:/home/theo/Zotero/storage/ECMC7MZ6/1808.html:text/html;Kovachki_Stuart_2019_Ensemble Kalman Inversion.pdf:/home/theo/Zotero/storage/87G64D3R/Kovachki_Stuart_2019_Ensemble Kalman Inversion.pdf:application/pdf},
}

@misc{MachineLearningCommentKkastner,
	title = {r/{MachineLearning} - {Comment} by u/kkastner on ”{AMA} {Geoffrey} {Hinton}”},
	url = {https://www.reddit.com/r/MachineLearning/comments/2lmo0l/ama_geoffrey_hinton/clwbnmg},
	abstract = {374 votes et 256 commentaires sur Reddit jusque là},
	language = {fr-FR},
	urldate = {2021-06-22},
	journal = {reddit},
	file = {Snapshot:/home/theo/Zotero/storage/QU89CPB3/clwbnmg.html:text/html},
}

@article{wildConnectionsEquivalencesNystr2021,
	title = {Connections and {Equivalences} between the {Nystr}{\textbackslash}"om {Method} and {Sparse} {Variational} {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/2106.01121},
	abstract = {We investigate the connections between sparse approximation methods for making kernel methods and Gaussian processes (GPs) scalable to massive data, focusing on the Nystr{\textbackslash}"om method and the Sparse Variational Gaussian Processes (SVGP). While sparse approximation methods for GPs and kernel methods share some algebraic similarities, the literature lacks a deep understanding of how and why they are related. This is a possible obstacle for the communications between the GP and kernel communities, making it difficult to transfer results from one side to the other. Our motivation is to remove this possible obstacle, by clarifying the connections between the sparse approximations for GPs and kernel methods. In this work, we study the two popular approaches, the Nystr{\textbackslash}"om and SVGP approximations, in the context of a regression problem, and establish various connections and equivalences between them. In particular, we provide an RKHS interpretation of the SVGP approximation, and show that the Evidence Lower Bound of the SVGP contains the objective function of the Nystr{\textbackslash}"om approximation, revealing the origin of the algebraic equivalence between the two approaches. We also study recently established convergence results for the SVGP and how they are related to the approximation quality of the Nystr{\textbackslash}"om method.},
	urldate = {2021-06-03},
	journal = {arXiv:2106.01121 [cs, math, stat]},
	author = {Wild, Veit and Kanagawa, Motonobu and Sejdinovic, Dino},
	month = jun,
	year = {2021},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 2106.01121},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found, Computer Science - Machine Learning, Statistics - Methodology, Mathematics - Statistics Theory},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/4NFW5VXU/2106.html:text/html;Wild et al_2021_Connections and Equivalences between the Nystr-om Method and Sparse.pdf:/home/theo/Zotero/storage/XVVBFZT2/Wild et al_2021_Connections and Equivalences between the Nystr-om Method and Sparse.pdf:application/pdf},
}

@article{mishkinSLANGFastStructured2019,
	title = {{SLANG}: {Fast} {Structured} {Covariance} {Approximations} for {Bayesian} {Deep} {Learning} with {Natural} {Gradient}},
	shorttitle = {{SLANG}},
	url = {http://arxiv.org/abs/1811.04504},
	abstract = {Uncertainty estimation in large deep-learning models is a computationally challenging task, where it is difficult to form even a Gaussian approximation to the posterior distribution. In such situations, existing methods usually resort to a diagonal approximation of the covariance matrix despite, the fact that these matrices are known to result in poor uncertainty estimates. To address this issue, we propose a new stochastic, low-rank, approximate natural-gradient (SLANG) method for variational inference in large, deep models. Our method estimates a "diagonal plus low-rank" structure based solely on back-propagated gradients of the network log-likelihood. This requires strictly less gradient computations than methods that compute the gradient of the whole variational objective. Empirical evaluations on standard benchmarks confirm that SLANG enables faster and more accurate estimation of uncertainty than mean-field methods, and performs comparably to state-of-the-art methods.},
	language = {en},
	urldate = {2021-05-21},
	journal = {arXiv:1811.04504 [cs, stat]},
	author = {Mishkin, Aaron and Kunstner, Frederik and Nielsen, Didrik and Schmidt, Mark and Khan, Mohammad Emtiyaz},
	month = jan,
	year = {2019},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1811.04504},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	pages = {11},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/LQT8DZG7/1811.html:text/html;SLANG - Mishkin et al - 2019.pdf:/home/theo/Zotero/storage/7L9VWRTC/SLANG - Mishkin et al - 2019.pdf:application/pdf;SLANG - Mishkin et al -.pdf:/home/theo/Zotero/storage/4T7BYBE8/SLANG - Mishkin et al -.pdf:application/pdf},
}

@article{tomczakEfficientLowRank,
	title = {Efﬁcient {Low} {Rank} {Gaussian} {Variational} {Inference} for {Neural} {Networks}},
	abstract = {Bayesian neural networks are enjoying a renaissance driven in part by recent advances in variational inference (VI). The most common form of VI employs a fully factorized or mean-ﬁeld distribution, but this is known to suffer from several pathologies, especially as we expect posterior distributions with highly correlated parameters. Current algorithms that capture these correlations with a Gaussian approximating family are difﬁcult to scale to large models due to computational costs and high variance of gradient updates. By using a new form of the reparametrization trick, we derive a computationally efﬁcient algorithm for performing VI with a Gaussian family with a low-rank plus diagonal covariance structure. We scale to deep feed-forward and convolutional architectures. We ﬁnd that adding low-rank terms to parametrized diagonal covariance does not improve predictive performance except on small networks, but low-rank terms added to a constant diagonal covariance improves performance on small and large-scale network architectures.},
	language = {en},
	author = {Tomczak, Marcin B and Swaroop, Siddharth and Turner, Richard E},
	note = {ZSCC: 0000001},
	keywords = {⛔ No DOI found},
	pages = {13},
	file = {Tomczak et al. - Efﬁcient Low Rank Gaussian Variational Inference f.pdf:/home/theo/Zotero/storage/CEP3SMFX/Tomczak et al. - Efﬁcient Low Rank Gaussian Variational Inference f.pdf:application/pdf},
}

@article{lazaro-gredillaMarginalizedNeuralNetwork2010,
	title = {Marginalized neural network mixtures for large-scale regression},
	volume = {21},
	issn = {1045-9227},
	url = {https://doi.org/10.1109/TNN.2010.2049859},
	doi = {10/dn2xrg},
	abstract = {For regression tasks, traditional neural networks (NNs) have been superseded by Gaussian processes, which provide probabilistic predictions (input-dependent error bars), improved accuracy, and virtually no overfitting. Due to their high computational cost, in scenarios with massive data sets, one has to resort to sparse Gaussian processes, which strive to achieve similar performance with much smaller computational effort. In this context, we introduce a mixture of NNs with marginalized output weights that can both provide probabilistic predictions and improve on the performance of sparse Gaussian processes, at the same computational cost. The effectiveness of this approach is shown experimentally on some representative large data sets.},
	number = {8},
	urldate = {2021-05-21},
	journal = {IEEE Transactions on Neural Networks},
	author = {Lázaro-Gredilla, Miguel and Figueiras-Vidal, Aníbal R.},
	month = aug,
	year = {2010},
	note = {ZSCC: 0000025},
	keywords = {Gaussian processes, regression, gaussian processes, Bayesian models, large data sets, multilayer perceptrons},
	pages = {1345--1351},
	file = {Marginalized neural network mixtures for large-scale regression - Lázaro-Gredilla_Figueiras-Vidal - 2010.pdf:/home/theo/Zotero/storage/7KMUBA73/Marginalized neural network mixtures for large-scale regression - Lázaro-Gredilla_Figueiras-Vidal - 2010.pdf:application/pdf},
}

@article{watsonLatentDerivativeBayesian,
	title = {Latent {Derivative} {Bayesian} {Last} {Layer} {Networks}},
	abstract = {Bayesian neural networks (BNN) are powerful parametric models for nonlinear regression with uncertainty quantiﬁcation. However, the approximate inference techniques for weight space priors suﬀer from several drawbacks. The ‘Bayesian last layer’ (BLL) is an alternative BNN approach that learns the feature space for an exact Bayesian linear model with explicit predictive distributions. However, its predictions outside of the data distribution (OOD) are typically overconﬁdent, as the marginal likelihood objective results in a learned feature space that overﬁts to the data. We overcome this weakness by introducing a functional prior on the model’s derivatives w.r.t. the inputs. Treating these Jacobians as latent variables, we incorporate the prior into the objective to inﬂuence the smoothness and diversity of the features, which enables greater predictive uncertainty. For the BLL, the Jacobians can be computed directly using forward mode automatic diﬀerentiation, and the distribution over Jacobians may be obtained in closed-form. We demonstrate this method enhances the BLL to Gaussian process-like performance on tasks where calibrated uncertainty is critical: OOD regression, Bayesian optimization and active learning, which include high-dimensional real-world datasets.},
	language = {en},
	author = {Watson, Joe and Lin, Jihao Andreas and Klink, Pascal and Pajarinen, Joni and Peters, Jan},
	note = {ZSCC: 0000000},
	keywords = {⛔ No DOI found},
	pages = {13},
	file = {Watson et al. - Latent Derivative Bayesian Last Layer Networks.pdf:/home/theo/Zotero/storage/BVRSM2UV/Watson et al. - Latent Derivative Bayesian Last Layer Networks.pdf:application/pdf},
}

@article{brosseLastLayerAlgorithmsClassification2020,
	title = {On {Last}-{Layer} {Algorithms} for {Classification}: {Decoupling} {Representation} from {Uncertainty} {Estimation}},
	shorttitle = {On {Last}-{Layer} {Algorithms} for {Classification}},
	url = {http://arxiv.org/abs/2001.08049},
	abstract = {Uncertainty quantification for deep learning is a challenging open problem. Bayesian statistics offer a mathematically grounded framework to reason about uncertainties; however, approximate posteriors for modern neural networks still require prohibitive computational costs. We propose a family of algorithms which split the classification task into two stages: representation learning and uncertainty estimation. We compare four specific instances, where uncertainty estimation is performed via either an ensemble of Stochastic Gradient Descent or Stochastic Gradient Langevin Dynamics snapshots, an ensemble of bootstrapped logistic regressions, or via a number of Monte Carlo Dropout passes. We evaluate their performance in terms of {\textbackslash}emph\{selective\} classification (risk-coverage), and their ability to detect out-of-distribution samples. Our experiments suggest there is limited value in adding multiple uncertainty layers to deep classifiers, and we observe that these simple methods strongly outperform a vanilla point-estimate SGD in some complex benchmarks like ImageNet.},
	urldate = {2021-05-21},
	journal = {arXiv:2001.08049 [cs, stat]},
	author = {Brosse, Nicolas and Riquelme, Carlos and Martin, Alice and Gelly, Sylvain and Moulines, Éric},
	month = jan,
	year = {2020},
	note = {ZSCC: 0000002 
arXiv: 2001.08049},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/C4F8YUPS/2001.html:text/html;On Last-Layer Algorithms for Classification - Brosse et al - 2020.pdf:/home/theo/Zotero/storage/J45XWCHG/On Last-Layer Algorithms for Classification - Brosse et al - 2020.pdf:application/pdf},
}

@article{zengRelevanceBayesianLayer2018,
	title = {The {Relevance} of {Bayesian} {Layer} {Positioning} to {Model} {Uncertainty} in {Deep} {Bayesian} {Active} {Learning}},
	url = {http://arxiv.org/abs/1811.12535},
	abstract = {One of the main challenges of deep learning tools is their inability to capture model uncertainty. While Bayesian deep learning can be used to tackle the problem, Bayesian neural networks often require more time and computational power to train than deterministic networks. Our work explores whether fully Bayesian networks are needed to successfully capture model uncertainty. We vary the number and position of Bayesian layers in a network and compare their performance on active learning with the MNIST dataset. We found that we can fully capture the model uncertainty by using only a few Bayesian layers near the output of the network, combining the advantages of deterministic and Bayesian networks.},
	urldate = {2021-05-21},
	journal = {arXiv:1811.12535 [cs, stat]},
	author = {Zeng, Jiaming and Lesnikowski, Adam and Alvarez, Jose M.},
	month = nov,
	year = {2018},
	note = {ZSCC: 0000006 
arXiv: 1811.12535},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/HQJMUWHX/1811.html:text/html;The Relevance of Bayesian Layer Positioning to Model Uncertainty in Deep - Zeng et al - 2018.pdf:/home/theo/Zotero/storage/P4HR4H5X/The Relevance of Bayesian Layer Positioning to Model Uncertainty in Deep - Zeng et al - 2018.pdf:application/pdf},
}

@article{dutordoirDeepNeuralNetworks2021,
	title = {Deep {Neural} {Networks} as {Point} {Estimates} for {Deep} {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/2105.04504},
	abstract = {Deep Gaussian processes (DGPs) have struggled for relevance in applications due to the challenges and cost associated with Bayesian inference. In this paper we propose a sparse variational approximation for DGPs for which the approximate posterior mean has the same mathematical structure as a Deep Neural Network (DNN). We make the forward pass through a DGP equivalent to a ReLU DNN by finding an interdomain transformation that represents the GP posterior mean as a sum of ReLU basis functions. This unification enables the initialisation and training of the DGP as a neural network, leveraging the well established practice in the deep learning community, and so greatly aiding the inference task. The experiments demonstrate improved accuracy and faster training compared to current DGP methods, while retaining favourable predictive uncertainties.},
	urldate = {2021-05-13},
	journal = {arXiv:2105.04504 [cs, stat]},
	author = {Dutordoir, Vincent and Hensman, James and van der Wilk, Mark and Ek, Carl Henrik and Ghahramani, Zoubin and Durrande, Nicolas},
	month = may,
	year = {2021},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 2105.04504},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/ADJ85VX7/2105.html:text/html;Deep Neural Networks as Point Estimates for Deep Gaussian Processes - Dutordoir et al - 2021.pdf:/home/theo/Zotero/storage/QJQPR2LL/Deep Neural Networks as Point Estimates for Deep Gaussian Processes - Dutordoir et al - 2021.pdf:application/pdf},
}

@article{solinInfiniteHorizonGaussianProcesses2018,
	title = {Infinite-{Horizon} {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/1811.06588},
	abstract = {Gaussian processes provide a flexible framework for forecasting, removing noise, and interpreting long temporal datasets. State space modelling (Kalman filtering) enables these non-parametric models to be deployed on long datasets by reducing the complexity to linear in the number of data points. The complexity is still cubic in the state dimension \$m\$ which is an impediment to practical application. In certain special cases (Gaussian likelihood, regular spacing) the GP posterior will reach a steady posterior state when the data are very long. We leverage this and formulate an inference scheme for GPs with general likelihoods, where inference is based on single-sweep EP (assumed density filtering). The infinite-horizon model tackles the cubic cost in the state dimensionality and reduces the cost in the state dimension \$m\$ to \${\textbackslash}mathcal\{O\}(m{\textasciicircum}2)\$ per data point. The model is extended to online-learning of hyperparameters. We show examples for large finite-length modelling problems, and present how the method runs in real-time on a smartphone on a continuous data stream updated at 100{\textasciitilde}Hz.},
	urldate = {2021-04-28},
	journal = {arXiv:1811.06588 [cs, stat]},
	author = {Solin, Arno and Hensman, James and Turner, Richard E.},
	month = nov,
	year = {2018},
	note = {ZSCC: 0000013 
arXiv: 1811.06588},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/ML5HFKK3/1811.html:text/html;Infinite-Horizon Gaussian Processes - Solin et al - 2018.pdf:/home/theo/Zotero/storage/YHQ4ZH75/Infinite-Horizon Gaussian Processes - Solin et al - 2018.pdf:application/pdf},
}

@article{johnsTwostageEnsembleKalman2008,
	title = {A two-stage ensemble {Kalman} filter for smooth data assimilation},
	volume = {15},
	issn = {1352-8505, 1573-3009},
	url = {http://link.springer.com/10.1007/s10651-007-0033-0},
	doi = {10/dz9v9w},
	abstract = {The ensemble Kalman Filter (EnKF) applied to a simple ﬁre propagation model by a nonlinear convection-diﬀusion-reaction partial diﬀerential equation breaks down because the EnKF creates nonphysical ensemble members with large gradients. A modiﬁcation of the EnKF is proposed by adding a regularization term that penalizes large gradients. The method is implemented by applying the EnKF formulas twice, with the regularization term as another observation. The regularization step is also interpreted as a shrinkage of the prior distribution. Numerical results are given to illustrate success of the new method.},
	language = {en},
	number = {1},
	urldate = {2021-04-27},
	journal = {Environmental and Ecological Statistics},
	author = {Johns, Craig J. and Mandel, Jan},
	month = mar,
	year = {2008},
	note = {ZSCC: 0000075},
	pages = {101--110},
	file = {A two-stage ensemble Kalman filter for smooth data assimilation:/home/theo/Zotero/storage/BH2ZIMX5/johns2007.pdf:application/pdf;Johns and Mandel - 2008 - A two-stage ensemble Kalman filter for smooth data.pdf:/home/theo/Zotero/storage/MBM7EHZZ/Johns and Mandel - 2008 - A two-stage ensemble Kalman filter for smooth data.pdf:application/pdf},
}

@article{nealAnnealedImportanceSampling1998,
	title = {Annealed {Importance} {Sampling}},
	url = {http://arxiv.org/abs/physics/9803008},
	abstract = {Simulated annealing - moving from a tractable distribution to a distribution of interest via a sequence of intermediate distributions - has traditionally been used as an inexact method of handling isolated modes in Markov chain samplers. Here, it is shown how one can use the Markov chain transitions for such an annealing sequence to define an importance sampler. The Markov chain aspect allows this method to perform acceptably even for high-dimensional problems, where finding good importance sampling distributions would otherwise be very difficult, while the use of importance weights ensures that the estimates found converge to the correct values as the number of annealing runs increases. This annealed importance sampling procedure resembles the second half of the previously-studied tempered transitions, and can be seen as a generalization of a recently-proposed variant of sequential importance sampling. It is also related to thermodynamic integration methods for estimating ratios of normalizing constants. Annealed importance sampling is most attractive when isolated modes are present, or when estimates of normalizing constants are required, but it may also be more generally useful, since its independent sampling allows one to bypass some of the problems of assessing convergence and autocorrelation in Markov chain samplers.},
	urldate = {2021-04-27},
	journal = {arXiv:physics/9803008},
	author = {Neal, Radford M.},
	month = sep,
	year = {1998},
	note = {ZSCC: 0000006 
arXiv: physics/9803008},
	keywords = {⛔ No DOI found, Physics - Computational Physics, Physics - Data Analysis, Statistics and Probability},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/YJCUFHAG/9803008.html:text/html;Annealed Importance Sampling - Neal - 1998.pdf:/home/theo/Zotero/storage/AN53CG7S/Annealed Importance Sampling - Neal - 1998.pdf:application/pdf},
}

@article{foadImplementationUnscentedTransformation2020,
	title = {Implementation of the unscented transformation with low rank approximation in uncertainty analysis during large-break loss of coolant accident},
	volume = {146},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454920303121},
	doi = {10/gjs7x4},
	abstract = {The Low Rank Approximation (LRA) and Unscented Transform (UT) are integrated to produce a new algorithm having the capability to decrease the time required for the uncertainty quantification during Loss of coolant accident (LOCA) in Pressurized Water Reactors (PWR). The LRA is an efficient technique used in reducing computational cost due to its ability to perform dimensionality reduction by revealing the active or important degrees of freedom and calculate the basis of the so-called active subspace basing on the Singular Value Decomposition (SVD). For further reduction in the computational time; the UT algorithm is also implemented to generate a set of sigma points, these sigma points are the representatives of the whole probability distribution (the UT is restricted to Gaussian distribution). The main safety parameter is the maximum cladding temperatures during the accident which are computed by ATHLET thermal-hydraulic code. The reactivity coefficients and the covariance matrix are calculated using the SCALE 6.2 code. The present calculation model has 14-dimensions, therefore the number of sigma points needed for the SVD/UT technique is 29, and can be minimized to 5 sigma points only if the LRA/UT is used where two singular values are sufficient to reproduce/span the space thanks to the strong correlations between the reactivity coefficients.},
	language = {en},
	urldate = {2021-04-27},
	journal = {Annals of Nuclear Energy},
	author = {Foad, Basma and Yamamoto, Akio and Endo, Tomohiro},
	month = oct,
	year = {2020},
	note = {ZSCC: 0000001},
	keywords = {Uncertainty, ATHLET, LOCA, LRA, PWR, SCALE, SVD, UT},
	pages = {107614},
	file = {ScienceDirect Snapshot:/home/theo/Zotero/storage/4H2LXXEU/S0306454920303121.html:text/html;Implementation of the unscented transformation with low rank approximation in - Foad et al - 2020.pdf:/home/theo/Zotero/storage/LRQ47QK3/Implementation of the unscented transformation with low rank approximation in - Foad et al - 2020.pdf:application/pdf},
}

@article{menegazSystematizationUnscentedKalman2015,
	title = {A {Systematization} of the {Unscented} {Kalman} {Filter} {Theory}},
	volume = {60},
	issn = {1558-2523},
	doi = {10/f75jpt},
	abstract = {In this paper, we propose a systematization of the (discrete-time) Unscented Kalman Filter (UKF) theory. We gather all available UKF variants in the literature, present corrections to theoretical inconsistencies, and provide a tool for the construction of new UKF's in a consistent way. This systematization is done, mainly, by revisiting the concepts of Sigma-Representation, Unscented Transformation (UT), Scaled Unscented Transformation (SUT), UKF, and Square-Root Unscented Kalman Filter (SRUKF). Inconsistencies are related to 1) matching the order of the transformed covariance and cross-covariance matrices of both the UT and the SUT; 2) multiple UKF definitions; 3) issue with some reduced sets of sigma points described in the literature; 4) the conservativeness of the SUT; 5) the scaling effect of the SUT on both its transformed covariance and cross-covariance matrices; and 6) possibly ill-conditioned results in SRUKF's. With the proposed systematization, the symmetric sets of sigma points in the literature are formally justified, and we are able to provide new consistent variations for UKF's, such as the Scaled SRUKF's and the UKF's composed by the minimum number of sigma points. Furthermore, our proposed SRUKF has improved computational properties when compared to state-of-the-art methods.},
	number = {10},
	journal = {IEEE Transactions on Automatic Control},
	author = {Menegaz, Henrique M. T. and Ishihara, João Y. and Borges, Geovany A. and Vargas, Alessandro N.},
	month = oct,
	year = {2015},
	note = {ZSCC: 0000159 
Conference Name: IEEE Transactions on Automatic Control},
	keywords = {Kalman filters, Additives, Covariance matrices, Equations, Estimation, Noise, Unscented Kalman Filter (UKF), Unscented Transformation (UT), Vectors},
	pages = {2583--2598},
	file = {A Systematization of the Unscented Kalman Filter Theory:/home/theo/Zotero/storage/PULIU6JQ/menegaz2015.pdf:application/pdf;Menegaz et al_2015_A Systematization of the Unscented Kalman Filter Theory.pdf:/home/theo/Zotero/storage/RM7BEZQQ/Menegaz et al_2015_A Systematization of the Unscented Kalman Filter Theory.pdf:application/pdf;IEEE Xplore Abstract Record:/home/theo/Zotero/storage/SVMHZNCL/7042740.html:text/html},
}

@article{giraldoFullyNaturalGradient2020,
	title = {A {Fully} {Natural} {Gradient} {Scheme} for {Improving} {Inference} of the {Heterogeneous} {Multi}-{Output} {Gaussian} {Process} {Model}},
	url = {http://arxiv.org/abs/1911.10225},
	abstract = {A recent novel extension of multi-output Gaussian processes handles heterogeneous outputs assuming that each output has its own likelihood function. It uses a vector-valued Gaussian process prior to jointly model all likelihoods' parameters as latent functions drawn from a Gaussian process with a linear model of coregionalisation covariance. By means of an inducing points framework, the model is able to obtain tractable variational bounds amenable to stochastic variational inference. Nonetheless, the strong conditioning between the variational parameters and the hyper-parameters burdens the adaptive gradient optimisation methods used in the original approach. To overcome this issue we borrow ideas from variational optimisation introducing an exploratory distribution over the hyper-parameters, allowing inference together with the posterior's variational parameters through a fully natural gradient optimisation scheme. Furthermore, in this work we introduce an extension of the heterogeneous multi-output model, where its latent functions are drawn from convolution processes. We show that our optimisation scheme can achieve better local optima solutions with higher test performance rates than adaptive gradient methods, this for both the linear model of coregionalisation and the convolution processes model. We also show how to make the convolutional model scalable by means of stochastic variational inference and how to optimise it through a fully natural gradient scheme. We compare the performance of the different methods over toy and real databases.},
	urldate = {2021-04-15},
	journal = {arXiv:1911.10225 [cs, stat]},
	author = {Giraldo, Juan-José and Álvarez, Mauricio A.},
	month = jul,
	year = {2020},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1911.10225},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/I8QKGKXE/1911.html:text/html;Giraldo_Álvarez_2020_A Fully Natural Gradient Scheme for Improving Inference of the Heterogeneous.pdf:/home/theo/Zotero/storage/NKVJIAKD/Giraldo_Álvarez_2020_A Fully Natural Gradient Scheme for Improving Inference of the Heterogeneous.pdf:application/pdf},
}

@article{saeediVariationalParticleApproximations,
	title = {Variational {Particle} {Approximations}},
	abstract = {Approximate inference in high-dimensional, discrete probabilistic models is a central problem in computational statistics and machine learning. This paper describes discrete particle variational inference (DPVI), a new approach that combines key strengths of Monte Carlo, variational and search-based techniques. DPVI is based on a novel family of particle-based variational approximations that can be ﬁt using simple, fast, deterministic search techniques. Like Monte Carlo, DPVI can handle multiple modes, and yields exact results in a well-deﬁned limit. Like unstructured mean-ﬁeld, DPVI is based on optimizing a lower bound on the partition function; when this quantity is not of intrinsic interest, it facilitates convergence assessment and debugging. Like both Monte Carlo and combinatorial search, DPVI can take advantage of factorization, sequential structure, and custom search operators. This paper deﬁnes DPVI particle-based approximation family and partition function lower bounds, along with the sequential DPVI and local DPVI algorithm templates for optimizing them. DPVI is illustrated and evaluated via experiments on lattice Markov Random Fields, nonparametric Bayesian mixtures and block-models, and parametric as well as non-parametric hidden Markov models. Results include applications to real-world spike-sorting and relational modeling problems, and show that DPVI can oﬀer appealing time/accuracy trade-oﬀs as compared to multiple alternatives.},
	language = {en},
	author = {Saeedi, Ardavan and Kulkarni, Tejas D and Mansinghka, Vikash K and Gershman, Samuel J},
	note = {ZSCC: 0000021},
	keywords = {⛔ No DOI found},
	pages = {29},
	file = {Saeedi et al. - Variational Particle Approximations.pdf:/home/theo/Zotero/storage/2VBI3KDU/Saeedi et al. - Variational Particle Approximations.pdf:application/pdf},
}

@article{gershmanNonparametricVariationalInference2012,
	title = {Nonparametric variational inference},
	url = {http://arxiv.org/abs/1206.4665},
	abstract = {Variational methods are widely used for approximate posterior inference. However, their use is typically limited to families of distributions that enjoy particular conjugacy properties. To circumvent this limitation, we propose a family of variational approximations inspired by nonparametric kernel density estimation. The locations of these kernels and their bandwidth are treated as variational parameters and optimized to improve an approximate lower bound on the marginal likelihood of the data. Using multiple kernels allows the approximation to capture multiple modes of the posterior, unlike most other variational approximations. We demonstrate the efficacy of the nonparametric approximation with a hierarchical logistic regression model and a nonlinear matrix factorization model. We obtain predictive performance as good as or better than more specialized variational methods and sample-based approximations. The method is easy to apply to more general graphical models for which standard variational methods are difficult to derive.},
	urldate = {2021-04-14},
	journal = {arXiv:1206.4665 [cs, stat]},
	author = {Gershman, Samuel and Hoffman, Matt and Blei, David},
	month = jun,
	year = {2012},
	note = {ZSCC: 0000140 
arXiv: 1206.4665},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found, Computer Science - Machine Learning},
	file = {Nonparametric Variational Inference - Gershman et al -.pdf:/home/theo/Zotero/storage/VEIUUIDT/Nonparametric Variational Inference - Gershman et al -.pdf:application/pdf;Nonparametric Variational Inference - Gershman et al -.pdf:/home/theo/Zotero/storage/NT8BI5J6/Nonparametric Variational Inference - Gershman et al -.pdf:application/pdf;arXiv.org Snapshot:/home/theo/Zotero/storage/7TKZ4PX4/1206.html:text/html;Nonparametric variational inference - Gershman et al - 2012.pdf:/home/theo/Zotero/storage/ZUKCUHG4/Nonparametric variational inference - Gershman et al - 2012.pdf:application/pdf},
}

@article{nealExactBayesianInference2015,
	title = {Exact {Bayesian} inference via data augmentation},
	volume = {25},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-013-9435-z},
	doi = {10/gg2bnp},
	abstract = {Data augmentation is a common tool in Bayesian statistics, especially in the application of MCMC. Data augmentation is used where direct computation of the posterior density, π(θ{\textbar}x), of the parameters θ, given the observed data x, is not possible. We show that for a range of problems, it is possible to augment the data by y, such that, π(θ{\textbar}x,y) is known, and π(y{\textbar}x) can easily be computed. In particular, π(y{\textbar}x) is obtained by collapsingπ(y,θ{\textbar}x) through integrating out θ. This allows the exact computation of π(θ{\textbar}x) as a mixture distribution without recourse to approximating methods such as MCMC. Useful byproducts of the exact posterior distribution are the marginal likelihood of the model and the exact predictive distribution.},
	language = {en},
	number = {2},
	urldate = {2021-04-14},
	journal = {Statistics and Computing},
	author = {Neal, Peter and Kypraios, Theodore},
	month = mar,
	year = {2015},
	note = {ZSCC: 0000015},
	pages = {333--347},
	file = {Exact Bayesian inference via data augmentation:/home/theo/Zotero/storage/NAET4K2D/neal2013.pdf:application/pdf;Exact Bayesian inference via data augmentation - Neal_Kypraios - 2015.pdf:/home/theo/Zotero/storage/QVUFDUE6/Exact Bayesian inference via data augmentation - Neal_Kypraios - 2015.pdf:application/pdf},
}

@article{fisherMeasureTransportKernel,
	title = {Measure {Transport} with {Kernel} {Stein} {Discrepancy}},
	abstract = {Measure transport underpins several recent algorithms for posterior approximation in the Bayesian context, wherein a transport map is sought to minimise the Kullback–Leibler divergence (KLD) from the posterior to the approximation. The KLD is a strong mode of convergence, requiring absolute continuity of measures and placing restrictions on which transport maps can be permitted. Here we propose to minimise a kernel Stein discrepancy (KSD) instead, requiring only that the set of transport maps is dense in an L2 sense and demonstrating how this condition can be validated. The consistency of the associated posterior approximation is established and empirical results suggest that KSD is a competitive and more ﬂexible alternative to KLD for measure transport.},
	language = {en},
	author = {Fisher, Matthew A and Nolan, Tui H and Graham, Matthew M},
	note = {ZSCC: 0000001},
	keywords = {⛔ No DOI found},
	pages = {11},
	file = {Fisher et al. - Measure Transport with Kernel Stein Discrepancy.pdf:/home/theo/Zotero/storage/AGTF3C2A/Fisher et al. - Measure Transport with Kernel Stein Discrepancy.pdf:application/pdf},
}

@article{radulBaseMeasureProblem,
	title = {The {Base} {Measure} {Problem} and its {Solution}},
	abstract = {Probabilistic programming systems generally compute with probability density functions, leaving the base measure of each such function implicit. This mostly works, but creates problems when densities with respect to diﬀerent base measures are accidentally combined or compared. Mistakes also happen when computing volume corrections for continuous changes of variables, which in general depend on the support measure. We motivate and clarify the problem in the context of a composable library of probability distributions and bijective transformations. We solve the problem by standardizing on Hausdorﬀ measure as a base, and deriving formulas for comparing and combining mixed-dimension densities, as well as updating densities with respect to Hausdorﬀ measure under diﬀeomorphic transformations. We also propose a software architecture that implements these formulas eﬃciently in the common case. We hope that by adopting our solution, probabilistic programming systems can become more robust and general, and make a broader class of models accessible to practitioners.},
	language = {en},
	author = {Radul, Alexey and Alexeev, Boris},
	note = {ZSCC: 0000000},
	keywords = {⛔ No DOI found},
	pages = {11},
	file = {Radul and Alexeev - The Base Measure Problem and its Solution.pdf:/home/theo/Zotero/storage/R3FBG383/Radul and Alexeev - The Base Measure Problem and its Solution.pdf:application/pdf},
}

@article{rossiSparseGaussianProcesses2021,
	title = {Sparse {Gaussian} {Processes} {Revisited}: {Bayesian} {Approaches} to {Inducing}-{Variable} {Approximations}},
	shorttitle = {Sparse {Gaussian} {Processes} {Revisited}},
	url = {http://arxiv.org/abs/2003.03080},
	abstract = {Variational inference techniques based on inducing variables provide an elegant framework for scalable posterior estimation in Gaussian process (GP) models. Besides enabling scalability, one of their main advantages over sparse approximations using direct marginal likelihood maximization is that they provide a robust alternative for point estimation of the inducing inputs, i.e. the location of the inducing variables. In this work we challenge the common wisdom that optimizing the inducing inputs in the variational framework yields optimal performance. We show that, by revisiting old model approximations such as the fully-independent training conditionals endowed with powerful sampling-based inference methods, treating both inducing locations and GP hyper-parameters in a Bayesian way can improve performance significantly. Based on stochastic gradient Hamiltonian Monte Carlo, we develop a fully Bayesian approach to scalable GP and deep GP models, and demonstrate its state-of-the-art performance through an extensive experimental campaign across several regression and classification problems.},
	urldate = {2021-04-13},
	journal = {arXiv:2003.03080 [cs, stat]},
	author = {Rossi, Simone and Heinonen, Markus and Bonilla, Edwin V. and Shen, Zheyang and Filippone, Maurizio},
	month = feb,
	year = {2021},
	note = {ZSCC: 0000000 
arXiv: 2003.03080},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/4QYKHSHB/2003.html:text/html;Sparse Gaussian Processes Revisited - Rossi et al - 2021.pdf:/home/theo/Zotero/storage/SIXZ4R7S/Sparse Gaussian Processes Revisited - Rossi et al - 2021.pdf:application/pdf},
}

@article{kunstnerHomeomorphicInvarianceEMNonAsymptotic,
	title = {Homeomorphic-{Invariance} of {EM}: {Non}-{Asymptotic} {Convergence} in {KL} {Divergence} for {Exponential} {Families} via {Mirror} {Descent}},
	language = {en},
	author = {Kunstner, Frederik and Kumar, Raunak and Schmidt, Mark},
	note = {ZSCC: 0000000},
	keywords = {⛔ No DOI found},
	pages = {11},
	file = {Kunstner et al. - Homeomorphic-Invariance of EM Non-Asymptotic Conv.pdf:/home/theo/Zotero/storage/NPIG2EJ5/Kunstner et al. - Homeomorphic-Invariance of EM Non-Asymptotic Conv.pdf:application/pdf},
}

@article{chingTransitionalMarkovChain2007,
	title = {Transitional {Markov} {Chain} {Monte} {Carlo} {Method} for {Bayesian} {Model} {Updating}, {Model} {Class} {Selection}, and {Model} {Averaging}},
	volume = {133},
	issn = {0733-9399, 1943-7889},
	url = {http://ascelibrary.org/doi/10.1061/%28ASCE%290733-9399%282007%29133%3A7%28816%29},
	doi = {10/dp2kns},
	abstract = {This paper presents a newly developed simulation-based approach for Bayesian model updating, model class selection, and model averaging called the transitional Markov chain Monte Carlo ͑TMCMC͒ approach. The idea behind TMCMC is to avoid the problem of sampling from difﬁcult target probability density functions ͑PDFs͒ but sampling from a series of intermediate PDFs that converge to the target PDF and are easier to sample. The TMCMC approach is motivated by the adaptive Metropolis–Hastings method developed by Beck and Au in 2002 and is based on Markov chain Monte Carlo. It is shown that TMCMC is able to draw samples from some difﬁcult PDFs ͑e.g., multimodal PDFs, very peaked PDFs, and PDFs with ﬂat manifold͒. The TMCMC approach can also estimate evidence of the chosen probabilistic model class conditioning on the measured data, a key component for Bayesian model class selection and model averaging. Three examples are used to demonstrate the effectiveness of the TMCMC approach in Bayesian model updating, model class selection, and model averaging.},
	language = {en},
	number = {7},
	urldate = {2021-04-08},
	journal = {Journal of Engineering Mechanics},
	author = {Ching, Jianye and Chen, Yi-Chu},
	month = jul,
	year = {2007},
	note = {ZSCC: 0000569},
	pages = {816--832},
	file = {Transitional Markov Chain Monte Carlo Method for Bayesian Model Updating, Model Class Selection, and Model Averaging:/home/theo/Zotero/storage/S8PW6LB4/ching2007.pdf:application/pdf;Ching and Chen - 2007 - Transitional Markov Chain Monte Carlo Method for B.pdf:/home/theo/Zotero/storage/ASDLQYIF/Ching and Chen - 2007 - Transitional Markov Chain Monte Carlo Method for B.pdf:application/pdf},
}

@book{frankelGeometryPhysicsIntroduction2012,
	address = {Cambridge ; New York},
	edition = {3rd ed},
	title = {The geometry of physics: an introduction},
	isbn = {978-1-107-60260-1},
	shorttitle = {The geometry of physics},
	abstract = {"This book is intended to provide a working knowledge of those parts of exterior differential forms, differential geometry, algebraic and differential topology, Lie groups, vector bundles, and Chern forms that are essential for a deeper understanding of both classical and modern physics and engineering. Included are discussions of analytical and fluid dynamics, electromagnetism (in flat and curved space), thermodynamics, the deformation tensors of elasticity, soap films, special and general relativity, the Dirac operator and spinors, and gauge fields, including Yang-Mills, the Aharonov-Bohm effect, Berry phase, and instanton winding numbers, quarks, and the quark model for mesons. Before a discussion of abstract notions of differential geometry, geometric intuition is developed through a rather extensive introduction to the study of surfaces in ordinary space; consequently, the book should be of interest also to mathematics students. This book will be useful to graduate and advance undergraduate students of physics, engineering or mathematics. It can be used as a course text or for self-study. This third edition includes a new overview of Cartan's exterior differential forms. It previews many of the geometric concepts developed in the text and illustrates their applications to a single extended problem in engineering, namely the Cauchy stresses created by a small twist of an elastic cylindrical rod about its axis"--},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Frankel, Theodore},
	year = {2012},
	note = {ZSCC: NoCitationData[s0]},
	keywords = {Geometry, Differential, Mathematical physics, MATHEMATICS / Topology},
	file = {Frankel - 2012 - The geometry of physics an introduction.pdf:/home/theo/Zotero/storage/27YAZJGP/Frankel - 2012 - The geometry of physics an introduction.pdf:application/pdf},
}

@book{fortneyVisualIntroductionDifferential2018,
	address = {Cham},
	title = {A {Visual} {Introduction} to {Differential} {Forms} and {Calculus} on {Manifolds}},
	isbn = {978-3-319-96991-6 978-3-319-96992-3},
	url = {http://link.springer.com/10.1007/978-3-319-96992-3},
	language = {en},
	urldate = {2021-03-31},
	publisher = {Springer International Publishing},
	author = {Fortney, Jon Pierre},
	year = {2018},
	doi = {10.1007/978-3-319-96992-3},
	note = {ZSCC: 0000010 },
	file = {Fortney - 2018 - A Visual Introduction to Differential Forms and Ca.pdf:/home/theo/Zotero/storage/ZGNNF32P/Fortney - 2018 - A Visual Introduction to Differential Forms and Ca.pdf:application/pdf},
}

@article{wilkinsonSparseAlgorithmsMarkovian,
	title = {Sparse {Algorithms} for {Markovian} {Gaussian} {Processes}},
	abstract = {Approximate Bayesian inference methods that scale to very large datasets are crucial in leveraging probabilistic models for real-world time series. Sparse Markovian Gaussian processes combine the use of inducing variables with eﬃcient Kalman ﬁlter-like recursions, resulting in algorithms whose computational and memory requirements scale linearly in the number of inducing points, whilst also enabling parallel parameter updates and stochastic optimisation. Under this paradigm, we derive a general site-based approach to approximate inference, whereby we approximate the non-Gaussian likelihood with local Gaussian terms, called sites. Our approach results in a suite of novel sparse extensions to algorithms from both the machine learning and signal processing literature, including variational inference, expectation propagation, and the classical nonlinear Kalman smoothers. The derived methods are suited to large time series, and we also demonstrate their applicability to spatio-temporal data, where the model has separate inducing points in both time and space.},
	language = {en},
	author = {Wilkinson, William J and Solin, Arno and Adam, Vincent},
	note = {ZSCC: 0000000},
	pages = {11},
	file = {Wilkinson et al. - Sparse Algorithms for Markovian Gaussian Processes.pdf:/home/theo/Zotero/storage/5I4EIM6F/Wilkinson et al. - Sparse Algorithms for Markovian Gaussian Processes.pdf:application/pdf},
}

@inproceedings{baumSupervisedLearningProbability1988,
	title = {Supervised {Learning} of {Probability} {Distributions} by {Neural} {Networks}},
	url = {https://proceedings.neurips.cc/paper/1987/file/eccbc87e4b5ce2fe28308fd9f2a7baf3-Paper.pdf},
	urldate = {2021-03-24},
	booktitle = {Neural {Information} {Processing} {Systems}},
	publisher = {American Institute of Physics},
	author = {Baum, Eric and Wilczek, Frank},
	editor = {Anderson, D.},
	year = {1988},
	note = {ZSCC: NoCitationData[s0]},
	keywords = {⛔ No DOI found},
	file = {NIPS Snapshot:/home/theo/Zotero/storage/4WRNDYM9/6a61d423d02a1c56250dc23ae7ff12f3-Paper.html:text/html;Baum_Wilczek_1988_Supervised Learning of Probability Distributions by Neural Networks.pdf:/home/theo/Zotero/storage/MU4R4MXJ/Baum_Wilczek_1988_Supervised Learning of Probability Distributions by Neural Networks.pdf:application/pdf},
}

@article{dhakaRobustAccurateStochastic2020,
	title = {Robust, {Accurate} {Stochastic} {Optimization} for {Variational} {Inference}},
	volume = {33},
	url = {https://papers.nips.cc/paper/2020/hash/7cac11e2f46ed46c339ec3d569853759-Abstract.html},
	language = {en},
	urldate = {2021-03-23},
	journal = {Advances in Neural Information Processing Systems},
	author = {Dhaka, Akash Kumar and Catalina, Alejandro and Andersen, Michael R. and Magnusson, Måns and Huggins, Jonathan and Vehtari, Aki},
	year = {2020},
	note = {ZSCC: 0000003},
	pages = {10961--10973},
	file = {Snapshot:/home/theo/Zotero/storage/ZAF4J295/7cac11e2f46ed46c339ec3d569853759-Abstract.html:text/html;Robust, Accurate Stochastic Optimization for Variational Inference - Dhaka et al - 2020.pdf:/home/theo/Zotero/storage/JRYJZB2W/Robust, Accurate Stochastic Optimization for Variational Inference - Dhaka et al - 2020.pdf:application/pdf},
}

@article{gibbsChoosingBoundingProbability2002,
	title = {On {Choosing} and {Bounding} {Probability} {Metrics}},
	volume = {70},
	issn = {1751-5823},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1751-5823.2002.tb00178.x},
	doi = {10/bg3ff9},
	abstract = {When studying convergence of measures, an important issue is the choice of probability metric. We provide a summary and some new results concerning bounds among some important probability metrics/distances that are used by statisticians and probabilists. Knowledge of other metrics can provide a means of deriving bounds for another one in an applied problem. Considering other metrics can also provide alternate insights. We also give examples that show that rates of convergence can strongly depend on the metric chosen. Careful consideration is necessary when choosing a metric.},
	language = {en},
	number = {3},
	urldate = {2021-03-19},
	journal = {International Statistical Review},
	author = {Gibbs, Alison L. and Su, Francis Edward},
	year = {2002},
	note = {ZSCC: 0001147 
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1751-5823.2002.tb00178.x},
	keywords = {Discrepancy, Hellinger distance, Probability metrics, Prokhorov metric, Rates of convergence, Relative entropy, to read, Wasserstein distance},
	pages = {419--435},
	file = {On Choosing and Bounding Probability Metrics - Gibbs_Su - 2002.pdf:/home/theo/Zotero/storage/NLXQG8UE/On Choosing and Bounding Probability Metrics - Gibbs_Su - 2002.pdf:application/pdf;Snapshot:/home/theo/Zotero/storage/6XUGAMZE/j.1751-5823.2002.tb00178.html:text/html},
}

@article{deisenrothDeepKernelLearning2009,
	title = {Deep {Kernel} {Learning}},
	volume = {72},
	issn = {09252312},
	url = {http://arxiv.org/abs/1511.02222},
	doi = {10.1016/j.neucom.2008.12.019},
	abstract = {Reinforcement learning (RL) and optimal control of systems with continuous states and actions require approximation techniques in most interesting cases. In this article, we introduce Gaussian process dynamic programming (GPDP), an approximate value function-based RL algorithm. We consider both a classic optimal control problem, where problem-specific prior knowledge is available, and a classic RL problem, where only very general priors can be used. For the classic optimal control problem, GPDP models the unknown value functions with Gaussian processes and generalizes dynamic programming to continuous-valued states and actions. For the RL problem, GPDP starts from a given initial state and explores the state space using Bayesian active learning. To design a fast learner, available data have to be used efficiently. Hence, we propose to learn probabilistic models of the a priori unknown transition dynamics and the value functions on the fly. In both cases, we successfully apply the resulting continuous-valued controllers to the under-actuated pendulum swing up and analyze the performances of the suggested algorithms. It turns out that GPDP uses data very efficiently and can be applied to problems, where classic dynamic programming would be cumbersome. © 2009 Elsevier B.V. All rights reserved.},
	number = {7-9},
	journal = {Neurocomputing},
	author = {Deisenroth, Marc Peter and Rasmussen, Carl Edward and Peters, Jan},
	year = {2009},
	pmid = {264993200014},
	note = {ZSCC: 0000224 
arXiv: 1511.02222
ISBN: 1406.2661},
	keywords = {Gaussian processes, Bayesian active learning, Dynamic programming, Optimal control, Policy learning, Reinforcement learning},
	pages = {1508--1524},
	file = {Gaussian process dynamic programming - Deisenroth et al - 2009.pdf:/home/theo/Zotero/storage/CRXMQ3NK/Gaussian process dynamic programming - Deisenroth et al - 2009.pdf:application/pdf},
}

@article{quirozBlockPoissonEstimatorOptimally2020,
	title = {The block-{Poisson} estimator for optimally tuned exact subsampling {MCMC}},
	url = {http://arxiv.org/abs/1603.08232},
	abstract = {Speeding up Markov Chain Monte Carlo (MCMC) for datasets with many observations by data subsampling has recently received considerable attention. A pseudo-marginal MCMC method is proposed that estimates the likelihood by data subsampling using a block-Poisson estimator. The estimator is a product of Poisson estimators, allowing us to update a single block of subsample indicators in each MCMC iteration so that a desired correlation is achieved between the logs of successive likelihood estimates. This is important since pseudo-marginal MCMC with positively correlated likelihood estimates can use substantially smaller subsamples without adversely affecting the sampling efficiency. The block-Poisson estimator is unbiased but not necessarily positive, so the algorithm runs the MCMC on the absolute value of the likelihood estimator and uses an importance sampling correction to obtain consistent estimates of the posterior mean of any function of the parameters. Our article derives guidelines to select the optimal tuning parameters for our method and shows that it compares very favourably to regular MCMC without subsampling, and to two other recently proposed exact subsampling approaches in the literature.},
	urldate = {2021-03-18},
	journal = {arXiv:1603.08232 [stat]},
	author = {Quiroz, Matias and Tran, Minh-Ngoc and Villani, Mattias and Kohn, Robert and Dang, Khue-Dung},
	month = apr,
	year = {2020},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1603.08232},
	keywords = {Statistics - Machine Learning, Statistics - Computation, Statistics - Methodology},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/59EG67JM/1603.html:text/html;The block-Poisson estimator for optimally tuned exact subsampling MCMC - Quiroz et al - 2020.pdf:/home/theo/Zotero/storage/4KLA3PWZ/The block-Poisson estimator for optimally tuned exact subsampling MCMC - Quiroz et al - 2020.pdf:application/pdf},
}

@article{robertsInfiniteHierarchiesPrior2001,
	title = {Infinite hierarchies and prior distributions},
	volume = {7},
	issn = {1350-7265},
	url = {https://projecteuclid.org/journals/bernoulli/volume-7/issue-3/Infinite-hierarchies-and-prior-distributions/bj/1080004760.full},
	doi = {10/dtr5hg},
	abstract = {This paper introduces a way of constructing non-informative priors for Bayesian analysis, by taking a limit of priors arising from hierarchical constructions as the number of levels in the hierarchy converges to infinity. Results are proved showing that for location families, and other related cases, limits are often not dependent on the exact form of the increment distribution used.},
	number = {3},
	urldate = {2021-03-15},
	journal = {Bernoulli},
	author = {Roberts, Gareth O. and Rosenthal, Jeffrey S.},
	month = jun,
	year = {2001},
	note = {ZSCC: 0000014 
Publisher: Bernoulli Society for Mathematical Statistics and Probability},
	keywords = {hierarchical priors, non-informative priors},
	pages = {453--471},
	file = {Snapshot:/home/theo/Zotero/storage/2X6NE29W/1080004760.html:text/html;Roberts_Rosenthal_2001_Infinite hierarchies and prior distributions.pdf:/home/theo/Zotero/storage/FZTYRBLM/Roberts_Rosenthal_2001_Infinite hierarchies and prior distributions.pdf:application/pdf},
}

@book{kuhnelDifferentialGeometryCurves2006,
	address = {Providence, R.I},
	edition = {2nd ed},
	series = {Student mathematical library},
	title = {Differential geometry: curves - surfaces - manifolds},
	isbn = {978-0-8218-3988-1},
	shorttitle = {Differential geometry},
	language = {eng},
	number = {v. 16},
	publisher = {American Mathematical Society},
	author = {Kühnel, Wolfgang},
	year = {2006},
	note = {ZSCC: 0000004 
OCLC: ocm61500086},
	keywords = {Geometry, Differential, Curves, Manifolds (Mathematics), Surfaces},
	file = {Differential geometry - Kühnel - 2006.pdf:/home/theo/Zotero/storage/HVGCAUWF/Differential geometry - Kühnel - 2006.pdf:application/pdf},
}

@misc{KuhnelDifferentialGeometry,
	title = {Kuhnel: {Differential} {Geometry}: {Curves} - {Surfaces} - {Manifolds}, {Second} {Edition}},
	shorttitle = {Kuhnel},
	url = {https://www.ams.org/publications/authors/books/postpub/stml-16-R},
	abstract = {Advancing research. Creating connections.},
	language = {en},
	urldate = {2021-03-11},
	journal = {American Mathematical Society},
	file = {Snapshot:/home/theo/Zotero/storage/Y64TS9AP/stml-16-R.html:text/html},
}

@article{petersenMatrixCookbook,
	title = {Matrix {Cookbook}},
	language = {en},
	author = {Petersen, Kaare Brandt and Pedersen, Michael Syskind},
	keywords = {⛔ No DOI found},
	pages = {72},
	file = {Petersen and Pedersen - [ httpmatrixcookbook.com ].pdf:/home/theo/Zotero/storage/235QHELZ/Petersen and Pedersen - [ httpmatrixcookbook.com ].pdf:application/pdf},
}

@book{zhangMatrixTheory2011,
	address = {New York, NY},
	series = {Universitext},
	title = {Matrix {Theory}},
	isbn = {978-1-4614-1098-0 978-1-4614-1099-7},
	url = {http://link.springer.com/10.1007/978-1-4614-1099-7},
	urldate = {2021-01-26},
	publisher = {Springer New York},
	author = {Zhang, Fuzhen},
	year = {2011},
	doi = {10.1007/978-1-4614-1099-7},
	note = {ZSCC: 0001235 },
	file = {Zhang - 2011 - Matrix Theory.pdf:/home/theo/Zotero/storage/WKT8LYCQ/Zhang - 2011 - Matrix Theory.pdf:application/pdf},
}

@article{nuskenSteinVariationalGradient2021,
	title = {Stein {Variational} {Gradient} {Descent}: many-particle and long-time asymptotics},
	shorttitle = {Stein {Variational} {Gradient} {Descent}},
	url = {http://arxiv.org/abs/2102.12956},
	abstract = {Stein variational gradient descent (SVGD) refers to a class of methods for Bayesian inference based on interacting particle systems. In this paper, we consider the originally proposed deterministic dynamics as well as a stochastic variant, each of which represent one of the two main paradigms in Bayesian computational statistics: variational inference and Markov chain Monte Carlo. As it turns out, these are tightly linked through a correspondence between gradient flow structures and large-deviation principles rooted in statistical physics. To expose this relationship, we develop the cotangent space construction for the Stein geometry, prove its basic properties, and determine the large-deviation functional governing the many-particle limit for the empirical measure. Moreover, we identify the Stein-Fisher information (or kernelised Stein discrepancy) as its leading order contribution in the long-time and many-particle regime in the sense of \${\textbackslash}Gamma\$-convergence, shedding some light on the finite-particle properties of SVGD. Finally, we establish a comparison principle between the Stein-Fisher information and RKHS-norms that might be of independent interest.},
	urldate = {2021-03-10},
	journal = {arXiv:2102.12956 [cs, math, stat]},
	author = {Nüsken, Nikolas and Renger, D. R. Michiel},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.12956},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Mathematics - Numerical Analysis, Mathematics - Statistics Theory, Mathematics - Analysis of PDEs, Mathematics - Probability},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/LK4BRIHB/2102.html:text/html;Stein Variational Gradient Descent - Nüsken_Renger - 2021.pdf:/home/theo/Zotero/storage/7IL37MHN/Stein Variational Gradient Descent - Nüsken_Renger - 2021.pdf:application/pdf},
}

@book{bishopPatternRecognitionMachine2006,
	address = {New York},
	series = {Information science and statistics},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2},
	language = {en},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	year = {2006},
	keywords = {Machine learning, Pattern perception},
	file = {Bishop - 2006 - Pattern recognition and machine learning.pdf:/home/theo/Zotero/storage/REZ37RNP/Bishop - 2006 - Pattern recognition and machine learning.pdf:application/pdf},
}

@article{kimGeneralizationCaffarelliContraction2011,
	title = {A {Generalization} of {Caffarelli}'s {Contraction} {Theorem} via (reverse) {Heat} {Flow}},
	url = {http://arxiv.org/abs/1002.0373},
	abstract = {A theorem of L. Caffarelli implies the existence of a map pushing forward a source Gaussian measure to a target measure which is more log-concave than the source one, which contracts Euclidean distance (in fact, Caffarelli showed that the optimal-transport Brenier map \$T\_\{opt\}\$ is a contraction in this case). We generalize this result to more general source and target measures, using a condition on the third derivative of the potential, using two different proofs. The first uses a map \$T\$, whose inverse is constructed as a flow along an advection field associated to an appropriate heat-diffusion process. The contraction property is then reduced to showing that log-concavity is preserved along the corresponding diffusion semi-group, by using a maximum principle for parabolic PDE. In particular, Caffarelli's original result immediately follows by using the Ornstein-Uhlenbeck process and the Pr{\textbackslash}'ekopa--Leindler Theorem. The second uses the map \$T\_\{opt\}\$ by generalizing Caffarelli's argument, employing in addition further results of Caffarelli. As applications, we obtain new correlation and isoperimetric inequalities.},
	urldate = {2021-03-05},
	journal = {arXiv:1002.0373 [math]},
	author = {Kim, Young-Heon and Milman, Emanuel},
	month = jul,
	year = {2011},
	note = {arXiv: 1002.0373},
	keywords = {Mathematics - Analysis of PDEs, Mathematics - Functional Analysis},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/AG9S5ISB/1002.html:text/html;A Generalization of Caffarelli's Contraction Theorem via (reverse) Heat Flow - Kim_Milman - 2011.pdf:/home/theo/Zotero/storage/9Y3BQ5Q7/A Generalization of Caffarelli's Contraction Theorem via (reverse) Heat Flow - Kim_Milman - 2011.pdf:application/pdf},
}

@article{pitmanCombinatorialStochasticProcesses2006,
	title = {Combinatorial stochastic processes},
	volume = {1875},
	url = {http://www.ams.org/mathscinet/search/publications.html?pg1=MR&s1=MR2245368%5Cnpapers2://publication/uuid/AC1FC13D-01AD-4217-9A7F-1BD693C25F8F},
	abstract = {This is a collection of expository articles about various topics at the interface between enumerative combinatorics and stochastic processes. These articles ex- pand on a course of lectures given at the E ́cole d’E ́t ́e de Probabilit ́es de St. Flour in July 2002. The articles are called ’chapters’ and numbered according to the order of these chapters in a printed volume to appear in Springer Lecture Notes in Mathematics. Each chapter is fairly self-contained, so readers with ad- equate background can start reading any chapter, with occasional consultation of earlier chapters as necessary. Following this Chapter 0, there are 10 chapters, each divided into sections. Most sections conclude with some Exercises. Those for which I don’t know solutions are called Problems.},
	journal = {Combinatorial stochastic processes},
	author = {Pitman, J},
	year = {2006},
	keywords = {⛔ No DOI found},
	pages = {x+256},
	file = {Combinatorial stochastic processes - Pitman - 2006.pdf:/home/theo/Zotero/storage/I2J7K7YJ/Combinatorial stochastic processes - Pitman - 2006.pdf:application/pdf},
}

@article{williamsonDesignApproximationAlgorithms2011,
	title = {The design of approximation algorithms},
	volume = {9780521195},
	doi = {10/gh68xd},
	abstract = {Discrete optimization problems are everywhere, from traditional operations research planning problems, such as scheduling, facility location, and network design; to computer science problems in databases; to advertising issues in viral marketing. Yet most such problems are NP-hard. Thus unless P = NP, there are no efficient algorithms to find optimal solutions to such problems. This book shows how to design approximation algorithms: efficient algorithms that find provably near-optimal solutions. The book is organized around central algorithmic techniques for designing approximation algorithms, including greedy and local search algorithms, dynamic programming, linear and semidefinite programming, and randomization. Each chapter in the first part of the book is devoted to a single algorithmic technique, which is then applied to several different problems. The second part revisits the techniques but offers more sophisticated treatments of them. The book also covers methods for proving that optimization problems are hard to approximate. Designed as a textbook for graduate-level algorithms courses, the book will also serve as a reference for researchers interested in the heuristic solution of discrete optimization problems.},
	journal = {The Design of Approximation Algorithms},
	author = {Williamson, David P. and Shmoys, David B.},
	year = {2011},
	note = {ISBN: 9780511921735},
	keywords = {⚠️ Invalid DOI},
	pages = {1--504},
	file = {The design of approximation algorithms - Williamson_Shmoys - 2011.pdf:/home/theo/Zotero/storage/2UDZGBA9/The design of approximation algorithms - Williamson_Shmoys - 2011.pdf:application/pdf},
}

@article{zhuVarianceReductionQuasiNewton,
	title = {Variance {Reduction} and {Quasi}-{Newton} for {Particle}-{Based} {Variational} {Inference}},
	abstract = {Particle-based Variational Inference methods (ParVIs), like Stein Variational Gradient Descent, are nonparametric variational inference methods that optimize a set of particles to best approximate a target distribution. ParVIs have been proposed as efﬁcient approximate inference algorithms and as potential alternatives to MCMC methods. However, to our knowledge, the quality of the posterior approximation of particles from ParVIs has not been examined before for large-scale Bayesian inference problems. We conduct this analysis and evaluate the sample quality of particles produced by ParVIs, and we ﬁnd that existing ParVI approaches using stochastic gradients converge insufﬁciently fast under sample quality metrics. We propose a novel variance reduction and quasiNewton preconditioning framework for ParVIs, by leveraging the Riemannian structure of the Wasserstein space and advanced Riemannian optimization algorithms. Experimental results demonstrate the accelerated convergence of variance reduction and quasi-Newton methods for ParVIs for accurate posterior inference in large-scale and ill-conditioned problems.},
	language = {en},
	author = {Zhu, Michael H and Liu, Chang and Zhu, Jun},
	note = {ZSCC: 0000000},
	pages = {12},
	file = {Variance Reduction and Quasi-Newton for Particle-Based Variational Inference - Zhu et al -.pdf:/home/theo/Zotero/storage/NIC32XUS/Variance Reduction and Quasi-Newton for Particle-Based Variational Inference - Zhu et al -.pdf:application/pdf;Variance Reduction and Quasi-Newton for Particle-Based Variational Inference - Zhu et al -.pdf:/home/theo/Zotero/storage/BCNP5IJ5/Variance Reduction and Quasi-Newton for Particle-Based Variational Inference - Zhu et al -.pdf:application/pdf;Variance Reduction and Quasi-Newton for Particle-Based Variational Inference - Zhu et al -.pdf:/home/theo/Zotero/storage/6JQGFBDF/Variance Reduction and Quasi-Newton for Particle-Based Variational Inference - Zhu et al -.pdf:application/pdf},
}

@article{gallegoStochasticGradientMCMC2020,
	title = {Stochastic {Gradient} {MCMC} with {Repulsive} {Forces}},
	url = {http://arxiv.org/abs/1812.00071},
	abstract = {We propose a unifying view of two different Bayesian inference algorithms, Stochastic Gradient Markov Chain Monte Carlo (SG-MCMC) and Stein Variational Gradient Descent (SVGD), leading to improved and efficient novel sampling schemes. We show that SVGD combined with a noise term can be framed as a multiple chain SG-MCMC method. Instead of treating each parallel chain independently from others, our proposed algorithm implements a repulsive force between particles, avoiding collapse and facilitating a better exploration of the parameter space. We also show how the addition of this noise term is necessary to obtain a valid SG-MCMC sampler, a significant difference with SVGD. Experiments with both synthetic distributions and real datasets illustrate the benefits of the proposed scheme.},
	urldate = {2021-02-10},
	journal = {arXiv:1812.00071 [cs, stat]},
	author = {Gallego, Victor and Insua, David Rios},
	month = feb,
	year = {2020},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1812.00071},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/5XNCGXSC/1812.html:text/html;Stochastic Gradient MCMC with Repulsive Forces - Gallego_Insua - 2020.pdf:/home/theo/Zotero/storage/W2B82ELX/Stochastic Gradient MCMC with Repulsive Forces - Gallego_Insua - 2020.pdf:application/pdf;arXiv.org Snapshot:/home/theo/Zotero/storage/8SFXDENP/1812.html:text/html;Stochastic Gradient MCMC with Repulsive Forces - Gallego_Insua - 2020.pdf:/home/theo/Zotero/storage/8NQADFGD/Stochastic Gradient MCMC with Repulsive Forces - Gallego_Insua - 2020.pdf:application/pdf},
}

@article{chenSteinPointMarkov2020,
	title = {Stein {Point} {Markov} {Chain} {Monte} {Carlo}},
	url = {http://arxiv.org/abs/1905.03673},
	abstract = {An important task in machine learning and statistics is the approximation of a probability measure by an empirical measure supported on a discrete point set. Stein Points are a class of algorithms for this task, which proceed by sequentially minimising a Stein discrepancy between the empirical measure and the target and, hence, require the solution of a non-convex optimisation problem to obtain each new point. This paper removes the need to solve this optimisation problem by, instead, selecting each new point based on a Markov chain sample path. This significantly reduces the computational cost of Stein Points and leads to a suite of algorithms that are straightforward to implement. The new algorithms are illustrated on a set of challenging Bayesian inference problems, and rigorous theoretical guarantees of consistency are established.},
	urldate = {2020-10-09},
	journal = {arXiv:1905.03673 [math, stat]},
	author = {Chen, Wilson Ye and Barp, Alessandro and Briol, François-Xavier and Gorham, Jackson and Girolami, Mark and Mackey, Lester and Oates, Chris J.},
	month = sep,
	year = {2020},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1905.03673},
	keywords = {Statistics - Machine Learning, Statistics - Computation, Statistics - Methodology, Mathematics - Statistics Theory},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/XZ3CC2AV/1905.html:text/html;Stein Point Markov Chain Monte Carlo - Chen et al - 2020.pdf:/home/theo/Zotero/storage/E5SRIWRI/Stein Point Markov Chain Monte Carlo - Chen et al - 2020.pdf:application/pdf;arXiv.org Snapshot:/home/theo/Zotero/storage/KDHRFXWA/1905.html:text/html;Stein Point Markov Chain Monte Carlo - Chen et al - 2020.pdf:/home/theo/Zotero/storage/LAZCNESA/Stein Point Markov Chain Monte Carlo - Chen et al - 2020.pdf:application/pdf},
}

@article{zhangNoisyNaturalGradient2018,
	title = {Noisy {Natural} {Gradient} as {Variational} {Inference}},
	url = {http://arxiv.org/abs/1712.02390},
	abstract = {Variational Bayesian neural nets combine the flexibility of deep learning with Bayesian uncertainty estimation. Unfortunately, there is a tradeoff between cheap but simple variational families (e.g.{\textasciitilde}fully factorized) or expensive and complicated inference procedures. We show that natural gradient ascent with adaptive weight noise implicitly fits a variational posterior to maximize the evidence lower bound (ELBO). This insight allows us to train full-covariance, fully factorized, or matrix-variate Gaussian variational posteriors using noisy versions of natural gradient, Adam, and K-FAC, respectively, making it possible to scale up to modern-size ConvNets. On standard regression benchmarks, our noisy K-FAC algorithm makes better predictions and matches Hamiltonian Monte Carlo's predictive variances better than existing methods. Its improved uncertainty estimates lead to more efficient exploration in active learning, and intrinsic motivation for reinforcement learning.},
	urldate = {2020-10-08},
	journal = {arXiv:1712.02390 [cs, stat]},
	author = {Zhang, Guodong and Sun, Shengyang and Duvenaud, David and Grosse, Roger},
	month = feb,
	year = {2018},
	note = {ZSCC: 0000073 
arXiv: 1712.02390},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/T34FWXYT/1712.html:text/html;Noisy Natural Gradient as Variational Inference - Zhang et al - 2018.pdf:/home/theo/Zotero/storage/VE3EUVKX/Noisy Natural Gradient as Variational Inference - Zhang et al - 2018.pdf:application/pdf;arXiv.org Snapshot:/home/theo/Zotero/storage/KIFPJQXN/1712.html:text/html;Noisy Natural Gradient as Variational Inference - Zhang et al - 2018.pdf:/home/theo/Zotero/storage/X2K8L63J/Noisy Natural Gradient as Variational Inference - Zhang et al - 2018.pdf:application/pdf},
}

@article{saMinibatchGibbsSampling,
	title = {Minibatch {Gibbs} {Sampling} on {Large} {Graphical} {Models}},
	abstract = {Gibbs sampling is the de facto Markov chain Monte Carlo method used for inference and learning on large scale graphical models. For complicated factor graphs with lots of factors, the performance of Gibbs sampling can be limited by the computational cost of executing a single update step of the Markov chain. This cost is proportional to the degree of the graph, the number of factors adjacent to each variable. In this paper, we show how this cost can be reduced by using minibatching: subsampling the factors to form an estimate of their sum. We introduce several minibatched variants of Gibbs, show that they can be made unbiased, prove bounds on their convergence rates, and show that under some conditions they can result in asymptotic single-update-runtime speedups over plain Gibbs sampling.},
	language = {en},
	author = {Sa, Christopher De and Chen, Vincent and Wong, Wing},
	note = {ZSCC: 0000008},
	pages = {9},
	file = {Minibatch Gibbs Sampling on Large Graphical Models - Sa et al -.pdf:/home/theo/Zotero/storage/DRG2BPT8/Minibatch Gibbs Sampling on Large Graphical Models - Sa et al -.pdf:application/pdf;Minibatch Gibbs Sampling on Large Graphical Models - Sa et al -.pdf:/home/theo/Zotero/storage/PKVSQAPH/Minibatch Gibbs Sampling on Large Graphical Models - Sa et al -.pdf:application/pdf},
}

@article{hensmanMCMCVariationallySparse2015,
	title = {{MCMC} for {Variationally} {Sparse} {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/1506.04000},
	abstract = {Gaussian process (GP) models form a core part of probabilistic machine learning. Considerable research effort has been made into attacking three issues with GP models: how to compute efficiently when the number of data is large; how to approximate the posterior when the likelihood is not Gaussian and how to estimate covariance function parameter posteriors. This paper simultaneously addresses these, using a variational approximation to the posterior which is sparse in support of the function but otherwise free-form. The result is a Hybrid Monte-Carlo sampling scheme which allows for a non-Gaussian approximation over the function values and covariance parameters simultaneously, with efficient computations based on inducing-point sparse GPs. Code to replicate each experiment in this paper will be available shortly.},
	urldate = {2021-01-08},
	journal = {arXiv:1506.04000 [stat]},
	author = {Hensman, James and Matthews, Alexander G. de G. and Filippone, Maurizio and Ghahramani, Zoubin},
	month = jun,
	year = {2015},
	note = {ZSCC: 0000090 
arXiv: 1506.04000},
	keywords = {Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/TVVE6TI9/1506.html:text/html;MCMC for Variationally Sparse Gaussian Processes - Hensman et al - 2015.pdf:/home/theo/Zotero/storage/XH3XYHWC/MCMC for Variationally Sparse Gaussian Processes - Hensman et al - 2015.pdf:application/pdf},
}

@book{murphyMachineLearningProbabilistic2012,
	address = {Cambridge, MA},
	series = {Adaptive computation and machine learning series},
	title = {Machine learning: a probabilistic perspective},
	isbn = {978-0-262-01802-9},
	shorttitle = {Machine learning},
	language = {en},
	publisher = {MIT Press},
	author = {Murphy, Kevin P.},
	year = {2012},
	note = {ZSCC: 0007949},
	keywords = {Machine learning, Probabilities},
	file = {Machine learning - Murphy - 2012.pdf:/home/theo/Zotero/storage/F5NX79LZ/Machine learning - Murphy - 2012.pdf:application/pdf;Machine Learning - P. Murphy - 1991.pdf:/home/theo/Zotero/storage/86RLMUIX/Machine Learning - P. Murphy - 1991.pdf:application/pdf},
}

@article{jospinHandsonBayesianNeural2020a,
	title = {Hands-on {Bayesian} {Neural} {Networks} -- a {Tutorial} for {Deep} {Learning} {Users}},
	url = {http://arxiv.org/abs/2007.06823},
	abstract = {Modern deep learning methods have equipped researchers and engineers with incredibly powerful tools to tackle problems that previously seemed impossible. However, since deep learning methods operate as black boxes, the uncertainty associated with their predictions is often challenging to quantify. Bayesian statistics offer a formalism to understand and quantify the uncertainty associated with deep neural networks predictions. This paper provides a tutorial for researchers and scientists who are using machine learning, especially deep learning, with an overview of the relevant literature and a complete toolset to design, implement, train, use and evaluate Bayesian neural networks.},
	urldate = {2020-12-18},
	journal = {arXiv:2007.06823 [cs, stat]},
	author = {Jospin, Laurent Valentin and Buntine, Wray and Boussaid, Farid and Laga, Hamid and Bennamoun, Mohammed},
	month = jul,
	year = {2020},
	note = {ZSCC: 0000007 
arXiv: 2007.06823},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found, Computer Science - Machine Learning, I.2.6, 62-02 (Primary), G.3},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/PZZ26NJH/2007.html:text/html;Hands-on Bayesian Neural Networks -- a Tutorial for Deep Learning Users - Jospin et al - 2020.pdf:/home/theo/Zotero/storage/Y3WYNUHD/Hands-on Bayesian Neural Networks -- a Tutorial for Deep Learning Users - Jospin et al - 2020.pdf:application/pdf;arXiv.org Snapshot:/home/theo/Zotero/storage/7SDIHMLZ/2007.html:text/html;Hands-on Bayesian Neural Networks -- a Tutorial for Deep Learning Users - Jospin et al - 2020.pdf:/home/theo/Zotero/storage/KPL3M254/Hands-on Bayesian Neural Networks -- a Tutorial for Deep Learning Users - Jospin et al - 2020.pdf:application/pdf;arXiv.org Snapshot:/home/theo/Zotero/storage/2ETVXRGF/2007.html:text/html;Hands-on Bayesian Neural Networks -- a Tutorial for Deep Learning Users - Jospin et al - 2020.pdf:/home/theo/Zotero/storage/TVFRER4F/Hands-on Bayesian Neural Networks -- a Tutorial for Deep Learning Users - Jospin et al - 2020.pdf:application/pdf},
}

@book{villaniTopicsOptimalTransportation2003,
	address = {Providence, RI},
	series = {Graduate studies in mathematics},
	title = {Topics in optimal transportation},
	isbn = {978-0-8218-3312-4},
	number = {v. 58},
	publisher = {American Mathematical Society},
	author = {Villani, Cédric},
	year = {2003},
	note = {ZSCC: 0004573},
	keywords = {Monge-Ampère equations, Transportation problems (Programming)},
	file = {Topics in optimal transportation - Villani - 2003.pdf:/home/theo/Zotero/storage/A6QVDTHM/Topics in optimal transportation - Villani - 2003.pdf:application/pdf;Topics in optimal transportation - Villani - 2003.djvu:/home/theo/Zotero/storage/VGIVV7VU/Topics in optimal transportation - Villani - 2003.djvu:image/vnd.djvu},
}

@article{jainiSumofSquaresPolynomialFlow,
	title = {Sum-of-{Squares} {Polynomial} {Flow}},
	abstract = {Triangular map is a recent construct in probability theory that allows one to transform any source probability density function to any target density function. Based on triangular maps, we propose a general framework for high-dimensional density estimation, by specifying one-dimensional transformations (equivalently conditional densities) and appropriate conditioner networks. This framework (a) reveals the commonalities and differences of existing autoregressive and ﬂow based methods, (b) allows a uniﬁed understanding of the limitations and representation power of these recent approaches and, (c) motivates us to uncover a new Sum-of-Squares (SOS) ﬂow that is interpretable, universal, and easy to train. We perform several synthetic experiments on various density geometries to demonstrate the beneﬁts (and shortcomings) of such transformations. SOS ﬂows achieve competitive results in simulations and several real-world datasets.},
	language = {en},
	author = {Jaini, Priyank and Selby, Kira A and Yu, Yaoliang},
	note = {ZSCC: 0000044},
	pages = {10},
	file = {Sum-of-Squares Polynomial Flow - Jaini et al -.pdf:/home/theo/Zotero/storage/DYP7LRJC/Sum-of-Squares Polynomial Flow - Jaini et al -.pdf:application/pdf},
}

@book{villaniOptimalTransportOld2009,
	address = {Berlin},
	series = {Grundlehren der mathematischen {Wissenschaften}},
	title = {Optimal transport: old and new},
	isbn = {978-3-540-71049-3},
	shorttitle = {Optimal transport},
	language = {en},
	number = {338},
	publisher = {Springer},
	author = {Villani, Cédric},
	year = {2009},
	note = {ZSCC: 0000000 
OCLC: ocn244421231},
	keywords = {Geometry, Differential, Probabilities, Transportation problems (Programming), Dynamics, Dynamique, Géométrie différentielle, Mathematical optimization, Optimisation mathématique, Probabilités, Problèmes de transport (Programmation)},
	file = {Optimal transport - Villani - 2009.pdf:/home/theo/Zotero/storage/MADXNN58/Optimal transport - Villani - 2009.pdf:application/pdf},
}

@inproceedings{gorinovaAutomaticReparameterisationProbabilistic2020,
	title = {Automatic {Reparameterisation} of {Probabilistic} {Programs}},
	url = {http://proceedings.mlr.press/v119/gorinova20a.html},
	abstract = {Probabilistic programming has emerged as a powerful paradigm in statistics, applied science, and machine learning: by decoupling modelling from inference, it promises to allow modellers to directly...},
	language = {en},
	urldate = {2021-03-04},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Gorinova, Maria and Moore, Dave and Hoffman, Matthew},
	month = nov,
	year = {2020},
	note = {ZSCC: 0000004 
ISSN: 2640-3498},
	pages = {3648--3657},
	file = {Snapshot:/home/theo/Zotero/storage/FGURQXF6/gorinova20a.html:text/html;Automatic Reparameterisation of Probabilistic Programs - Gorinova et al - 2020.pdf:/home/theo/Zotero/storage/EH6Q9XW8/Automatic Reparameterisation of Probabilistic Programs - Gorinova et al - 2020.pdf:application/pdf},
}

@article{buschmanSubstitutionFormulasLaplace,
	title = {Substitution {Formulas} for {Laplace} {Transformations}},
	language = {en},
	author = {Buschman, R G},
	note = {ZSCC: 0000001},
	pages = {3},
	file = {Substitution Formulas for Laplace Transformations - Buschman -.pdf:/home/theo/Zotero/storage/TDMMJCRA/Substitution Formulas for Laplace Transformations - Buschman -.pdf:application/pdf},
}

@article{kimberlingProbabilisticInterpretationComplete1974,
	title = {A probabilistic interpretation of complete monotonicity},
	volume = {10},
	issn = {1420-8903},
	url = {https://doi.org/10.1007/BF01832852},
	doi = {10.1007/BF01832852},
	language = {en},
	number = {2},
	urldate = {2021-02-25},
	journal = {aequationes mathematicae},
	author = {Kimberling, Clark H.},
	month = jun,
	year = {1974},
	note = {ZSCC: 0000274},
	pages = {152--164},
	file = {A probabilistic interpretation of complete monotonicity - Kimberling - 1974.pdf:/home/theo/Zotero/storage/8GWIR4RB/A probabilistic interpretation of complete monotonicity - Kimberling - 1974.pdf:application/pdf},
}

@article{titsiasMarkovChainMonte2011,
	title = {Markov chain {Monte} {Carlo} algorithms for {Gaussian} processes},
	volume = {9780521196},
	doi = {10.1017/CBO9780511984679.015},
	abstract = {© Cambridge University Press 2011. Gaussian processes (GPs) have a long history in statistical physics and mathematical probability. Two of the most well-studied stochastic processes, Brownian motion [12, 47] and the Ornstein–Uhlenbeck process [43], are instances of GPs. In the context of regression and statistical learning, GPs have been used extensively in applications that arise in geostatistics and experimental design [26, 45, 7, 40]. More recently, in the machine learning literature, GPs have been considered as general estimation tools for solving problems such as non-linear regression and classification [29]. In the context of machine learning, GPs offer a flexible nonparametric Bayesian framework for estimating latent functions from data and they share similarities with neural networks [23] and kernel methods [35]. In standard GP regression, where the likelihood is Gaussian, the posterior over the latent function (given data and hyperparameters) is described by a new GP that is obtained analytically. In all other cases, where the likelihood function is non-Gaussian, exact inference is intractable and approximate inference methods are needed. Deterministic approximate methods are currently widely used for inference in GP models [48, 16, 8, 29, 19, 34]. However, they are limited by an assumption that the likelihood function factorises. In addition, these methods usually treat the hyperparameters of the model (the parameters that appear in the likelihood and the kernel function) in a non full Bayesian way by providing only point estimates.},
	number = {Mcmc},
	journal = {Bayesian Time Series Models},
	author = {Titsias, Michalis K. and Rattray, Magnus and Lawrence, Neil D.},
	year = {2011},
	note = {ISBN: 9780511984679},
	pages = {295--316},
	file = {Markov chain Monte Carlo algorithms for Gaussian processes - Titsias et al - 2011.pdf:/home/theo/Zotero/storage/BWGEQS6P/Markov chain Monte Carlo algorithms for Gaussian processes - Titsias et al - 2011.pdf:application/pdf},
}

@article{andrewsd.f;mallowsScaleMixturesNormal2012,
	title = {Scale {Mixtures} of {Normal} {Distributions}},
	volume = {36},
	url = {http://www.jstor.org/stable/2984774%20.},
	abstract = {This paper presents necessary and sufficient conditions under which a random variable X may be generated as the ratio ZI V where Z and V are independent and Z has a standard normal distribution. This representation is useful in Monte Carlo calculations. It is established that when 7 V2 is exponential, X is double exponential; and that when WV has the asymptotic distribution of the Kolmogorov distance statistic, X is logistic},
	number = {1},
	journal = {Royal Statistical Society},
	author = {Andrews , D. F; Mallows, C. L},
	year = {2012},
	pages = {99--102},
}

@article{saulChainedGaussianProcesses2016,
	title = {Chained {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/1604.05263},
	abstract = {Gaussian process models are flexible, Bayesian non-parametric approaches to regression. Properties of multivariate Gaussians mean that they can be combined linearly in the manner of additive models and via a link function (like in generalized linear models) to handle non-Gaussian data. However, the link function formalism is restrictive, link functions are always invertible and must convert a parameter of interest to a linear combination of the underlying processes. There are many likelihoods and models where a non-linear combination is more appropriate. We term these more general models Chained Gaussian Processes: the transformation of the GPs to the likelihood parameters will not generally be invertible, and that implies that linearisation would only be possible with multiple (localized) links, i.e. a chain. We develop an approximate inference procedure for Chained GPs that is scalable and applicable to any factorized likelihood. We demonstrate the approximation on a range of likelihood functions.},
	author = {Saul, Alan D. and Hensman, James and Vehtari, Aki and Lawrence, Neil D.},
	year = {2016},
	note = {arXiv: 1604.05263},
	pages = {1--23},
	file = {Chained Gaussian Processes - Saul et al - 2016.pdf:/home/theo/Zotero/storage/4N6HWRNM/Chained Gaussian Processes - Saul et al - 2016.pdf:application/pdf},
}

@article{vandykArtDataAugmentation2006,
	title = {The {Art} of {Data} {Augmentation}},
	volume = {10},
	doi = {10.1002/9781118413357},
	abstract = {Today, with big data and its implications so important to citizenship and society, artists are at the forefront of helping us see and understand data in altogether new ways. And the questions they ask help us process our collective anxiety and fascin...},
	number = {1},
	author = {VAN DYK, David A. and MENG, Xiao-Li},
	year = {2006},
	note = {ISBN: 9781118411315},
	keywords = {Guidelines for Preparing Good, Types of Variables},
	pages = {1--37},
	file = {The Art of Data Augmentation - VAN DYK_MENG - 2006.pdf:/home/theo/Zotero/storage/BUJ2I7HB/The Art of Data Augmentation - VAN DYK_MENG - 2006.pdf:application/pdf},
}

@article{ruizContrastiveDivergenceCombining2019,
	title = {A {Contrastive} {Divergence} for {Combining} {Variational} {Inference} and {MCMC}},
	url = {http://arxiv.org/abs/1905.04062},
	abstract = {We develop a method to combine Markov chain Monte Carlo (MCMC) and variational inference (VI), leveraging the advantages of both inference approaches. Specifically, we improve the variational distribution by running a few MCMC steps. To make inference tractable, we introduce the variational contrastive divergence (VCD), a new divergence that replaces the standard Kullback-Leibler (KL) divergence used in VI. The VCD captures a notion of discrepancy between the initial variational distribution and its improved version (obtained after running the MCMC steps), and it converges asymptotically to the symmetrized KL divergence between the variational distribution and the posterior of interest. The VCD objective can be optimized efficiently with respect to the variational parameters via stochastic optimization. We show experimentally that optimizing the VCD leads to better predictive performance on two latent variable models: logistic matrix factorization and variational autoencoders (VAEs).},
	author = {Ruiz, Francisco J. R. and Titsias, Michalis K.},
	year = {2019},
	note = {arXiv: 1905.04062},
	file = {A Contrastive Divergence for Combining Variational Inference and MCMC - Ruiz_Titsias - 2019.pdf:/home/theo/Zotero/storage/EPQYND8A/A Contrastive Divergence for Combining Variational Inference and MCMC - Ruiz_Titsias - 2019.pdf:application/pdf},
}

@article{bentonFunctionspaceDistributionsKernels2006,
	title = {Function-space {Distributions} over {Kernels}},
	author = {Benton, Greg and Salkey, Jayson and Maddox, Wesley and Albinati, Julio and Gordon, Andrew},
	year = {2006},
}

@article{banachFonctionsAbsolumentContinues1928,
	title = {Sur les fonctions absolument continues des fonctions absolument continues},
	volume = {11},
	issn = {0016-2736},
	doi = {10.4064/fm-11-1-113-116},
	journal = {Fundamenta Mathematicae},
	author = {Banach, Stefan and Saks, Stanisław},
	year = {1928},
	pages = {113--116},
}

@article{palmerVariationalScaleMixture2006,
	title = {Variational and {Scale} {Mixture} {Representations} of {Non}-{Gaussian} {Densities} for {Estimation}},
	journal = {Thesis},
	author = {Palmer, Jason Allan},
	year = {2006},
	note = {ISBN: 9783540773405},
}

@article{ilienkoContinuousCounterpartsPoisson2013,
	title = {Continuous counterparts of {Poisson} and binomial distributions and their properties},
	volume = {39},
	url = {http://arxiv.org/abs/1303.5990},
	abstract = {On the basis of integral representations of Poisson and binomial distribution functions via complete and incomplete Euler {\textbackslash}Gamma- and B-functions, we introduce and discuss continuous counterparts of the Poisson and binomial distributions. The former turns out to be closely related to classical Volterra functions as well. Under usual conditions, we also prove that the sequence of continuous binomial distributions converges weakly to the continuous Poisson one. At the end, we discuss a relationship between the continuous Poisson distribution and the {\textbackslash}Gamma-process.},
	author = {Ilienko, Andrii},
	year = {2013},
	note = {arXiv: 1303.5990},
	keywords = {2010 mathematics subject classification, and phrases, binomial distribution, continuous counterparts, gamma process, poisson distribution, primary 60e05, secondary 33e20, supported by dfg grant, this work is partially, volterra functions},
	pages = {137--147},
}

@article{cerfProbabilisticProofSchoeberg2018,
	title = {A probabilistic proof of {Schoeberg}'s theorem},
	url = {http://arxiv.org/abs/1801.05252},
	abstract = {We present an alternative proof of Perron's theorem, which is probabilistic in nature. It rests on the representation of the Perron eigenvector as a functional of the trajectory of an auxiliary Markov chain.},
	author = {Cerf, Raphaël and Dalmau, Joseba},
	year = {2018},
	note = {arXiv: 1801.05252},
	keywords = {evy process, hartman, l, negative definite function, subordination, transition density, wintner condition},
}

@article{wuCompactlySupportedPositive1995,
	title = {Compactly supported positive definite radial functions},
	volume = {4},
	issn = {10197168},
	doi = {10.1007/BF03177517},
	abstract = {We provide criteria for positive definiteness of radial functions with compact support. Based on these criteria we will produce a series of positive definite and compactly supported radial functions, which will be very useful in applications. The simplest ones are cut-off poly-nomials, which consist of a single polynomial piece on [0,1] and vanish on [1,{\textasciitilde}). More precisely, for any given dimension n and prescribed C k smoothness, there is a function in Ck(R"), which is a positive definite radial function with compact support and is a cut-off polynomial as a function of Euclidean distance. Another example is derived from odd-degree B-splines.},
	number = {1},
	journal = {Advances in Computational Mathematics},
	author = {Wu, Zongmin},
	year = {1995},
	keywords = {approximation, AMS subject classification: 41A15, 41A25, 41A30, 4, Compact support, positive definite, radial function, scattered data interpolation},
	pages = {283--292},
	file = {Compactly supported positive definite radial functions - Wu - 1995.pdf:/home/theo/Zotero/storage/3TR3Y3GA/Compactly supported positive definite radial functions - Wu - 1995.pdf:application/pdf},
}

@article{opperGeneralBoundsBayes1999,
	title = {General {Bounds} on {Bayes} {Errors} for {Regression} with {Gaussian} {Processes}},
	issn = {10495258},
	journal = {Advances in Neural Information Processing Systems},
	author = {Opper, Manfred and Vivarelli, Francesco},
	year = {1999},
	note = {ISBN: 0262112450},
	pages = {302--308},
}

@book{cohenNumericalMethodsLaplace2013,
	title = {numerical methods for {Laplace} transform inversion},
	volume = {53},
	isbn = {978-85-7811-079-6},
	abstract = {The Laplace transform, as its name implies, can be traced back to the work of the Marquis Pierre-Simon de Laplace (1749-1827). Strange as it may seem no reference is made to Laplace transforms in Rouse Ball’s “A Short Account of the History of Mathematics”. Rouse Ball does refer to Laplace’s contribution to Probability Theory and his use of the generating function.},
	author = {Cohen, Alan M.},
	year = {2013},
	pmid = {25246403},
	doi = {10.1017/CBO9781107415324.004},
	note = {arXiv: 1011.1669v3
Publication Title: Journal of Chemical Information and Modeling
Issue: 9
ISSN: 1098-6596},
	keywords = {icle},
}

@article{schreiterEfficientSparsificationGaussian2016,
	title = {Efficient sparsification for {Gaussian} process regression},
	volume = {192},
	issn = {18728286},
	url = {http://dx.doi.org/10.1016/j.neucom.2016.02.032},
	doi = {10.1016/j.neucom.2016.02.032},
	abstract = {Sparse Gaussian process models provide an efficient way to perform regression on large data sets. Sparsification approaches deal with the selection of a representative subset of available training data for inducing the sparse model approximation. A variety of insertion and deletion criteria have been proposed, but they either lack accuracy or suffer from high computational costs. In this paper, we present a new and straightforward criterion for successive selection and deletion of training points in sparse Gaussian process regression. The proposed novel strategies for sparsification are as fast as the purely randomized schemes and, thus, appropriate for applications in online learning. Experiments on real-world robot data demonstrate that our obtained regression models are competitive with the computationally intensive state-of-the-art methods in terms of generalization and accuracy. Furthermore, we employ our approach in learning inverse dynamics models for compliant robot control using very large data sets, i.e. with half a million training points. In this experiment, it is also shown that our approximated sparse Gaussian process model is sufficiently fast for real-time prediction in robot control.},
	number = {March},
	journal = {Neurocomputing},
	author = {Schreiter, Jens and Nguyen-Tuong, Duy and Toussaint, Marc},
	year = {2016},
	note = {Publisher: Elsevier},
	keywords = {Gaussian processes, Greedy subset selection, Learning robot inverse dynamics, Sparse approximations},
	pages = {29--37},
}

@article{correspStreamingStochasticVariational,
	title = {Streaming stochastic variational {Bayes} ; {An} improved approach for {Bayesian} inference with data streams {Streaming} {Stochastic} {Variational} {Bayes} ; {An} {Improved} {Approach} for {Bayesian} {Inference} with {Data} {Streams}},
	author = {Corresp, Nadheesh Jihan and Jayasinghe, Malith and Perera, Srinath and Jihan, Nadheesh and Jayasinghe, Malith and Perera, Srinath},
}

@article{bryanElementaryInversionLaplace2006,
	title = {Elementary inversion of the {Laplace} transform},
	abstract = {This paper provides an elementary derivation of a very simple " closed-form " inversion formula for the Laplace Transform.},
	journal = {Preprint},
	author = {Bryan, Kurt},
	year = {2006},
	keywords = {ams subject classifications, inverse laplace transform, laplace transform},
	pages = {1--10},
}

@article{TheoryReproducingKernels2009,
	title = {Theory of {Reproducing} {Kernels} {Author} ( s ): {N} . {Aronszajn} {Source} : {Transactions} of the {American} {Mathematical} {Society} , {Vol} . 68 , {No} . 3 ( {May} , 1950 ), pp . {Published} by : {American} {Mathematical} {Society} {Stable} {URL} : http://www.jstor.org/stable/1990404},
	volume = {68},
	number = {3},
	journal = {Society},
	year = {2009},
	pages = {337--404},
}

@article{jaakkolaVariationalApproachBayesian1997a,
	title = {A {Variational} {Approach} to {Bayesian} {Logistic} {Regression} {Models} and {Their} {Extensions}},
	url = {https://www.researchgate.net/publication/2365311%0Apapers3://publication/uuid/936889F6-03D0-45CD-B612-E85BDDD8C4E0},
	doi = {10.1.1.49.5049},
	abstract = {Jaakkola and (1996). methods should be contrasted with sampling techniques (Neal 1994) that have become standard in the context of},
	number = {82},
	journal = {Sixth International Workshop on Artificial Intelligence and Statistics},
	author = {Jaakkola, Tommi S and Jordan, Michael I},
	year = {1997},
	note = {ISBN: 9702},
}

@article{chauveauHowCompareMCMC2007,
	title = {How to compare {MCMC} simulation strategies ? {To} cite this version : {HAL} {Id} : hal-00019174 {How} to compare {MCMC} simulation strategies ?},
	author = {Chauveau, Didier and Vandekerkhove, Pierre and Chauveau, Didier and Vandekerkhove, Pierre},
	year = {2007},
}

@article{abateInfiniteseriesRepresentationsLaplace1999,
	title = {Infinite-series representations of laplace transforms of probability density functions for numerical inversion},
	volume = {42},
	issn = {04534514},
	doi = {10.15807/jorsj.42.268},
	abstract = {In order to numerically invert Laplace transforms to calculate probability density functions (pdf's) and cumulative distribution functions (cdf's) in queueing and related models, we need to be able to calculate the Laplace transform values. In many cases the desired Laplace transform values (e.g., of a waiting-time cdf) can be computed when the Laplace transform values of component pdf's (e.g., of a service-time pdf) can be computed. However, there are few explicit expressions for Laplace transforms of component pdf's available when the pdf does not have a pure exponential tail. In order to remedy this problem, we propose the construction of infinite-series representations for Laplace transforms of pdf's and show how they can be used to calculate transform values. We use the Laplace transforms of exponential pdf's, Laguerre functions and Erlang pdf's as basis elements in the series representations. We develop several specific parametric families of pdf's in this infinite-series framework. We show how to determine the asymptotic form of the pdf from the series representation and how to truncate so as to preserve the asymptotic form for a time of interest.},
	number = {3},
	journal = {Journal of the Operations Research Society of Japan},
	author = {Abate, Joseph and Whitt, Ward},
	year = {1999},
	pages = {268--285},
}

@article{torquatoEffectDimensionalityContinuum2012,
	title = {Effect of dimensionality on the continuum percolation of overlapping hyperspheres and hypercubes. {II}. {Simulation} results and analyses},
	volume = {137},
	issn = {00219606},
	doi = {10.1063/1.4742750},
	abstract = {In the first paper of this series [S. Torquato, J. Chem. Phys. \{{\textbackslash}bf 136\}, 054106 (2012)], analytical results concerning the continuum percolation of overlapping hyperparticles in \$d\$-dimensional Euclidean space \${\textbackslash}mathbb\{R\}{\textasciicircum}d\$ were obtained, including lower bounds on the percolation threshold. In the present investigation, we provide additional analytical results for certain cluster statistics, such as the concentration of \$k\$-mers and related quantities, and obtain an upper bound on the percolation threshold \${\textbackslash}eta\_c\$. We utilize the tightest lower bound obtained in the first paper to formulate an efficient simulation method, called the \{{\textbackslash}it rescaled-particle\} algorithm, to estimate continuum percolation properties across many space dimensions with heretofore unattained accuracy. This simulation procedure is applied to compute the threshold \${\textbackslash}eta\_c\$ and associated mean number of overlaps per particle \$\{{\textbackslash}cal N\}\_c\$ for both overlapping hyperspheres and oriented hypercubes for \$ 3 {\textbackslash}le d {\textbackslash}le 11\$. These simulations results are compared to corresponding upper and lower bounds on these percolation properties. We find that the bounds converge to one another as the space dimension increases, but the lower bound provides an excellent estimate of \${\textbackslash}eta\_c\$ and \$\{{\textbackslash}cal N\}\_c\$, even for relatively low dimensions. We confirm a prediction of the first paper in this series that low-dimensional percolation properties encode high-dimensional information. We also show that the concentration of monomers dominate over concentration values for higher-order clusters (dimers, trimers, etc.) as the space dimension becomes large. Finally, we provide accurate analytical estimates of the pair connectedness function and blocking function at their contact values for any \$d\$ as a function of density.},
	number = {7},
	journal = {Journal of Chemical Physics},
	author = {Torquato, S. and Jiao, Y.},
	year = {2012},
}

@article{abateLaguerreMethodNumerically2008,
	title = {On the {Laguerre} {Method} for {Numerically} {Inverting} {Laplace} {Transforms}},
	volume = {8},
	issn = {1091-9856},
	doi = {10.1287/ijoc.8.4.413},
	abstract = {... developed variant of the Fourier -series method to calculate the coefficients of the Laguerre gener- ... ometrically fast . ... Queues, algorithms: Laplace transform inversion . Keywords: numerical transform inversion , Laplace transforms , Laguerre polynomials, Weeks' algo- ... {\textbackslash}n},
	number = {4},
	journal = {INFORMS Journal on Computing},
	author = {Abate, Joseph and Choudhury, Gagan L. and Whitt, Ward},
	year = {2008},
	pages = {413--427},
}

@article{hensmanVariationalFourierFeatures2016,
	title = {Variational {Fourier} features for {Gaussian} processes},
	volume = {18},
	url = {http://arxiv.org/abs/1611.06740},
	abstract = {This work brings together two powerful concepts in Gaussian processes: the variational approach to sparse approximation and the spectral representation of Gaussian processes. This gives rise to an approximation that inherits the benefits of the variational approach but with the representational power and computational scalability of spectral representations. The work hinges on a key result that there exist spectral features related to a finite domain of the Gaussian process which exhibit almost-independent covariances. We derive these expressions for Matern kernels in one dimension, and generalize to more dimensions using kernels with specific structures. Under the assumption of additive Gaussian noise, our method requires only a single pass through the dataset, making for very fast and accurate computation. We fit a model to 4 million training points in just a few minutes on a standard laptop. With non-conjugate likelihoods, our MCMC scheme reduces the cost of computation from O(NM2) (for a sparse Gaussian process) to O(NM) per iteration, where N is the number of data and M is the number of features.},
	author = {Hensman, James and Durrande, Nicolas and Solin, Arno},
	year = {2016},
	note = {arXiv: 1611.06740},
	keywords = {gaussian processes, variational inference, fourier features},
	pages = {1--52},
}

@article{kershnerNumberCirclesCovering2012,
	title = {The {Number} of {Circles} {Covering} a {Set}},
	volume = {61},
	number = {3},
	author = {Kershner, Richard},
	year = {2012},
	pages = {665--671},
	file = {The Number of Circles Covering a Set - Kershner - 2012.pdf:/home/theo/Zotero/storage/CN4ME3B8/The Number of Circles Covering a Set - Kershner - 2012.pdf:application/pdf},
}

@article{goldschmidtApproximationAlgorithmsClique2005,
	title = {Approximation {Algorithms} for the k -{Clique} {Covering} {Problem}},
	volume = {9},
	issn = {0895-4801},
	doi = {10.1137/s089548019325232x},
	abstract = {The problem of covering edges and vertices in a graph (or in a hypergraph) was motivated by a problem arising in the context of the component assembly problem. The problem is as follows: given a graph and a clique size k, find the minimum number of k-cliques such that all edges and vertices of the graph are covered by (included in) the cliques. This paper provides a collection of approximation algorithms for various clique sizes with proven worst-case bounds. The problem has a natural extension to hypergraphs, for which we consider one particular class. The k-clique covering problem can be formulated as a set covering problem. It is shown that the algorithms we design, which exploit the structure of this special set covering problem, have better performance than those derived from direct applications of general purpose algorithms for the set covering. In particular, these special classes of set covering problems can be solved with better worst-case bounds and/or complexity than if treated as general set covering problems.},
	number = {3},
	journal = {SIAM Journal on Discrete Mathematics},
	author = {Goldschmidt, Oliver and Hochbaum, Dorit S. and Hurkens, Cor and Yu, Gang},
	year = {2005},
	pages = {492--509},
}

@book{pardalosConvexOptimizationTheory2010,
	title = {Convex optimization theory},
	volume = {25},
	isbn = {978-0-521-83378-3},
	url = {http://www.tandfonline.com/doi/abs/10.1080/10556781003625177},
	abstract = {Engineering tools and mathematical optimization are applied in this study to plan the work of the agents of the cow artificial insemination service (inseminator) in Israel. Time is crucial in insemination as the chances of conception decline with increasing delay between the start of estrus and insemination. About 1,090 artificial inseminations of cows are performed daily in Israel. They involve 412 farms in 283 villages, and are performed by 29 inseminators; the work plan should balance the work load among the inseminators. To this end, the working time of an inseminator in each village is required. Thus, a model to predict the working time in a village was developed. Subsequently, a mathematical optimization model was designed and solved, which aims to allocate customers to trips and to determine the itinerary of each trip to minimize total distance/time. The main benefits included a 21.4\% reduction in total traveling time and a 55\% reduction in the difference between the lengths of the longest and shortest working days. Moreover, the longest delay in reaching an estrous cow is reduced from 7.6 to 5.9 h (i.e., by 1.7 h), which may increase the conception ratio by some 7\%. In addition, the trade-off between work balance and total traveling time was studied.},
	author = {Pardalos, Panos M.},
	year = {2010},
	doi = {10.1080/10556781003625177},
	note = {Publication Title: Optimization Methods and Software
Issue: 3
ISSN: 1055-6788},
	file = {Convex optimization theory - Pardalos - 2010.pdf:/home/theo/Zotero/storage/A2NRFKX3/Convex optimization theory - Pardalos - 2010.pdf:application/pdf},
}

@article{grammDataReductionExact2008,
	title = {Data reduction and exact algorithms for clique cover},
	volume = {13},
	issn = {10846654},
	doi = {10.1145/1412228.1412236},
	abstract = {To cover the edges of a graph with a minimum number of cliques is an NP-hard problem with many applications. For this problem we develop efficient and effective polynomial-time data reduction rules that, combined with a search tree algorithm, allow for exact problem solutions in competitive time. This is confirmed by experiments with real-world and synthetic data. Moreover, we prove the fixed-parameter tractability of covering edges by cliques.},
	journal = {Journal of Experimental Algorithmics},
	author = {Gramm, Jens and Guo, Jiong and Hüffner, Falk and Niedermeier, Rolf},
	year = {2008},
	pages = {2.2},
}

@article{schoenbergMetricSpacesPositive1937,
	title = {Metric {Spaces} and {Positive} {Definite} {Functions}},
	volume = {44},
	issn = {00029947},
	doi = {10.2307/1989894},
	abstract = {n/a},
	number = {3},
	journal = {Transactions of the American Mathematical Society},
	author = {Schoenberg, I. J.},
	year = {1937},
	pages = {522},
	file = {Metric Spaces and Positive Definite Functions - Schoenberg - 1937.pdf:/home/theo/Zotero/storage/NY3WSXGN/Metric Spaces and Positive Definite Functions - Schoenberg - 1937.pdf:application/pdf},
}

@misc{resselSHORTPROOFSCHOENBERG,
	title = {A {SHORT} {PROOF} {OF} {SCHOENBERG}'{S} {THEOREM}},
	isbn = {0-7803-7313-8},
	author = {Ressel, Paul},
	file = {A SHORT PROOF OF SCHOENBERG'S THEOREM - Ressel -.pdf:/home/theo/Zotero/storage/LMZUFGP3/A SHORT PROOF OF SCHOENBERG'S THEOREM - Ressel -.pdf:application/pdf},
}

@article{danielsCoveringCircleSample1952,
	title = {The {Covering} {Circle} of a {Sample} from a {Circular} {Normal} {Distribution}},
	volume = {39},
	issn = {00063444},
	doi = {10.2307/2332472},
	number = {1/2},
	journal = {Biometrika},
	author = {Daniels, H. E.},
	year = {1952},
	pages = {137},
	file = {The Covering Circle of a Sample from a Circular Normal Distribution - Daniels - 1952.pdf:/home/theo/Zotero/storage/SJKNYQ86/The Covering Circle of a Sample from a Circular Normal Distribution - Daniels - 1952.pdf:application/pdf},
}

@article{titsiasUnbiasedImplicitVariational2018,
	title = {Unbiased {Implicit} {Variational} {Inference}},
	volume = {89},
	url = {http://arxiv.org/abs/1808.02078},
	abstract = {We develop unbiased implicit variational inference (UIVI), a method that expands the applicability of variational inference by defining an expressive variational family. UIVI considers an implicit variational distribution obtained in a hierarchical manner using a simple reparameterizable distribution whose variational parameters are defined by arbitrarily flexible deep neural networks. Unlike previous works, UIVI directly optimizes the evidence lower bound (ELBO) rather than an approximation to the ELBO. We demonstrate UIVI on several models, including Bayesian multinomial logistic regression and variational autoencoders, and show that UIVI achieves both tighter ELBO and better predictive performance than existing approaches at a similar computational cost.},
	author = {Titsias, Michalis K. and Ruiz, Francisco J. R.},
	year = {2018},
	note = {arXiv: 1808.02078},
	file = {Unbiased Implicit Variational Inference - Titsias_Ruiz - 2018.pdf:/home/theo/Zotero/storage/L8X8V6KG/Unbiased Implicit Variational Inference - Titsias_Ruiz - 2018.pdf:application/pdf},
}

@article{barnesInteractionEffectsPrediction2019,
	title = {On the {Interaction} {Effects} {Between} {Prediction} and {Clustering}},
	volume = {89},
	abstract = {Machine learning systems increasingly depend on pipelines of multiple algorithms to provide high quality and well structured predictions. This paper argues interaction effects between clustering and prediction (e.g. classification, regression) algorithms can cause subtle adverse behaviors during cross-validation that may not be initially apparent. In particular, we focus on the problem of estimating the out-of-cluster (OOC) prediction loss given an approximate clustering with probabilistic error rate p0. Traditional cross-validation techniques exhibit significant empirical bias in this setting, and the few attempts to estimate and correct for these effects are intractable on larger datasets. Further, no previous work has been able to characterize the conditions under which these empirical effects occur, and if they do, what properties they have. We precisely answer these questions by providing theoretical properties which hold in various settings, and prove that expected out-of-cluster loss behavior rapidly decays with even minor clustering errors. Fortunately, we are able to leverage these same properties to construct hypothesis tests and scalable estimators necessary for correcting the problem. Empirical results on benchmark datasets validate our theoretical results and demonstrate how scaling techniques provide solutions to new classes of problems.},
	journal = {22nd International Conference on Artificial Intelligence and Statistics},
	author = {Barnes, Matt and Dubrawski, Artur},
	year = {2019},
	file = {On the Interaction Effects Between Prediction and Clustering - Barnes_Dubrawski - 2019.pdf:/home/theo/Zotero/storage/33STWIMH/On the Interaction Effects Between Prediction and Clustering - Barnes_Dubrawski - 2019.pdf:application/pdf},
}

@article{broderickStreamingVariationalBayes2013,
	title = {Streaming {Variational} {Bayes}},
	url = {http://arxiv.org/abs/1307.6769},
	abstract = {We present SDA-Bayes, a framework for (S)treaming, (D)istributed, (A)synchronous computation of a Bayesian posterior. The framework makes streaming updates to the estimated posterior according to a user-specified approximation batch primitive. We demonstrate the usefulness of our framework, with variational Bayes (VB) as the primitive, by fitting the latent Dirichlet allocation model to two large-scale document collections. We demonstrate the advantages of our algorithm over stochastic variational inference (SVI) by comparing the two after a single pass through a known amount of data---a case where SVI may be applied---and in the streaming setting, where SVI does not apply.},
	author = {Broderick, Tamara and Boyd, Nicholas and Wibisono, Andre and Wilson, Ashia C. and Jordan, Michael I.},
	year = {2013},
	note = {arXiv: 1307.6769},
	pages = {1--18},
	file = {Streaming Variational Bayes - Broderick et al - 2013.pdf:/home/theo/Zotero/storage/PAFI78AS/Streaming Variational Bayes - Broderick et al - 2013.pdf:application/pdf},
}

@article{daiKernelExponentialFamily2018,
	title = {Kernel {Exponential} {Family} {Estimation} via {Doubly} {Dual} {Embedding}},
	volume = {89},
	url = {http://arxiv.org/abs/1811.02228},
	abstract = {We investigate penalized maximum log-likelihood estimation for exponential family distributions whose natural parameter resides in a reproducing kernel Hilbert space. Key to our approach is a novel technique, doubly dual embedding, that avoids computation of the partition function. This technique also allows the development of a flexible sampling strategy that amortizes the cost of Monte-Carlo sampling in the inference stage. The resulting estimator can be easily generalized to kernel conditional exponential families. We furthermore establish a connection between infinite-dimensional exponential family estimation and MMD-GANs, revealing a new perspective for understanding GANs. Compared to current score matching based estimators, the proposed method improves both memory and time efficiency while enjoying stronger statistical properties, such as fully capturing smoothness in its statistical convergence rate while the score matching estimator appears to saturate. Finally, we show that the proposed estimator can empirically outperform state-of-the-art methods in both kernel exponential family estimation and its conditional extension.},
	author = {Dai, Bo and Dai, Hanjun and Gretton, Arthur and Song, Le and Schuurmans, Dale and He, Niao},
	year = {2018},
	note = {arXiv: 1811.02228},
	file = {PDF:/home/theo/Zotero/storage/TYHBN26N/Dai et al. - 2018 - Kernel Exponential Family Estimation via Doubly Dual Embedding(2).pdf:application/pdf},
}

@article{hegdeDeepLearningDifferential2018,
	title = {Deep learning with differential {Gaussian} process flows},
	url = {http://arxiv.org/abs/1810.04066},
	abstract = {We propose a novel deep learning paradigm of differential flows that learn a stochastic differential equation transformations of inputs prior to a standard classification or regression function. The key property of differential Gaussian processes is the warping of inputs through infinitely deep, but infinitesimal, differential fields, that generalise discrete layers into a dynamical system. We demonstrate state-of-the-art results that exceed the performance of deep Gaussian processes and neural networks},
	number = {1},
	author = {Hegde, Pashupati and Heinonen, Markus and Lähdesmäki, Harri and Kaski, Samuel},
	year = {2018},
	note = {arXiv: 1810.04066},
	file = {Deep learning with differential Gaussian process flows - Hegde et al - 2018.pdf:/home/theo/Zotero/storage/H7G3B633/Deep learning with differential Gaussian process flows - Hegde et al - 2018.pdf:application/pdf},
}

@article{liuKernelizedSteinDiscrepancy2016a,
	title = {A {Kernelized} {Stein} {Discrepancy} for {Goodness}-of-fit {Tests} and {Model} {Evaluation}},
	url = {http://arxiv.org/abs/1602.03253},
	abstract = {We derive a new discrepancy statistic for measuring differences between two probability distributions based on combining Stein's identity with the reproducing kernel Hilbert space theory. We apply our result to test how well a probabilistic model fits a set of observations, and derive a new class of powerful goodness-of-fit tests that are widely applicable for complex and high dimensional distributions, even for those with computationally intractable normalization constants. Both theoretical and empirical properties of our methods are studied thoroughly.},
	urldate = {2020-07-09},
	journal = {arXiv:1602.03253 [stat]},
	author = {Liu, Qiang and Lee, Jason D. and Jordan, Michael I.},
	month = jul,
	year = {2016},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1602.03253},
	keywords = {Statistics - Machine Learning, ⛔ No DOI found},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/52CQ8FUF/1602.html:text/html;Liu et al_2016_A Kernelized Stein Discrepancy for Goodness-of-fit Tests and Model Evaluation.pdf:/home/theo/Zotero/storage/WUW7FFNC/Liu et al_2016_A Kernelized Stein Discrepancy for Goodness-of-fit Tests and Model Evaluation.pdf:application/pdf;arXiv.org Snapshot:/home/theo/Zotero/storage/NKL6PY4Y/1602.html:text/html;arXiv.org Snapshot:/home/theo/Zotero/storage/NLWYHZ5A/1602.html:text/html;A Kernelized Stein Discrepancy for Goodness-of-fit Tests and Model Evaluation - Liu et al - 2016.pdf:/home/theo/Zotero/storage/R7VVCNGD/A Kernelized Stein Discrepancy for Goodness-of-fit Tests and Model Evaluation - Liu et al - 2016.pdf:application/pdf;A Kernelized Stein Discrepancy for Goodness-of-fit Tests and Model Evaluation - Liu et al - 2016.pdf:/home/theo/Zotero/storage/72WZFYU9/A Kernelized Stein Discrepancy for Goodness-of-fit Tests and Model Evaluation - Liu et al - 2016.pdf:application/pdf},
}

@article{maddoxSimpleBaselineBayesian2019,
	title = {A {Simple} {Baseline} for {Bayesian} {Uncertainty} in {Deep} {Learning}},
	url = {http://arxiv.org/abs/1902.02476},
	abstract = {We propose SWA-Gaussian (SWAG), a simple, scalable, and general purpose approach for uncertainty representation and calibration in deep learning. Stochastic Weight Averaging (SWA), which computes the first moment of stochastic gradient descent (SGD) iterates with a modified learning rate schedule, has recently been shown to improve generalization in deep learning. With SWAG, we fit a Gaussian using the SWA solution as the first moment and a low rank plus diagonal covariance also derived from the SGD iterates, forming an approximate posterior distribution over neural network weights; we then sample from this Gaussian distribution to perform Bayesian model averaging. We empirically find that SWAG approximates the shape of the true posterior, in accordance with results describing the stationary distribution of SGD iterates. Moreover, we demonstrate that SWAG performs well on a wide variety of tasks, including out of sample detection, calibration, and transfer learning, in comparison to many popular alternatives including MC dropout, KFAC Laplace, SGLD, and temperature scaling.},
	urldate = {2020-08-28},
	journal = {arXiv:1902.02476 [cs, stat]},
	author = {Maddox, Wesley and Garipov, Timur and Izmailov, Pavel and Vetrov, Dmitry and Wilson, Andrew Gordon},
	month = dec,
	year = {2019},
	note = {ZSCC: 0000081 
arXiv: 1902.02476},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/LPUYGHCT/1902.html:text/html;A Simple Baseline for Bayesian Uncertainty in Deep Learning - Maddox et al - 2019.pdf:/home/theo/Zotero/storage/SG3GX85H/A Simple Baseline for Bayesian Uncertainty in Deep Learning - Maddox et al - 2019.pdf:application/pdf},
}

@incollection{galDistributedVariationalInference2014,
	title = {Distributed {Variational} {Inference} in {Sparse} {Gaussian} {Process} {Regression} and {Latent} {Variable} {Models}},
	url = {http://papers.nips.cc/paper/5593-distributed-variational-inference-in-sparse-gaussian-process-regression-and-latent-variable-models.pdf},
	urldate = {2020-09-01},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {Gal, Yarin and van der Wilk, Mark and Rasmussen, Carl Edward},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
	year = {2014},
	note = {ZSCC: NoCitationData[s0]},
	pages = {3257--3265},
	file = {NIPS Snapshot:/home/theo/Zotero/storage/H8WJFP5X/5593-distributed-variational-inference-in-sparse-gaussian-process-regression-and-latent-variabl.html:text/html;Distributed Variational Inference in Sparse Gaussian Process Regression and - Gal et al - 2014.pdf:/home/theo/Zotero/storage/X46LWGTT/Distributed Variational Inference in Sparse Gaussian Process Regression and - Gal et al - 2014.pdf:application/pdf},
}

@article{saeediVariationalParticleApproximationsa,
	title = {Variational {Particle} {Approximations}},
	abstract = {Approximate inference in high-dimensional, discrete probabilistic models is a central problem in computational statistics and machine learning. This paper describes discrete particle variational inference (DPVI), a new approach that combines key strengths of Monte Carlo, variational and search-based techniques. DPVI is based on a novel family of particle-based variational approximations that can be ﬁt using simple, fast, deterministic search techniques. Like Monte Carlo, DPVI can handle multiple modes, and yields exact results in a well-deﬁned limit. Like unstructured mean-ﬁeld, DPVI is based on optimizing a lower bound on the partition function; when this quantity is not of intrinsic interest, it facilitates convergence assessment and debugging. Like both Monte Carlo and combinatorial search, DPVI can take advantage of factorization, sequential structure, and custom search operators. This paper deﬁnes DPVI particle-based approximation family and partition function lower bounds, along with the sequential DPVI and local DPVI algorithm templates for optimizing them. DPVI is illustrated and evaluated via experiments on lattice Markov Random Fields, nonparametric Bayesian mixtures and block-models, and parametric as well as non-parametric hidden Markov models. Results include applications to real-world spike-sorting and relational modeling problems, and show that DPVI can oﬀer appealing time/accuracy trade-oﬀs as compared to multiple alternatives.},
	language = {en},
	author = {Saeedi, Ardavan and Kulkarni, Tejas D and Mansinghka, Vikash K and Gershman, Samuel J},
	note = {ZSCC: 0000015},
	pages = {29},
	file = {Variational Particle Approximations - Saeedi et al -.pdf:/home/theo/Zotero/storage/D4LLVHYW/Variational Particle Approximations - Saeedi et al -.pdf:application/pdf},
}

@article{salimbeniNaturalGradientsPractice2018,
	title = {Natural {Gradients} in {Practice}: {Non}-{Conjugate} {Variational} {Inference} in {Gaussian} {Process} {Models}},
	shorttitle = {Natural {Gradients} in {Practice}},
	url = {http://arxiv.org/abs/1803.09151},
	abstract = {The natural gradient method has been used effectively in conjugate Gaussian process models, but the non-conjugate case has been largely unexplored. We examine how natural gradients can be used in non-conjugate stochastic settings, together with hyperparameter learning. We conclude that the natural gradient can significantly improve performance in terms of wall-clock time. For ill-conditioned posteriors the benefit of the natural gradient method is especially pronounced, and we demonstrate a practical setting where ordinary gradients are unusable. We show how natural gradients can be computed efficiently and automatically in any parameterization, using automatic differentiation. Our code is integrated into the GPflow package.},
	urldate = {2020-08-26},
	journal = {arXiv:1803.09151 [cs, stat]},
	author = {Salimbeni, Hugh and Eleftheriadis, Stefanos and Hensman, James},
	month = mar,
	year = {2018},
	note = {ZSCC: 0000028 
arXiv: 1803.09151},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/LD44L767/1803.html:text/html;Natural Gradients in Practice - Salimbeni et al - 2018.pdf:/home/theo/Zotero/storage/THNVTFD8/Natural Gradients in Practice - Salimbeni et al - 2018.pdf:application/pdf},
}

@article{chenHessianMatrixVs2011,
	title = {Hessian {Matrix} vs. {Gauss}–{Newton} {Hessian} {Matrix}},
	volume = {49},
	issn = {0036-1429, 1095-7170},
	url = {http://epubs.siam.org/doi/10.1137/100799988},
	doi = {10.1137/100799988},
	language = {en},
	number = {4},
	urldate = {2020-08-25},
	journal = {SIAM Journal on Numerical Analysis},
	author = {Chen, Pei},
	month = jan,
	year = {2011},
	note = {ZSCC: 0000037},
	pages = {1417--1435},
	file = {Hessian Matrix vs - Chen - 2011.pdf:/home/theo/Zotero/storage/HJXBF6NS/Hessian Matrix vs - Chen - 2011.pdf:application/pdf},
}

@article{ruffDeepOneClassClassification,
	title = {Deep {One}-{Class} {Classification}},
	abstract = {Despite the great advances made by deep learning in many machine learning problems, there is a relative dearth of deep learning approaches for anomaly detection. Those approaches which do exist involve networks trained to perform a task other than anomaly detection, namely generative models or compression, which are in turn adapted for use in anomaly detection; they are not trained on an anomaly detection based objective. In this paper we introduce a new anomaly detection method—Deep Support Vector Data Description—, which is trained on an anomaly detection based objective. The adaptation to the deep regime necessitates that our neural network and training procedure satisfy certain properties, which we demonstrate theoretically. We show the effectiveness of our method on MNIST and CIFAR-10 image benchmark datasets as well as on the detection of adversarial examples of GTSRB stop signs.},
	language = {en},
	author = {Ruff, Lukas and Vandermeulen, Robert A and Görnitz, Nico and Deecke, Lucas and Siddiqui, Shoaib A and Binder, Alexander and Müller, Emmanuel and Kloft, Marius},
	note = {ZSCC: NoCitationData[s0]},
	pages = {10},
	file = {Deep One-Class Classification - Ruff et al -.pdf:/home/theo/Zotero/storage/YP7ZNZII/Deep One-Class Classification - Ruff et al -.pdf:application/pdf},
}

@article{libertyAlgorithmOnlineKMeans2015,
	title = {An {Algorithm} for {Online} {K}-{Means} {Clustering}},
	url = {http://arxiv.org/abs/1412.5721},
	abstract = {This paper shows that one can be competitive with the k-means objective while operating online. In this model, the algorithm receives vectors v\_1,...,v\_n one by one in an arbitrary order. For each vector the algorithm outputs a cluster identifier before receiving the next one. Our online algorithm generates {\textasciitilde}O(k) clusters whose k-means cost is {\textasciitilde}O(W*). Here, W* is the optimal k-means cost using k clusters and {\textasciitilde}O suppresses poly-logarithmic factors. We also show that, experimentally, it is not much worse than k-means++ while operating in a strictly more constrained computational model.},
	urldate = {2020-08-05},
	journal = {arXiv:1412.5721 [cs]},
	author = {Liberty, Edo and Sriharsha, Ram and Sviridenko, Maxim},
	month = feb,
	year = {2015},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1412.5721},
	keywords = {Computer Science - Machine Learning, Computer Science - Data Structures and Algorithms},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/XUEKQUJF/1412.html:text/html;An Algorithm for Online K-Means Clustering - Liberty et al - 2015.pdf:/home/theo/Zotero/storage/HPSILKUH/An Algorithm for Online K-Means Clustering - Liberty et al - 2015.pdf:application/pdf},
}

@article{cohen-addadOnlineKmeansClustering2019,
	title = {Online k-means {Clustering}},
	url = {http://arxiv.org/abs/1909.06861},
	abstract = {We study the problem of online clustering where a clustering algorithm has to assign a new point that arrives to one of \$k\$ clusters. The specific formulation we use is the \$k\$-means objective: At each time step the algorithm has to maintain a set of k candidate centers and the loss incurred is the squared distance between the new point and the closest center. The goal is to minimize regret with respect to the best solution to the \$k\$-means objective (\${\textbackslash}mathcal\{C\}\$) in hindsight. We show that provided the data lies in a bounded region, an implementation of the Multiplicative Weights Update Algorithm (MWUA) using a discretized grid achieves a regret bound of \${\textbackslash}tilde\{O\}({\textbackslash}sqrt\{T\})\$ in expectation. We also present an online-to-offline reduction that shows that an efficient no-regret online algorithm (despite being allowed to choose a different set of candidate centres at each round) implies an offline efficient algorithm for the \$k\$-means problem. In light of this hardness, we consider the slightly weaker requirement of comparing regret with respect to \$(1 + {\textbackslash}epsilon) {\textbackslash}mathcal\{C\}\$ and present a no-regret algorithm with runtime \$O{\textbackslash}left(T({\textbackslash}mathrm\{poly\}(log(T),k,d,1/{\textbackslash}epsilon){\textasciicircum}\{k(d+O(1))\}{\textbackslash}right)\$. Our algorithm is based on maintaining an incremental coreset and an adaptive variant of the MWUA. We show that na{\textbackslash}"\{i\}ve online algorithms, such as {\textbackslash}emph\{Follow The Leader\}, fail to produce sublinear regret in the worst case. We also report preliminary experiments with synthetic and real-world data.},
	urldate = {2020-08-05},
	journal = {arXiv:1909.06861 [cs, stat]},
	author = {Cohen-Addad, Vincent and Guedj, Benjamin and Kanade, Varun and Rom, Guy},
	month = sep,
	year = {2019},
	note = {ZSCC: 0000003 
arXiv: 1909.06861},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/T8UNMPWC/1909.html:text/html;Online k-means Clustering - Cohen-Addad et al - 2019.pdf:/home/theo/Zotero/storage/FETPZ4VQ/Online k-means Clustering - Cohen-Addad et al - 2019.pdf:application/pdf},
}

@inproceedings{sculleyWebscaleKmeansClustering2010,
	address = {Raleigh, North Carolina, USA},
	title = {Web-scale k-means clustering},
	isbn = {978-1-60558-799-8},
	url = {http://portal.acm.org/citation.cfm?doid=1772690.1772862},
	doi = {10.1145/1772690.1772862},
	language = {en},
	urldate = {2020-08-05},
	booktitle = {Proceedings of the 19th international conference on {World} wide web - {WWW} '10},
	publisher = {ACM Press},
	author = {Sculley, D.},
	year = {2010},
	note = {ZSCC: 0000625},
	pages = {1177},
	file = {Web-scale k-means clustering - Sculley - 2010.pdf:/home/theo/Zotero/storage/BJI6VXDR/Web-scale k-means clustering - Sculley - 2010.pdf:application/pdf},
}

@article{bottouOptimizationMethodsLargeScale2018,
	title = {Optimization {Methods} for {Large}-{Scale} {Machine} {Learning}},
	url = {http://arxiv.org/abs/1606.04838},
	abstract = {This paper provides a review and commentary on the past, present, and future of numerical optimization algorithms in the context of machine learning applications. Through case studies on text classification and the training of deep neural networks, we discuss how optimization problems arise in machine learning and what makes them challenging. A major theme of our study is that large-scale machine learning represents a distinctive setting in which the stochastic gradient (SG) method has traditionally played a central role while conventional gradient-based nonlinear optimization techniques typically falter. Based on this viewpoint, we present a comprehensive theory of a straightforward, yet versatile SG algorithm, discuss its practical behavior, and highlight opportunities for designing algorithms with improved performance. This leads to a discussion about the next generation of optimization methods for large-scale machine learning, including an investigation of two main streams of research on techniques that diminish noise in the stochastic directions and methods that make use of second-order derivative approximations.},
	urldate = {2020-08-25},
	journal = {arXiv:1606.04838 [cs, math, stat]},
	author = {Bottou, Léon and Curtis, Frank E. and Nocedal, Jorge},
	month = feb,
	year = {2018},
	note = {ZSCC: 0001186 
arXiv: 1606.04838},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Mathematics - Optimization and Control},
	file = {Optimization Methods for Large-Scale Machine Learning - Bottou et al - 2018.pdf:/home/theo/Zotero/storage/4BR2NGES/Optimization Methods for Large-Scale Machine Learning - Bottou et al - 2018.pdf:application/pdf;arXiv.org Snapshot:/home/theo/Zotero/storage/89RHSAPY/1606.html:text/html},
}

@article{wangSteinVariationalGradient2019,
	title = {Stein {Variational} {Gradient} {Descent} {With} {Matrix}-{Valued} {Kernels}},
	url = {http://arxiv.org/abs/1910.12794},
	abstract = {Stein variational gradient descent (SVGD) is a particle-based inference algorithm that leverages gradient information for efficient approximate inference. In this work, we enhance SVGD by leveraging preconditioning matrices, such as the Hessian and Fisher information matrix, to incorporate geometric information into SVGD updates. We achieve this by presenting a generalization of SVGD that replaces the scalar-valued kernels in vanilla SVGD with more general matrix-valued kernels. This yields a significant extension of SVGD, and more importantly, allows us to flexibly incorporate various preconditioning matrices to accelerate the exploration in the probability landscape. Empirical results show that our method outperforms vanilla SVGD and a variety of baseline approaches over a range of real-world Bayesian inference tasks.},
	urldate = {2020-07-31},
	journal = {arXiv:1910.12794 [cs, stat]},
	author = {Wang, Dilin and Tang, Ziyang and Bajaj, Chandrajit and Liu, Qiang},
	month = nov,
	year = {2019},
	note = {ZSCC: 0000005 
arXiv: 1910.12794},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/IXDZTYSJ/1910.html:text/html;Stein Variational Gradient Descent With Matrix-Valued Kernels - Wang et al - 2019.pdf:/home/theo/Zotero/storage/ZUL2M2GZ/Stein Variational Gradient Descent With Matrix-Valued Kernels - Wang et al - 2019.pdf:application/pdf},
}

@article{kanagawaGaussianProcessesKernel2018,
	title = {Gaussian {Processes} and {Kernel} {Methods}: {A} {Review} on {Connections} and {Equivalences}},
	shorttitle = {Gaussian {Processes} and {Kernel} {Methods}},
	url = {http://arxiv.org/abs/1807.02582},
	abstract = {This paper is an attempt to bridge the conceptual gaps between researchers working on the two widely used approaches based on positive definite kernels: Bayesian learning or inference using Gaussian processes on the one side, and frequentist kernel methods based on reproducing kernel Hilbert spaces on the other. It is widely known in machine learning that these two formalisms are closely related; for instance, the estimator of kernel ridge regression is identical to the posterior mean of Gaussian process regression. However, they have been studied and developed almost independently by two essentially separate communities, and this makes it difficult to seamlessly transfer results between them. Our aim is to overcome this potential difficulty. To this end, we review several old and new results and concepts from either side, and juxtapose algorithmic quantities from each framework to highlight close similarities. We also provide discussions on subtle philosophical and theoretical differences between the two approaches.},
	urldate = {2020-07-31},
	journal = {arXiv:1807.02582 [cs, stat]},
	author = {Kanagawa, Motonobu and Hennig, Philipp and Sejdinovic, Dino and Sriperumbudur, Bharath K.},
	month = jul,
	year = {2018},
	note = {ZSCC: 0000046 
arXiv: 1807.02582},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/SRBTAUR6/1807.html:text/html;Gaussian Processes and Kernel Methods - Kanagawa et al - 2018.pdf:/home/theo/Zotero/storage/J4VMU28H/Gaussian Processes and Kernel Methods - Kanagawa et al - 2018.pdf:application/pdf},
}

@article{burtConvergenceSparseVariational2020,
	title = {Convergence of {Sparse} {Variational} {Inference} in {Gaussian} {Processes} {Regression}},
	volume = {21},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v21/19-1015.html},
	number = {131},
	urldate = {2020-07-28},
	journal = {Journal of Machine Learning Research},
	author = {Burt, David R. and Rasmussen, Carl Edward and Wilk, Mark van der},
	year = {2020},
	note = {ZSCC: NoCitationData[s0]},
	pages = {1--63},
	file = {Snapshot:/home/theo/Zotero/storage/L3QE3M4G/19-1015.html:text/html;Convergence of Sparse Variational Inference in Gaussian Processes Regression - Burt et al - 2020.pdf:/home/theo/Zotero/storage/B38UVI8Z/Convergence of Sparse Variational Inference in Gaussian Processes Regression - Burt et al - 2020.pdf:application/pdf},
}

@book{kroeseHandbookMonteCarlo2011,
	edition = {1},
	series = {Wiley {Series} in {Probability} and {Statistics}},
	title = {Handbook of {Monte} {Carlo} {Methods}},
	isbn = {978-0-470-17793-8 978-1-118-01496-7},
	url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9781118014967},
	language = {en},
	urldate = {2020-07-27},
	publisher = {Wiley},
	author = {Kroese, Dirk P. and Taimre, Thomas and Botev, Zdravko I.},
	month = feb,
	year = {2011},
	doi = {10.1002/9781118014967},
	note = {ZSCC: 0000004 },
	file = {Handbook of Monte Carlo Methods - Kroese et al - 2011.pdf:/home/theo/Zotero/storage/9FXR9ZTE/Handbook of Monte Carlo Methods - Kroese et al - 2011.pdf:application/pdf},
}

@article{oktayRandomizedAutomaticDifferentiation2020,
	title = {Randomized {Automatic} {Differentiation}},
	url = {http://arxiv.org/abs/2007.10412},
	abstract = {The successes of deep learning, variational inference, and many other fields have been aided by specialized implementations of reverse-mode automatic differentiation (AD) to compute gradients of mega-dimensional objectives. The AD techniques underlying these tools were designed to compute exact gradients to numerical precision, but modern machine learning models are almost always trained with stochastic gradient descent. Why spend computation and memory on exact (minibatch) gradients only to use them for stochastic optimization? We develop a general framework and approach for randomized automatic differentiation (RAD), which allows unbiased gradient estimates to be computed with reduced memory in return for variance. We examine limitations of the general approach, and argue that we must leverage problem specific structure to realize benefits. We develop RAD techniques for a variety of simple neural network architectures, and show that for a fixed memory budget, RAD converges in fewer iterations than using a small batch size for feedforward networks, and in a similar number for recurrent networks. We also show that RAD can be applied to scientific computing, and use it to develop a low-memory stochastic gradient method for optimizing the control parameters of a linear reaction-diffusion PDE representing a fission reactor.},
	urldate = {2020-07-25},
	journal = {arXiv:2007.10412 [cs, stat]},
	author = {Oktay, Deniz and McGreivy, Nick and Aduol, Joshua and Beatson, Alex and Adams, Ryan P.},
	month = jul,
	year = {2020},
	note = {ZSCC: 0000000 
arXiv: 2007.10412},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {Randomized Automatic Differentiation - Oktay et al - 2020.pdf:/home/theo/Zotero/storage/CTSAEXEJ/Randomized Automatic Differentiation - Oktay et al - 2020.pdf:application/pdf;arXiv.org Snapshot:/home/theo/Zotero/storage/IFHU8ZNY/2007.html:text/html},
}

@article{wilsonKernelInterpolationScalable2015,
	title = {Kernel {Interpolation} for {Scalable} {Structured} {Gaussian} {Processes} ({KISS}-{GP})},
	url = {http://arxiv.org/abs/1503.01057},
	abstract = {We introduce a new structured kernel interpolation (SKI) framework, which generalises and unifies inducing point methods for scalable Gaussian processes (GPs). SKI methods produce kernel approximations for fast computations through kernel interpolation. The SKI framework clarifies how the quality of an inducing point approach depends on the number of inducing (aka interpolation) points, interpolation strategy, and GP covariance kernel. SKI also provides a mechanism to create new scalable kernel methods, through choosing different kernel interpolation strategies. Using SKI, with local cubic kernel interpolation, we introduce KISS-GP, which is 1) more scalable than inducing point alternatives, 2) naturally enables Kronecker and Toeplitz algebra for substantial additional gains in scalability, without requiring any grid data, and 3) can be used for fast and expressive kernel learning. KISS-GP costs O(n) time and storage for GP inference. We evaluate KISS-GP for kernel matrix approximation, kernel learning, and natural sound modelling.},
	urldate = {2020-07-23},
	journal = {arXiv:1503.01057 [cs, stat]},
	author = {Wilson, Andrew Gordon and Nickisch, Hannes},
	month = mar,
	year = {2015},
	note = {ZSCC: 0000224 
arXiv: 1503.01057},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/DYDSUIY6/1503.html:text/html;Kernel Interpolation for Scalable Structured Gaussian Processes (KISS-GP) - Wilson_Nickisch - 2015.pdf:/home/theo/Zotero/storage/CZLRMF4J/Kernel Interpolation for Scalable Structured Gaussian Processes (KISS-GP) - Wilson_Nickisch - 2015.pdf:application/pdf},
}

@book{shalev-shwartzUnderstandingMachineLearning2014,
	address = {Cambridge},
	title = {Understanding {Machine} {Learning}: {From} {Theory} to {Algorithms}},
	isbn = {978-1-107-29801-9},
	shorttitle = {Understanding {Machine} {Learning}},
	url = {http://ebooks.cambridge.org/ref/id/CBO9781107298019},
	language = {en},
	urldate = {2020-07-23},
	publisher = {Cambridge University Press},
	author = {Shalev-Shwartz, Shai and Ben-David, Shai},
	year = {2014},
	doi = {10.1017/CBO9781107298019},
	note = {ZSCC: 0002425 },
	file = {Understanding Machine Learning - Shalev-Shwartz_Ben-David - 2014.pdf:/home/theo/Zotero/storage/RY99SVZ8/Understanding Machine Learning - Shalev-Shwartz_Ben-David - 2014.pdf:application/pdf},
}

@article{masraniThermodynamicVariationalObjective2019,
	title = {The {Thermodynamic} {Variational} {Objective}},
	url = {http://arxiv.org/abs/1907.00031},
	abstract = {We introduce the thermodynamic variational objective (TVO) for learning in both continuous and discrete deep generative models. The TVO arises from a key connection between variational inference and thermodynamic integration that results in a tighter lower bound to the log marginal likelihood than the standard variational variational evidence lower bound (ELBO) while remaining as broadly applicable. We provide a computationally efficient gradient estimator for the TVO that applies to continuous, discrete, and non-reparameterizable distributions and show that the objective functions used in variational inference, variational autoencoders, wake sleep, and inference compilation are all special cases of the TVO. We use the TVO to learn both discrete and continuous deep generative models and empirically demonstrate state of the art model and inference network learning.},
	urldate = {2020-07-20},
	journal = {arXiv:1907.00031 [cs, stat]},
	author = {Masrani, Vaden and Le, Tuan Anh and Wood, Frank},
	month = nov,
	year = {2019},
	note = {ZSCC: 0000004 
arXiv: 1907.00031},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/ZGDH7C38/1907.html:text/html;The Thermodynamic Variational Objective - Masrani et al - 2019.pdf:/home/theo/Zotero/storage/7BSXKNFY/The Thermodynamic Variational Objective - Masrani et al - 2019.pdf:application/pdf},
}

@incollection{lawrenceEfficientSamplingGaussian2009,
	title = {Efficient {Sampling} for {Gaussian} {Process} {Inference} using {Control} {Variables}},
	url = {http://papers.nips.cc/paper/3414-efficient-sampling-for-gaussian-process-inference-using-control-variables.pdf},
	urldate = {2020-07-09},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 21},
	publisher = {Curran Associates, Inc.},
	author = {Lawrence, Neil D. and Rattray, Magnus and Titsias, Michalis K.},
	editor = {Koller, D. and Schuurmans, D. and Bengio, Y. and Bottou, L.},
	year = {2009},
	note = {ZSCC: NoCitationData[s0]},
	pages = {1681--1688},
	file = {NIPS Snapshot:/home/theo/Zotero/storage/XBQHMGE2/3414-efficient-sampling-for-gaussian-process-inference-using-control-variables.html:text/html;Efficient Sampling for Gaussian Process Inference using Control Variables - Lawrence et al - 2009.pdf:/home/theo/Zotero/storage/IDYRBI8A/Efficient Sampling for Gaussian Process Inference using Control Variables - Lawrence et al - 2009.pdf:application/pdf},
}

@article{wilsonEfficientlySamplingFunctions,
	title = {Efﬁciently {Sampling} {Functions} from {Gaussian} {Process} {Posteriors}},
	abstract = {Gaussian processes are the gold standard for many real-world modeling problems, especially in cases where a model’s success hinges upon its ability to faithfully represent predictive uncertainty. These problems typically exist as parts of larger frameworks, wherein quantities of interest are ultimately deﬁned by integrating over posterior distributions. These quantities are frequently intractable, motivating the use of Monte Carlo methods. Despite substantial progress in scaling up Gaussian processes to large training sets, methods for accurately generating draws from their posterior distributions still scale cubically in the number of test locations. We identify a decomposition of Gaussian processes that naturally lends itself to scalable sampling by separating out the prior from the data. Building off of this factorization, we propose an easy-to-use and general-purpose approach for fast posterior sampling, which seamlessly pairs with sparse approximations to afford scalability both during training and at test time. In a series of experiments designed to test competing sampling schemes’ statistical properties and practical ramiﬁcations, we demonstrate how decoupled sample paths accurately represent Gaussian process posteriors at a fraction of the usual cost.},
	language = {en},
	author = {Wilson, James T and Borovitskiy, Viacheslav and Terenin, Alexander and Mostowsky, Peter and Deisenroth, Marc Peter},
	note = {ZSCC: 0000003},
	pages = {11},
	file = {Efﬁciently Sampling Functions from Gaussian Process Posteriors - Wilson et al -.pdf:/home/theo/Zotero/storage/HMWLNVZT/Efﬁciently Sampling Functions from Gaussian Process Posteriors - Wilson et al -.pdf:application/pdf},
}

@article{hoffmanBlackBoxVariationalInference,
	title = {Black-{Box} {Variational} {Inference} as {Distilled} {Langevin} {Dynamics}},
	abstract = {Variational inference (VI) and Markov chain Monte Carlo (MCMC) are approximate posterior inference algorithms that are often said to have complementary strengths, with VI being fast but biased and MCMC being slower but asymptotically unbiased. In this paper, we analyze gradientbased MCMC and VI procedures and ﬁnd theoretical and empirical evidence that these procedures are not as different as one might think. In particular, a close examination of the FokkerPlanck equation that governs the Langevin dynamics (LD) MCMC procedure reveals that LD implicitly follows a gradient ﬂow that corresponds to a variational inference procedure based on optimizing a nonparametric normalizing ﬂow. This result suggests that the transient bias of LD (due to the Markov chain not having burned in) may track that of VI (due to the optimizer not having converged), up to differences due to VI’s asymptotic bias and parameterization. Empirically, we ﬁnd that the transient biases of these algorithms (and their momentum-accelerated counterparts) do evolve similarly. This suggests that practitioners with a limited time budget may get more accurate results by running an MCMC procedure (even if it’s far from burned in) than a VI procedure, as long as the variance of the MCMC estimator can be dealt with (e.g., by running many parallel chains).},
	language = {en},
	author = {Hoffman, Matthew and Ma, Yi-An},
	note = {ZSCC: 0000000},
	pages = {11},
	file = {Black-Box Variational Inference as Distilled Langevin Dynamics - Hoffman_Ma -.pdf:/home/theo/Zotero/storage/HNUJBQAN/Black-Box Variational Inference as Distilled Langevin Dynamics - Hoffman_Ma -.pdf:application/pdf},
}

@article{huangAugmentedNormalizingFlows2020,
	title = {Augmented {Normalizing} {Flows}: {Bridging} the {Gap} {Between} {Generative} {Flows} and {Latent} {Variable} {Models}},
	shorttitle = {Augmented {Normalizing} {Flows}},
	url = {http://arxiv.org/abs/2002.07101},
	abstract = {In this work, we propose a new family of generative flows on an augmented data space, with an aim to improve expressivity without drastically increasing the computational cost of sampling and evaluation of a lower bound on the likelihood. Theoretically, we prove the proposed flow can approximate a Hamiltonian ODE as a universal transport map. Empirically, we demonstrate state-of-the-art performance on standard benchmarks of flow-based generative modeling.},
	urldate = {2020-07-08},
	journal = {arXiv:2002.07101 [cs, stat]},
	author = {Huang, Chin-Wei and Dinh, Laurent and Courville, Aaron},
	month = feb,
	year = {2020},
	note = {ZSCC: 0000003 
arXiv: 2002.07101},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/RGHGQEXY/2002.html:text/html;Augmented Normalizing Flows - Huang et al - 2020.pdf:/home/theo/Zotero/storage/JT8HQZK7/Augmented Normalizing Flows - Huang et al - 2020.pdf:application/pdf},
}

@article{ustyuzhaninovCompositionalUncertaintyDeep,
	title = {Compositional uncertainty in deep {Gaussian} processes},
	abstract = {Gaussian processes (GPs) are nonparametric priors over functions. Fitting a GP implies computing a posterior distribution of functions consistent with the observed data. Similarly, deep Gaussian processes (DGPs) should allow us to compute a posterior distribution of compositions of multiple functions giving rise to the observations. However, exact Bayesian inference is intractable for DGPs, motivating the use of various approximations. We show that the application of simplifying mean-ﬁeld assumptions across the hierarchy leads to the layers of a DGP collapsing to near-deterministic transformations. We argue that such an inference scheme is suboptimal, not taking advantage of the potential of the model to discover the compositional structure in the data. To address this issue, we examine alternative variational inference schemes allowing for dependencies across different layers and discuss their advantages and limitations.},
	language = {en},
	author = {Ustyuzhaninov, Ivan and Kazlauskaite, Ieva and Kaiser, Markus and Bodin, Erik and Campbell, Neill D F and Ek, Carl Henrik},
	note = {ZSCC: 0000002},
	pages = {10},
	file = {Compositional uncertainty in deep Gaussian processes - Ustyuzhaninov et al -.pdf:/home/theo/Zotero/storage/QVK2MHC2/Compositional uncertainty in deep Gaussian processes - Ustyuzhaninov et al -.pdf:application/pdf},
}

@article{daiInterpretableSampleEfficient,
	title = {An {Interpretable} and {Sample} {Efﬁcient} {Deep} {Kernel} for {Gaussian} {Process}},
	abstract = {We propose a novel Gaussian process kernel that takes advantage of a deep neural network (DNN) structure but retains good interpretability. The resulting kernel is capable of addressing four major issues of the previous works of similar art, i.e., the optimality, explainability, model complexity, and sample efﬁciency. Our kernel design procedure comprises three steps: (1) Derivation of an optimal kernel with a non-stationary dot product structure that minimizes the prediction/test mean-squared-error (MSE); (2) Decomposition of this optimal kernel as a linear combination of shallow DNN subnetworks with the aid of multi-way feature interaction detection; (3) Updating the hyperparameters of the subnetworks via an alternating rationale until convergence. The designed kernel does not sacriﬁce interpretability for optimality. On the contrary, each subnetwork explicitly demonstrates the interaction of a set of features in a transformation function, leading to a solid path toward explainable kernel learning. We test the proposed kernel with both synthesized and real-world data sets, and the proposed kernel is superior to its competitors in terms of prediction performance in most cases. Moreover, it tends to maintain the prediction performance and be robust to data over-ﬁtting issue, when reducing the number of samples.},
	language = {en},
	author = {Dai, Yijue and Zhang, Tianjian and Lin, Zhidi and Yin, Feng and Theodoridis, Sergios and Cui, Shuguang},
	note = {ZSCC: NoCitationData[s0]},
	keywords = {toread},
	pages = {10},
	file = {An Interpretable and Sample Efﬁcient Deep Kernel for Gaussian Process - Dai et al -.pdf:/home/theo/Zotero/storage/FZC466G9/An Interpretable and Sample Efﬁcient Deep Kernel for Gaussian Process - Dai et al -.pdf:application/pdf},
}

@article{zhangRelationshipProbabilisticCircuits,
	title = {On the {Relationship} {Between} {Probabilistic} {Circuits} and {Determinantal} {Point} {Processes}},
	abstract = {Scaling probabilistic models to large realistic problems and datasets is a key challenge in machine learning. Central to this effort is the development of tractable probabilistic models (TPMs): models whose structure guarantees efﬁcient probabilistic inference algorithms. The current landscape of TPMs is fragmented: there exist various kinds of TPMs with different strengths and weaknesses. Two of the most prominent classes of TPMs are determinantal point processes (DPPs) and probabilistic circuits (PCs). This paper provides the ﬁrst systematic study of their relationship. We propose a uniﬁed analysis and shared language for discussing DPPs and PCs. Then we establish theoretical barriers for the uniﬁcation of these two families, and prove that there are cases where DPPs have no compact representation as a class of PCs. We close with a perspective on the central problem of unifying these tractable models.},
	language = {en},
	author = {Zhang, Honghua and Holtzen, Steven and Van den Broeck, Guy},
	note = {ZSCC: 0000000},
	keywords = {toread},
	pages = {10},
	file = {On the Relationship Between Probabilistic Circuits and Determinantal Point - Zhang et al -.pdf:/home/theo/Zotero/storage/YPGNQVFB/On the Relationship Between Probabilistic Circuits and Determinantal Point - Zhang et al -.pdf:application/pdf},
}

@article{bierkensBoomerangSampler2020,
	title = {The {Boomerang} {Sampler}},
	url = {http://arxiv.org/abs/2006.13777},
	abstract = {This paper introduces the boomerang sampler as a novel class of continuous-time non-reversible Markov chain Monte Carlo algorithms. The methodology begins by representing the target density as a density, \$e{\textasciicircum}\{-U\}\$, with respect to a prescribed (usually) Gaussian measure and constructs a continuous trajectory consisting of a piecewise elliptical path. The method moves from one elliptical orbit to another according to a rate function which can be written in terms of \$U\$. We demonstrate that the method is easy to implement and demonstrate empirically that it can out-perform existing benchmark piecewise deterministic Markov processes such as the bouncy particle sampler and the Zig-Zag. In the Bayesian statistics context, these competitor algorithms are of substantial interest in the large data context due to the fact that they can adopt data subsampling techniques which are exact (ie induce no error in the stationary distribution). We demonstrate theoretically and empirically that we can also construct a control-variate subsampling boomerang sampler which is also exact, and which possesses remarkable scaling properties in the large data limit. We furthermore illustrate a factorised version on the simulation of diffusion bridges.},
	urldate = {2020-07-08},
	journal = {arXiv:2006.13777 [cs, stat]},
	author = {Bierkens, Joris and Grazzi, Sebastiano and Kamatani, Kengo and Roberts, Gareth},
	month = jun,
	year = {2020},
	note = {ZSCC: 0000000 
arXiv: 2006.13777},
	keywords = {Computer Science - Machine Learning, Statistics - Computation, 68W20, 60J25},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/MVBD32P2/2006.html:text/html;The Boomerang Sampler - Bierkens et al - 2020.pdf:/home/theo/Zotero/storage/ITXFR7D4/The Boomerang Sampler - Bierkens et al - 2020.pdf:application/pdf},
}

@misc{bengioDeepLearningPart2020,
	title = {Deep {Learning}, part 1 - {Yoshua} {Bengio} - {MLSS} 2020, {Tübingen}},
	url = {https://www.youtube.com/watch?v=c_U4THknoHE&feature=youtu.be},
	urldate = {2020-07-06},
	author = {Bengio, Yoshua},
	month = jul,
	year = {2020},
}

@article{limOperatorvaluedKernelbasedVector,
	title = {Operator-valued {Kernel}-based {Vector} {Autoregressive} {Models} for {Network} {Inference} ({Supplementary} material)},
	language = {en},
	author = {Lim, Nehemy},
	note = {ZSCC: NoCitationData[s0]},
	pages = {3},
}

@article{finlayLearningNormalizingFlows2020,
	title = {Learning normalizing flows from {Entropy}-{Kantorovich} potentials},
	url = {http://arxiv.org/abs/2006.06033},
	abstract = {We approach the problem of learning continuous normalizing flows from a dual perspective motivated by entropy-regularized optimal transport, in which continuous normalizing flows are cast as gradients of scalar potential functions. This formulation allows us to train a dual objective comprised only of the scalar potential functions, and removes the burden of explicitly computing normalizing flows during training. After training, the normalizing flow is easily recovered from the potential functions.},
	urldate = {2020-07-03},
	journal = {arXiv:2006.06033 [cs, stat]},
	author = {Finlay, Chris and Gerolin, Augusto and Oberman, Adam M. and Pooladian, Aram-Alexandre},
	month = jun,
	year = {2020},
	note = {ZSCC: 0000000 
arXiv: 2006.06033},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, toread},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/WJXNQL5T/2006.html:text/html;Learning normalizing flows from Entropy-Kantorovich potentials - Finlay et al - 2020.pdf:/home/theo/Zotero/storage/JLPD2EY6/Learning normalizing flows from Entropy-Kantorovich potentials - Finlay et al - 2020.pdf:application/pdf},
}

@article{gongSlicedKernelizedStein2020,
	title = {Sliced {Kernelized} {Stein} {Discrepancy}},
	url = {http://arxiv.org/abs/2006.16531},
	abstract = {Kernelized Stein discrepancy (KSD), though being extensively used in goodness-of-fit tests and model learning, suffers from the curse-of-dimensionality. We address this issue by proposing the sliced Stein discrepancy and its scalable and kernelized variants, which employs kernel-based test functions defined on the optimal onedimensional projections instead of the full input in high dimensions. When applied to goodness-of-fit tests, extensive experiments show the proposed discrepancy significantly outperforms KSD and various baselines in high dimensions. For model learning, we show its advantages by training an independent component analysis when compared with existing Stein discrepancy baselines. We further propose a novel particle inference method called sliced Stein variational gradient descent (S-SVGD) which alleviates the mode-collapse issue of SVGD in training variational autoencoders.},
	urldate = {2020-07-03},
	journal = {arXiv:2006.16531 [cs, stat]},
	author = {Gong, Wenbo and Li, Yingzhen and Hernández-Lobato, José Miguel},
	month = jun,
	year = {2020},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 2006.16531},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, to read},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/NBNQT79G/2006.html:text/html;Sliced Kernelized Stein Discrepancy - Gong et al - 2020.pdf:/home/theo/Zotero/storage/XAEP9CDX/Sliced Kernelized Stein Discrepancy - Gong et al - 2020.pdf:application/pdf},
}

@article{hofmannKernelMethodsMachine2008,
	title = {Kernel methods in machine learning},
	volume = {36},
	issn = {0090-5364},
	url = {http://arxiv.org/abs/math/0701907},
	doi = {10.1214/009053607000000677},
	abstract = {We review machine learning methods employing positive definite kernels. These methods formulate learning and estimation problems in a reproducing kernel Hilbert space (RKHS) of functions defined on the data domain, expanded in terms of a kernel. Working in linear spaces of function has the benefit of facilitating the construction and analysis of learning algorithms while at the same time allowing large classes of functions. The latter include nonlinear functions as well as functions defined on nonvectorial data. We cover a wide range of methods, ranging from binary classifiers to sophisticated methods for estimation with structured data.},
	language = {en},
	number = {3},
	urldate = {2020-06-30},
	journal = {The Annals of Statistics},
	author = {Hofmann, Thomas and Schölkopf, Bernhard and Smola, Alexander J.},
	month = jun,
	year = {2008},
	note = {ZSCC: 0001515 
arXiv: math/0701907},
	keywords = {Mathematics - Statistics Theory, Mathematics - Probability, 30C40 (Primary) 68T05 (Secondary)},
	pages = {1171--1220},
	file = {Kernel methods in machine learning - Hofmann et al - 2008.pdf:/home/theo/Zotero/storage/QT8TCBQP/Kernel methods in machine learning - Hofmann et al - 2008.pdf:application/pdf},
}

@article{dutordoirSparseGaussianProcesses2020,
	title = {Sparse {Gaussian} {Processes} with {Spherical} {Harmonic} {Features}},
	url = {http://arxiv.org/abs/2006.16649},
	abstract = {We introduce a new class of inter-domain variational Gaussian processes (GP) where data is mapped onto the unit hypersphere in order to use spherical harmonic representations. Our inference scheme is comparable to variational Fourier features, but it does not suffer from the curse of dimensionality, and leads to diagonal covariance matrices between inducing variables. This enables a speed-up in inference, because it bypasses the need to invert large covariance matrices. Our experiments show that our model is able to fit a regression model for a dataset with 6 million entries two orders of magnitude faster compared to standard sparse GPs, while retaining state of the art accuracy. We also demonstrate competitive performance on classification with non-conjugate likelihoods.},
	urldate = {2020-07-02},
	journal = {arXiv:2006.16649 [cs, stat]},
	author = {Dutordoir, Vincent and Durrande, Nicolas and Hensman, James},
	month = jun,
	year = {2020},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 2006.16649},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, toread},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/5QE579GV/2006.html:text/html;Sparse Gaussian Processes with Spherical Harmonic Features - Dutordoir et al - 2020.pdf:/home/theo/Zotero/storage/A88ACXWW/Sparse Gaussian Processes with Spherical Harmonic Features - Dutordoir et al - 2020.pdf:application/pdf},
}

@article{alquierNoisyMonteCarlo2014,
	title = {Noisy {Monte} {Carlo}: {Convergence} of {Markov} chains with approximate transition kernels},
	shorttitle = {Noisy {Monte} {Carlo}},
	url = {http://arxiv.org/abs/1403.5496},
	abstract = {Monte Carlo algorithms often aim to draw from a distribution \${\textbackslash}pi\$ by simulating a Markov chain with transition kernel \$P\$ such that \${\textbackslash}pi\$ is invariant under \$P\$. However, there are many situations for which it is impractical or impossible to draw from the transition kernel \$P\$. For instance, this is the case with massive datasets, where is it prohibitively expensive to calculate the likelihood and is also the case for intractable likelihood models arising from, for example, Gibbs random fields, such as those found in spatial statistics and network analysis. A natural approach in these cases is to replace \$P\$ by an approximation \${\textbackslash}hat\{P\}\$. Using theory from the stability of Markov chains we explore a variety of situations where it is possible to quantify how 'close' the chain given by the transition kernel \${\textbackslash}hat\{P\}\$ is to the chain given by \$P\$. We apply these results to several examples from spatial statistics and network analysis.},
	urldate = {2020-06-29},
	journal = {arXiv:1403.5496 [stat]},
	author = {Alquier, P. and Friel, N. and Everitt, R. and Boland, A.},
	month = apr,
	year = {2014},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1403.5496},
	keywords = {Statistics - Methodology},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/VIHUG5PY/1403.html:text/html;Noisy Monte Carlo - Alquier et al - 2014.pdf:/home/theo/Zotero/storage/S8YL5M75/Noisy Monte Carlo - Alquier et al - 2014.pdf:application/pdf},
}

@article{rodriguesLikelihoodfreeApproximateGibbs2019,
	title = {Likelihood-free approximate {Gibbs} sampling},
	url = {http://arxiv.org/abs/1906.04347},
	abstract = {Likelihood-free methods such as approximate Bayesian computation (ABC) have extended the reach of statistical inference to problems with computationally intractable likelihoods. Such approaches perform well for small-to-moderate dimensional problems, but suffer a curse of dimensionality in the number of model parameters. We introduce a likelihood-free approximate Gibbs sampler that naturally circumvents the dimensionality issue by focusing on lower-dimensional conditional distributions. These distributions are estimated by flexible regression models either before the sampler is run, or adaptively during sampler implementation. As a result, and in comparison to Metropolis-Hastings based approaches, we are able to fit substantially more challenging statistical models than would otherwise be possible. We demonstrate the sampler's performance via two simulated examples, and a real analysis of Airbnb rental prices using a intractable high-dimensional multivariate non-linear state space model containing 13,140 parameters, which presents a real challenge to standard ABC techniques.},
	urldate = {2020-06-29},
	journal = {arXiv:1906.04347 [stat]},
	author = {Rodrigues, G. S. and Nott, D. J. and Sisson, S. A.},
	month = jun,
	year = {2019},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1906.04347},
	keywords = {Statistics - Machine Learning, Statistics - Computation, Statistics - Methodology, toread},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/7LCNMNFS/1906.html:text/html;Likelihood-free approximate Gibbs sampling - Rodrigues et al - 2019.pdf:/home/theo/Zotero/storage/QN2S9J7H/Likelihood-free approximate Gibbs sampling - Rodrigues et al - 2019.pdf:application/pdf},
}

@article{brehmerFlowsSimultaneousManifold2020,
	title = {Flows for simultaneous manifold learning and density estimation},
	url = {http://arxiv.org/abs/2003.13913},
	abstract = {We introduce manifold-learning flows (M-flows), a new class of generative models that simultaneously learn the data manifold as well as a tractable probability density on that manifold. Combining aspects of normalizing flows, GANs, autoencoders, and energy-based models, they have the potential to represent datasets with a manifold structure more faithfully and provide handles on dimensionality reduction, denoising, and out-of-distribution detection. We argue why such models should not be trained by maximum likelihood alone and present a new training algorithm that separates manifold and density updates. In a range of experiments we demonstrate how M-flows learn the data manifold and allow for better inference than standard flows in the ambient data space.},
	urldate = {2020-06-23},
	journal = {arXiv:2003.13913 [cs, stat]},
	author = {Brehmer, Johann and Cranmer, Kyle},
	month = jun,
	year = {2020},
	note = {ZSCC: 0000003 
arXiv: 2003.13913},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, toread},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/83MDYDB5/2003.html:text/html;Flows for simultaneous manifold learning and density estimation - Brehmer_Cranmer - 2020.pdf:/home/theo/Zotero/storage/2DHRUFEZ/Flows for simultaneous manifold learning and density estimation - Brehmer_Cranmer - 2020.pdf:application/pdf},
}

@article{kapoorVariationalAutoRegressiveGaussian2020,
	title = {Variational {Auto}-{Regressive} {Gaussian} {Processes} for {Continual} {Learning}},
	url = {http://arxiv.org/abs/2006.05468},
	abstract = {This paper proposes Variational Auto-Regressive Gaussian Process (VAR-GP), a principled Bayesian updating mechanism to incorporate new data for sequential tasks in the context of continual learning. It relies on a novel auto-regressive characterization of the variational distribution and inference is made scalable using sparse inducing point approximations. Experiments on standard continual learning benchmarks demonstrate the ability of VAR-GPs to perform well at new tasks without compromising performance on old ones, yielding competitive results to state-of-the-art methods. In addition, we qualitatively show how VAR-GP improves the predictive entropy estimates as we train on new tasks. Further, we conduct a thorough ablation study to verify the effectiveness of inferential choices.},
	urldate = {2020-06-16},
	journal = {arXiv:2006.05468 [cs, stat]},
	author = {Kapoor, Sanyam and Karaletsos, Theofanis and Bui, Thang D.},
	month = jun,
	year = {2020},
	note = {ZSCC: 0000000 
arXiv: 2006.05468},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/TPX4S4DF/2006.html:text/html;Variational Auto-Regressive Gaussian Processes for Continual Learning - Kapoor et al - 2020.pdf:/home/theo/Zotero/storage/UFBP83BI/Variational Auto-Regressive Gaussian Processes for Continual Learning - Kapoor et al - 2020.pdf:application/pdf},
}

@article{maSamplingCanBe2019,
	title = {Sampling can be faster than optimization},
	volume = {116},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1820003116},
	doi = {10.1073/pnas.1820003116},
	abstract = {Optimization algorithms and Monte Carlo sampling algorithms have provided the computational foundations for the rapid growth in applications of statistical machine learning in recent years. There is, however, limited theoretical understanding of the relationships between these 2 kinds of methodology, and limited understanding of relative strengths and weaknesses. Moreover, existing results have been obtained primarily in the setting of convex functions (for optimization) and log-concave functions (for sampling). In this setting, where local properties determine global properties, optimization algorithms are unsurprisingly more efficient computationally than sampling algorithms. We instead examine a class of nonconvex objective functions that arise in mixture modeling and multistable systems. In this nonconvex setting, we find that the computational complexity of sampling algorithms scales linearly with the model dimension while that of optimization algorithms scales exponentially.},
	language = {en},
	number = {42},
	urldate = {2020-06-15},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Ma, Yi-An and Chen, Yuansi and Jin, Chi and Flammarion, Nicolas and Jordan, Michael I.},
	month = oct,
	year = {2019},
	note = {ZSCC: 0000021},
	pages = {20881--20885},
	file = {Sampling can be faster than optimization - Ma et al - 2019.pdf:/home/theo/Zotero/storage/3UZMEMKX/Sampling can be faster than optimization - Ma et al - 2019.pdf:application/pdf},
}

@misc{covertIancovertNeuralGC2020,
	title = {iancovert/{Neural}-{GC}},
	copyright = {MIT License         ,                 MIT License},
	url = {https://github.com/iancovert/Neural-GC},
	abstract = {Granger causality discovery for neural networks. Contribute to iancovert/Neural-GC development by creating an account on GitHub.},
	urldate = {2020-06-12},
	author = {Covert, Ian},
	month = jun,
	year = {2020},
	note = {ZSCC: NoCitationData[s0] 
original-date: 2019-02-11T02:59:32Z},
}

@article{kipfNeuralRelationalInference2018,
	title = {Neural {Relational} {Inference} for {Interacting} {Systems}},
	url = {http://arxiv.org/abs/1802.04687},
	abstract = {Interacting systems are prevalent in nature, from dynamical systems in physics to complex societal dynamics. The interplay of components can give rise to complex behavior, which can often be explained using a simple model of the system's constituent parts. In this work, we introduce the neural relational inference (NRI) model: an unsupervised model that learns to infer interactions while simultaneously learning the dynamics purely from observational data. Our model takes the form of a variational auto-encoder, in which the latent code represents the underlying interaction graph and the reconstruction is based on graph neural networks. In experiments on simulated physical systems, we show that our NRI model can accurately recover ground-truth interactions in an unsupervised manner. We further demonstrate that we can find an interpretable structure and predict complex dynamics in real motion capture and sports tracking data.},
	urldate = {2020-06-12},
	journal = {arXiv:1802.04687 [cs, stat]},
	author = {Kipf, Thomas and Fetaya, Ethan and Wang, Kuan-Chieh and Welling, Max and Zemel, Richard},
	month = jun,
	year = {2018},
	note = {ZSCC: 0000141 
arXiv: 1802.04687},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/NEJYAMX9/1802.html:text/html;Neural Relational Inference for Interacting Systems - Kipf et al - 2018.pdf:/home/theo/Zotero/storage/N2RAFKTT/Neural Relational Inference for Interacting Systems - Kipf et al - 2018.pdf:application/pdf},
}

@article{tankNeuralGrangerCausality2018,
	title = {Neural {Granger} {Causality} for {Nonlinear} {Time} {Series}},
	url = {http://arxiv.org/abs/1802.05842},
	abstract = {While most classical approaches to Granger causality detection assume linear dynamics, many interactions in applied domains, like neuroscience and genomics, are inherently nonlinear. In these cases, using linear models may lead to inconsistent estimation of Granger causal interactions. We propose a class of nonlinear methods by applying structured multilayer perceptrons (MLPs) or recurrent neural networks (RNNs) combined with sparsity-inducing penalties on the weights. By encouraging specific sets of weights to be zero---in particular through the use of convex group-lasso penalties---we can extract the Granger causal structure. To further contrast with traditional approaches, our framework naturally enables us to efficiently capture long-range dependencies between series either via our RNNs or through an automatic lag selection in the MLP. We show that our neural Granger causality methods outperform state-of-the-art nonlinear Granger causality methods on the DREAM3 challenge data. This data consists of nonlinear gene expression and regulation time courses with only a limited number of time points. The successes we show in this challenging dataset provide a powerful example of how deep learning can be useful in cases that go beyond prediction on large datasets. We likewise demonstrate our methods in detecting nonlinear interactions in a human motion capture dataset.},
	urldate = {2020-06-12},
	journal = {arXiv:1802.05842 [stat]},
	author = {Tank, Alex and Covert, Ian and Foti, Nicholas and Shojaie, Ali and Fox, Emily},
	month = feb,
	year = {2018},
	note = {ZSCC: 0000016 
arXiv: 1802.05842},
	keywords = {Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/V4ZQGP6X/1802.html:text/html;Neural Granger Causality for Nonlinear Time Series - Tank et al - 2018.pdf:/home/theo/Zotero/storage/D4ESAD7V/Neural Granger Causality for Nonlinear Time Series - Tank et al - 2018.pdf:application/pdf},
}

@inproceedings{sukOnlineLearningSparse2012,
	address = {Seoul, Korea (South)},
	title = {Online learning of sparse pseudo-input {Gaussian} {Process}},
	isbn = {978-1-4673-1714-6 978-1-4673-1713-9 978-1-4673-1712-2},
	url = {http://ieeexplore.ieee.org/document/6377922/},
	doi = {10.1109/ICSMC.2012.6377922},
	abstract = {In this paper, we propose a novel method of online learning of sparse pseudo-data, representative of the whole training data, for Gaussian Process (GP) regressions. We call the proposed method Incremental Sparse Pseudo-input Gaussian Process (ISPGP) regression. The proposed ISPGP algorithm allows for training from either a huge amount of training data by scanning through it only once or an online incremental training dataset. Thanks to the nature of the incremental learning algorithm, the proposed ISPGP algorithm can theoretically work with inﬁnite data to which the conventional GP or SPGP algorithm is not applicable. From our experimental results on the KIN40K dataset, we can see that the proposed ISPGP algorithm is comparable to the conventional GP algorithm using the same number of training data. Although the proposed ISPGP algorithm performs slightly worse than Snelson and Ghahramani’s SPGP algorithm, the level of performance degradation is acceptable.},
	language = {en},
	urldate = {2020-06-12},
	booktitle = {2012 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({SMC})},
	publisher = {IEEE},
	author = {Suk, Heung-Il and Wang, Yuzhuo and Lee, Seong-Whan},
	month = oct,
	year = {2012},
	note = {ZSCC: 0000000},
	pages = {1357--1360},
	file = {Online learning of sparse pseudo-input Gaussian Process - Suk et al - 2012.pdf:/home/theo/Zotero/storage/3HG6JCK7/Online learning of sparse pseudo-input Gaussian Process - Suk et al - 2012.pdf:application/pdf},
}

@article{pangNeuralnetinducedGaussianProcess2019,
	title = {Neural-net-induced {Gaussian} process regression for function approximation and {PDE} solution},
	volume = {384},
	issn = {00219991},
	url = {http://arxiv.org/abs/1806.11187},
	doi = {10.1016/j.jcp.2019.01.045},
	abstract = {Neural-net-induced Gaussian process (NNGP) regression inherits both the high expressivity of deep neural networks (deep NNs) as well as the uncertainty quantification property of Gaussian processes (GPs). We generalize the current NNGP to first include a larger number of hyperparameters and subsequently train the model by maximum likelihood estimation. Unlike previous works on NNGP that targeted classification, here we apply the generalized NNGP to function approximation and to solving partial differential equations (PDEs). Specifically, we develop an analytical iteration formula to compute the covariance function of GP induced by deep NN with an error-function nonlinearity. We compare the performance of the generalized NNGP for function approximations and PDE solutions with those of GPs and fully-connected NNs. We observe that for smooth functions the generalized NNGP can yield the same order of accuracy with GP, while both NNGP and GP outperform deep NN. For non-smooth functions, the generalized NNGP is superior to GP and comparable or superior to deep NN.},
	urldate = {2020-06-11},
	journal = {Journal of Computational Physics},
	author = {Pang, Guofei and Yang, Liu and Karniadakis, George Em},
	month = may,
	year = {2019},
	note = {ZSCC: 0000026 
arXiv: 1806.11187},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	pages = {270--288},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/K3I5UPIL/1806.html:text/html;Neural-net-induced Gaussian process regression for function approximation and - Pang et al - 2019.pdf:/home/theo/Zotero/storage/78AJIS3E/Neural-net-induced Gaussian process regression for function approximation and - Pang et al - 2019.pdf:application/pdf},
}

@article{limOperatorvaluedKernelbasedVector2015,
	title = {Operator-valued kernel-based vector autoregressive models for network inference},
	volume = {99},
	issn = {0885-6125, 1573-0565},
	url = {http://link.springer.com/10.1007/s10994-014-5479-3},
	doi = {10.1007/s10994-014-5479-3},
	language = {en},
	number = {3},
	urldate = {2020-06-11},
	journal = {Machine Learning},
	author = {Lim, Néhémy and d’Alché-Buc, Florence and Auliac, Cédric and Michailidis, George},
	month = jun,
	year = {2015},
	note = {ZSCC: NoCitationData[s0]},
	pages = {489--513},
	file = {Operator-valued kernel-based vector autoregressive models for network inference - Lim et al - 2015.pdf:/home/theo/Zotero/storage/CCHB2GLG/Operator-valued kernel-based vector autoregressive models for network inference - Lim et al - 2015.pdf:application/pdf;Operator-valued kernel-based vector autoregressive models for network inference - Lim et al - 2015.pdf:/home/theo/Zotero/storage/GHB32C35/Operator-valued kernel-based vector autoregressive models for network inference - Lim et al - 2015.pdf:application/pdf},
}

@article{riutort-mayolPracticalHilbertSpace2020,
	title = {Practical {Hilbert} space approximate {Bayesian} {Gaussian} processes for probabilistic programming},
	url = {http://arxiv.org/abs/2004.11408},
	abstract = {Gaussian processes are powerful non-parametric probabilistic models for stochastic functions. However they entail a complexity that is computationally intractable when the number of observations is large, especially when estimated with fully Bayesian methods such as Markov chain Monte Carlo. In this paper, we focus on a novel approach for low-rank approximate Bayesian Gaussian processes, based on a basis function approximation via Laplace eigenfunctions for stationary covariance functions. The main contribution of this paper is a detailed analysis of the performance and practical implementation of the method in relation to key factors such as the number of basis functions, domain of the prediction space, and smoothness of the latent function. We provide intuitive visualizations and recommendations for choosing the values of these factors, which make it easier for users to improve approximation accuracy and computational performance. We also propose diagnostics for checking that the number of basis functions and the domain of the prediction space are adequate given the data. The proposed approach is simple and exhibits an attractive computational complexity due to its linear structure, and it is easy to implement in probabilistic programming frameworks. Several illustrative examples of the performance and applicability of the method in the probabilistic programming language Stan are presented together with the underlying Stan model code.},
	urldate = {2020-06-11},
	journal = {arXiv:2004.11408 [stat]},
	author = {Riutort-Mayol, Gabriel and Bürkner, Paul-Christian and Andersen, Michael R. and Solin, Arno and Vehtari, Aki},
	month = apr,
	year = {2020},
	note = {ZSCC: 0000000 
arXiv: 2004.11408},
	keywords = {Statistics - Computation, Statistics - Methodology},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/KIUQJVCX/2004.html:text/html;Practical Hilbert space approximate Bayesian Gaussian processes for - Riutort-Mayol et al - 2020.pdf:/home/theo/Zotero/storage/APB3QD9H/Practical Hilbert space approximate Bayesian Gaussian processes for - Riutort-Mayol et al - 2020.pdf:application/pdf},
}

@article{robertsGaussianProcessesTimeseries2013,
	title = {Gaussian processes for time-series modelling},
	volume = {371},
	issn = {1364-503X, 1471-2962},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2011.0550},
	doi = {10.1098/rsta.2011.0550},
	abstract = {In this paper we offer a gentle introduction to Gaussian processes for timeseries data analysis. The conceptual framework of Bayesian modelling for timeseries data is discussed and the foundations of Bayesian non-parametric modelling presented for Gaussian processes. We discuss how domain knowledge inﬂuences design of the Gaussian process models and provide case examples to highlight the approaches.},
	language = {en},
	number = {1984},
	urldate = {2020-06-10},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Roberts, S. and Osborne, M. and Ebden, M. and Reece, S. and Gibson, N. and Aigrain, S.},
	month = feb,
	year = {2013},
	note = {ZSCC: 0000292},
	pages = {20110550},
	file = {Gaussian processes for time-series modelling - Roberts et al - 2013.pdf:/home/theo/Zotero/storage/23JD56D5/Gaussian processes for time-series modelling - Roberts et al - 2013.pdf:application/pdf},
}

@article{chenStochasticGradientHamiltonian2014,
	title = {Stochastic {Gradient} {Hamiltonian} {Monte} {Carlo}},
	url = {http://arxiv.org/abs/1402.4102},
	abstract = {Hamiltonian Monte Carlo (HMC) sampling methods provide a mechanism for defining distant proposals with high acceptance probabilities in a Metropolis-Hastings framework, enabling more efficient exploration of the state space than standard random-walk proposals. The popularity of such methods has grown significantly in recent years. However, a limitation of HMC methods is the required gradient computation for simulation of the Hamiltonian dynamical system-such computation is infeasible in problems involving a large sample size or streaming data. Instead, we must rely on a noisy gradient estimate computed from a subset of the data. In this paper, we explore the properties of such a stochastic gradient HMC approach. Surprisingly, the natural implementation of the stochastic approximation can be arbitrarily bad. To address this problem we introduce a variant that uses second-order Langevin dynamics with a friction term that counteracts the effects of the noisy gradient, maintaining the desired target distribution as the invariant distribution. Results on simulated data validate our theory. We also provide an application of our methods to a classification task using neural networks and to online Bayesian matrix factorization.},
	urldate = {2020-06-08},
	journal = {arXiv:1402.4102 [cs, stat]},
	author = {Chen, Tianqi and Fox, Emily B. and Guestrin, Carlos},
	month = may,
	year = {2014},
	note = {ZSCC: 0000368 
arXiv: 1402.4102},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Methodology},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/9FHJIHSE/1402.html:text/html;Stochastic Gradient Hamiltonian Monte Carlo - Chen et al - 2014.pdf:/home/theo/Zotero/storage/SXPP6IRP/Stochastic Gradient Hamiltonian Monte Carlo - Chen et al - 2014.pdf:application/pdf},
}

@article{futamiFrankWolfeSteinSampling2018,
	title = {Frank-{Wolfe} {Stein} {Sampling}},
	url = {http://arxiv.org/abs/1805.07912},
	abstract = {In Bayesian inference, the posterior distributions are difficult to obtain analytically for complex models such as neural networks. Variational inference usually uses a parametric distribution for approximation, from which we can easily draw samples. Recently discrete approximation by particles has attracted attention because of its high expression ability. An example is Stein variational gradient descent (SVGD), which iteratively optimizes particles. Although SVGD has been shown to be computationally efficient empirically, its theoretical properties have not been clarified yet and no finite sample bound of the convergence rate is known. Another example is the Stein points (SP) method, which minimizes kernelized Stein discrepancy directly. Although a finite sample bound is assured theoretically, SP is computationally inefficient empirically, especially in high-dimensional problems. In this paper, we propose a novel method named maximum mean discrepancy minimization by the Frank-Wolfe algorithm (MMD-FW), which minimizes MMD in a greedy way by the FW algorithm. Our method is computationally efficient empirically and we show that its finite sample convergence bound is in a linear order in finite dimensions.},
	urldate = {2020-06-08},
	journal = {arXiv:1805.07912 [cs, stat]},
	author = {Futami, Futoshi and Cui, Zhenghang and Sato, Issei and Sugiyama, Masashi},
	month = may,
	year = {2018},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1805.07912
version: 1},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/LZSU7PLE/1805.html:text/html;Frank-Wolfe Stein Sampling - Futami et al - 2018.pdf:/home/theo/Zotero/storage/N4GZ89YN/Frank-Wolfe Stein Sampling - Futami et al - 2018.pdf:application/pdf},
}

@article{hoffmanNoUTurnSamplerAdaptively2011,
	title = {The {No}-{U}-{Turn} {Sampler}: {Adaptively} {Setting} {Path} {Lengths} in {Hamiltonian} {Monte} {Carlo}},
	shorttitle = {The {No}-{U}-{Turn} {Sampler}},
	url = {http://arxiv.org/abs/1111.4246},
	abstract = {Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm that avoids the random walk behavior and sensitivity to correlated parameters that plague many MCMC methods by taking a series of steps informed by first-order gradient information. These features allow it to converge to high-dimensional target distributions much more quickly than simpler methods such as random walk Metropolis or Gibbs sampling. However, HMC's performance is highly sensitive to two user-specified parameters: a step size \{{\textbackslash}epsilon\} and a desired number of steps L. In particular, if L is too small then the algorithm exhibits undesirable random walk behavior, while if L is too large the algorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an extension to HMC that eliminates the need to set a number of steps L. NUTS uses a recursive algorithm to build a set of likely candidate points that spans a wide swath of the target distribution, stopping automatically when it starts to double back and retrace its steps. Empirically, NUTS perform at least as efficiently as and sometimes more efficiently than a well tuned standard HMC method, without requiring user intervention or costly tuning runs. We also derive a method for adapting the step size parameter \{{\textbackslash}epsilon\} on the fly based on primal-dual averaging. NUTS can thus be used with no hand-tuning at all. NUTS is also suitable for applications such as BUGS-style automatic inference engines that require efficient "turnkey" sampling algorithms.},
	urldate = {2020-06-08},
	journal = {arXiv:1111.4246 [cs, stat]},
	author = {Hoffman, Matthew D. and Gelman, Andrew},
	month = nov,
	year = {2011},
	note = {ZSCC: 0000009 
arXiv: 1111.4246},
	keywords = {Computer Science - Machine Learning, Statistics - Computation},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/F8GMK83Z/1111.html:text/html;The No-U-Turn Sampler - Hoffman_Gelman - 2011.pdf:/home/theo/Zotero/storage/6EP6ZANX/The No-U-Turn Sampler - Hoffman_Gelman - 2011.pdf:application/pdf},
}

@article{agrawalKernelInteractionTrick,
	title = {The {Kernel} {Interaction} {Trick}: {Fast} {Bayesian} {Discovery} of {Pairwise}  {Interactions} in {High} {Dimensions}},
	abstract = {Discovering interaction effects on a response of interest is a fundamental problem faced in biology, medicine, economics, and many other scientiﬁc disciplines. In theory, Bayesian methods for discovering pairwise interactions enjoy many beneﬁts such as coherent uncertainty quantiﬁcation, the ability to incorporate background knowledge, and desirable shrinkage properties. In practice, however, Bayesian methods are often computationally intractable for even moderatedimensional problems. Our key insight is that many hierarchical models of practical interest admit a particular Gaussian process (GP) representation; the GP allows us to capture the posterior with a vector of O(p) kernel hyper-parameters rather than O(p2) interactions and main effects. With the implicit representation, we can run Markov chain Monte Carlo (MCMC) over model hyperparameters in time and memory linear in p per iteration. We focus on sparsity-inducing models and show on datasets with a variety of covariate behaviors that our method: (1) reduces runtime by orders of magnitude over naive applications of MCMC, (2) provides lower Type I and Type II error relative to state-of-the-art LASSO-based approaches, and (3) offers improved computational scaling in high dimensions relative to existing Bayesian and LASSO-based approaches.},
	language = {en},
	author = {Agrawal, Raj and Huggins, Jonathan H and Trippe, Brian L and Broderick, Tamara},
	note = {ZSCC: 0000004},
	pages = {10},
	file = {The Kernel Interaction Trick - Agrawal et al -.pdf:/home/theo/Zotero/storage/4PS7CHNY/The Kernel Interaction Trick - Agrawal et al -.pdf:application/pdf},
}

@incollection{osborneActiveLearningModel2012,
	title = {Active {Learning} of {Model} {Evidence} {Using} {Bayesian} {Quadrature}},
	url = {http://papers.nips.cc/paper/4657-active-learning-of-model-evidence-using-bayesian-quadrature.pdf},
	urldate = {2020-06-03},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Osborne, Michael and Garnett, Roman and Ghahramani, Zoubin and Duvenaud, David K and Roberts, Stephen J and Rasmussen, Carl E.},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	note = {ZSCC: NoCitationData[s0]},
	pages = {46--54},
	file = {NIPS Snapshot:/home/theo/Zotero/storage/7ZI4IETA/4657-active-learning-of-model-evidence-using-bayesian-quadrature.html:text/html;Active Learning of Model Evidence Using Bayesian Quadrature - Osborne et al - 2012.pdf:/home/theo/Zotero/storage/RGTHZ5X6/Active Learning of Model Evidence Using Bayesian Quadrature - Osborne et al - 2012.pdf:application/pdf},
}

@article{izmailovScalableGaussianProcesses2018,
	title = {Scalable {Gaussian} {Processes} with {Billions} of {Inducing} {Inputs} via {Tensor} {Train} {Decomposition}},
	abstract = {We propose a method (TT-GP) for approximate inference in Gaussian Process (GP) models. We build on previous scalable GP research including stochastic variational inference based on inducing inputs, kernel interpolation, and structure exploiting algebra. The key idea of our method is to use Tensor Train decomposition for variational parameters, which allows us to train GPs with billions of inducing inputs and achieve state-of-the-art results on several benchmarks. Further, our approach allows for training kernels based on deep neural networks without any modiﬁcations to the underlying GP model. A neural network learns a multidimensional embedding for the data, which is used by the GP to make the ﬁnal prediction. We train GP and neural network parameters end-to-end without pretraining, through maximization of GP marginal likelihood. We show the eﬃciency of the proposed approach on several regression and classiﬁcation benchmark datasets including MNIST, CIFAR-10, and Airline.},
	language = {en},
	author = {Izmailov, Pavel A and Novikov, Alexander V and Kropotov, Dmitry A},
	year = {2018},
	note = {ZSCC: NoCitationData[s0]},
	pages = {10},
	file = {Scalable Gaussian Processes with Billions of Inducing Inputs via Tensor Train - Izmailov et al - 2018.pdf:/home/theo/Zotero/storage/HDLUL6UN/Scalable Gaussian Processes with Billions of Inducing Inputs via Tensor Train - Izmailov et al - 2018.pdf:application/pdf;Scalable Gaussian Processes with Billions of Inducing Inputs via Tensor Train - Izmailov et al - 2018.pdf:/home/theo/Zotero/storage/85JXYINJ/Scalable Gaussian Processes with Billions of Inducing Inputs via Tensor Train - Izmailov et al - 2018.pdf:application/pdf},
}

@article{muandetKernelMeanEmbedding2017,
	title = {Kernel mean embedding of distributions: {A} review and beyond},
	volume = {10},
	issn = {19358245},
	doi = {10.1561/2200000060},
	abstract = {A Hilbert space embedding of a distribution-in short, a kernel mean embedding-has recently emerged as a powerful tool for machine learning and statistical inference. The basic idea behind this framework is to map distributions into a reproducing kernel Hilbert space (RKHS) in which the whole arsenal of kernel methods can be extended to probability measures. It can be viewed as a generalization of the original "feature map" common to support vector machines (SVMs) and other kernel methods. In addition to the classical applications of kernel methods, the kernel mean embedding has found novel applications in fields ranging from probabilistic modeling to statistical inference, causal discovery, and deep learning. This survey aims to give a comprehensive review of existing work and recent advances in this research area, and to discuss challenging issues and open problems that could potentially lead to new research directions. The survey begins with a brief introduction to the RKHS and positive definite kernels which forms the backbone of this survey, followed by a thorough discussion of the Hilbert space embedding of marginal distributions, theoretical guarantees, and a review of its applications. The embedding of distributions enables us to apply RKHS methods to probability measures which prompts a wide range of applications such as kernel two-sample testing, independent testing, and learning on distributional data. Next, we discuss the Hilbert space embedding for conditional distributions, give theoretical insights, and review some applications. The conditional mean embedding enables us to perform sum, product, and Bayes' rules-which are ubiquitous in graphical model, probabilistic inference, and reinforcement learning- in a non-parametric way using this new representation of distributions. We then discuss relationships between this framework and other related areas. Lastly, we give some suggestions on future research directions.},
	number = {1-2},
	journal = {Foundations and Trends in Machine Learning},
	author = {Muandet, Krikamol and Fukumizu, Kenji and Sriperumbudur, Bharath and Schölkopf, Bernhard},
	year = {2017},
	note = {ZSCC: 0000213 
arXiv: 1605.09522},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	pages = {1--141},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/4NL5K27W/1605.html:text/html;Kernel mean embedding of distributions - Muandet et al - 2017.pdf:/home/theo/Zotero/storage/ETYBXAQJ/Kernel mean embedding of distributions - Muandet et al - 2017.pdf:application/pdf},
}

@article{sawhneyMonteCarloGeometry,
	title = {Monte {Carlo} {Geometry} {Processing}:{A} {Grid}-{Free} {Approach} to {PDE}-{Based} {Methods} on {Volumetric} {Domains}},
	volume = {38},
	language = {en},
	number = {4},
	author = {Sawhney, Rohan and Crane, Keenan},
	note = {ZSCC: NoCitationData[s1]},
	pages = {18},
	file = {Sawhney and Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf:/home/theo/Zotero/storage/6CCMIG6M/Sawhney and Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf:application/pdf;Sawhney and Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf:/home/theo/Zotero/storage/TLDSCS65/Sawhney and Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf:application/pdf;Sawhney and Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf:/home/theo/Zotero/storage/W2CWMPUE/Sawhney and Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf:application/pdf;Sawhney and Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf:/home/theo/Zotero/storage/YGZDJ8EU/Sawhney and Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf:application/pdf;Sawhney and Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf:/home/theo/Zotero/storage/C293QTKU/Sawhney and Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf:application/pdf;Sawhney and Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf:/home/theo/Zotero/storage/H2NJ69A3/Sawhney and Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf:application/pdf},
}

@article{rasmussenGaussianProcessesSpeed,
	title = {Gaussian {Processes} to {Speed} up {Hybrid} {Monte} {Carlo} for {Expensive} {Bayesian} {Integrals}},
	abstract = {Hybrid Monte Carlo (HMC) is often the method of choice for computing Bayesian integrals that are not analytically tractable. However the success of this method may require a very large number of evaluations of the (un-normalized) posterior and its partial derivatives. In situations where the posterior is computationally costly to evaluate, this may lead to an unacceptable computational load for HMC. I propose to use a Gaussian Process model of the (log of the) posterior for most of the computations required by HMC. Within this scheme only occasional evaluation of the actual posterior is required to guarantee that the samples generated have exactly the desired distribution, even if the GP model is somewhat inaccurate. The method is demonstrated on a 10 dimensional problem, where 200 evaluations sufﬁce for the generation of 100 roughly independent points from the posterior. Thus, the proposed scheme allows Bayesian treatment of models with posteriors that are computationally demanding, such as models involving computer simulation.},
	language = {en},
	author = {Rasmussen, Carl Edward},
	note = {ZSCC: 0000165},
	pages = {9},
	file = {Gaussian Processes to Speed up Hybrid Monte Carlo for Expensive Bayesian - Rasmussen -.pdf:/home/theo/Zotero/storage/AY4347IF/Gaussian Processes to Speed up Hybrid Monte Carlo for Expensive Bayesian - Rasmussen -.pdf:application/pdf},
}

@article{radivojevicModifiedHamiltonianMonte2020,
	title = {Modified {Hamiltonian} {Monte} {Carlo} for {Bayesian} inference},
	volume = {30},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-019-09885-x},
	doi = {10.1007/s11222-019-09885-x},
	language = {en},
	number = {2},
	urldate = {2020-06-02},
	journal = {Statistics and Computing},
	author = {Radivojević, Tijana and Akhmatskaya, Elena},
	month = mar,
	year = {2020},
	note = {ZSCC: 0000002},
	pages = {377--404},
	file = {Modified Hamiltonian Monte Carlo for Bayesian inference - Radivojević_Akhmatskaya - 2020.pdf:/home/theo/Zotero/storage/KKZFX9LV/Modified Hamiltonian Monte Carlo for Bayesian inference - Radivojević_Akhmatskaya - 2020.pdf:application/pdf},
}

@article{kanagawaConvergenceGuaranteesAdaptive2019,
	title = {Convergence {Guarantees} for {Adaptive} {Bayesian} {Quadrature} {Methods}},
	url = {http://arxiv.org/abs/1905.10271},
	abstract = {Adaptive Bayesian quadrature (ABQ) is a powerful approach to numerical integration that empirically compares favorably with Monte Carlo integration on problems of medium dimensionality (where non-adaptive quadrature is not competitive). Its key ingredient is an acquisition function that changes as a function of previously collected values of the integrand. While this adaptivity appears to be empirically powerful, it complicates analysis. Consequently, there are no theoretical guarantees so far for this class of methods. In this work, for a broad class of adaptive Bayesian quadrature methods, we prove consistency, deriving non-tight but informative convergence rates. To do so we introduce a new concept we call weak adaptivity. Our results identify a large and flexible class of adaptive Bayesian quadrature rules as consistent, within which practitioners can develop empirically efficient methods.},
	urldate = {2020-06-02},
	journal = {arXiv:1905.10271 [cs, math, stat]},
	author = {Kanagawa, Motonobu and Hennig, Philipp},
	month = oct,
	year = {2019},
	note = {ZSCC: 0000002 
arXiv: 1905.10271},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Computation, Mathematics - Numerical Analysis},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/GF83UMQS/1905.html:text/html;Convergence Guarantees for Adaptive Bayesian Quadrature Methods - Kanagawa_Hennig - 2019.pdf:/home/theo/Zotero/storage/WQZYVFX7/Convergence Guarantees for Adaptive Bayesian Quadrature Methods - Kanagawa_Hennig - 2019.pdf:application/pdf},
}

@incollection{karvonenBayesSardCubatureMethod2018,
	title = {A {Bayes}-{Sard} {Cubature} {Method}},
	url = {http://papers.nips.cc/paper/7829-a-bayes-sard-cubature-method.pdf},
	urldate = {2020-06-02},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 31},
	publisher = {Curran Associates, Inc.},
	author = {Karvonen, Toni and Oates, Chris J and Sarkka, Simo},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
	note = {ZSCC: NoCitationData[s0]},
	pages = {5882--5893},
	file = {NIPS Snapshot:/home/theo/Zotero/storage/NWQHNPDR/7829-a-bayes-sard-cubature-method.html:text/html;A Bayes-Sard Cubature Method - Karvonen et al - 2018.pdf:/home/theo/Zotero/storage/VJZM4TGW/A Bayes-Sard Cubature Method - Karvonen et al - 2018.pdf:application/pdf},
}

@article{grathwohlCuttingOutMiddleMan2020,
	title = {Cutting out the {Middle}-{Man}: {Training} and {Evaluating} {Energy}-{Based} {Models} without {Sampling}},
	shorttitle = {Cutting out the {Middle}-{Man}},
	url = {http://arxiv.org/abs/2002.05616},
	abstract = {We present a new method for evaluating and training unnormalized density models. Our approach only requires access to the gradient of the unnormalized model's log-density. We estimate the Stein discrepancy between the data density p(x) and the model density q(x) defined by a vector function of the data. We parameterize this function with a neural network and fit its parameters to maximize the discrepancy. This yields a novel goodness-of-fit test which outperforms existing methods on high dimensional data. Furthermore, optimizing \$q(x)\$ to minimize this discrepancy produces a novel method for training unnormalized models which scales more gracefully than existing methods. The ability to both learn and compare models is a unique feature of the proposed method.},
	urldate = {2020-06-02},
	journal = {arXiv:2002.05616 [cs, stat]},
	author = {Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, Jorn-Henrik and Duvenaud, David and Zemel, Richard},
	month = feb,
	year = {2020},
	note = {ZSCC: 0000000 
arXiv: 2002.05616},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/P2D9XJHW/2002.html:text/html;Cutting out the Middle-Man - Grathwohl et al - 2020.pdf:/home/theo/Zotero/storage/7U5KHGE4/Cutting out the Middle-Man - Grathwohl et al - 2020.pdf:application/pdf},
}

@article{quinonero-candelaUnifyingViewSparse2005,
	title = {A {Unifying} {View} of {Sparse} {Approximate} {Gaussian} {Process} {Regression}},
	volume = {6},
	abstract = {We provide a new unifying view, including all existing proper probabilistic sparse approximations for Gaussian process regression. Our approach relies on expressing the effective prior which the methods are using. This allows new insights to be gained, and highlights the relationship between existing methods. It also allows for a clear theoretically justiﬁed ranking of the closeness of the known approximations to the corresponding full GPs. Finally we point directly to designs of new better sparse approximations, combining the best of the existing strategies, within attractive computational constraints.},
	language = {en},
	journal = {Journal of Machine Learning Research},
	author = {Quinonero-Candela, Joaquin and Rasmussen, Carl Edward},
	year = {2005},
	note = {ZSCC: NoCitationData[s0]},
	pages = {1939--1959},
	file = {A Unifying View of Sparse Approximate Gaussian Process Regression - Quinonero-Candela_Rasmussen - 2005.pdf:/home/theo/Zotero/storage/WA3QTAC2/A Unifying View of Sparse Approximate Gaussian Process Regression - Quinonero-Candela_Rasmussen - 2005.pdf:application/pdf},
}

@article{Hensman2013,
	title = {Gaussian {Processes} for {Big} {Data}},
	issn = {0899-7667},
	abstract = {We introduce stochastic variational inference for Gaussian process models. This enables the application of Gaussian process (GP) models to data sets containing millions of data points. We show how GPs can be vari- ationally decomposed to depend on a set of globally relevant inducing variables which factorize the model in the necessary manner to perform variational inference. Our ap- proach is readily extended to models with non-Gaussian likelihoods and latent variable models based around Gaussian processes. We demonstrate the approach on a simple toy problem and two real world data sets.},
	journal = {Proceedings of UAI 29},
	author = {Hensman, James and Sheffield, Uk and Fusi, N and Lawrence, Nd},
	year = {2013},
	pmid = {80990000001},
	note = {ZSCC: NoCitationData[s1] 
arXiv: 1309.6835
ISBN: 978-1-4503-1285-1},
	pages = {282--290},
	file = {Gaussian Processes for Big Data - Hensman et al - 2013.pdf:/home/theo/Zotero/storage/B4MNTS6G/Gaussian Processes for Big Data - Hensman et al - 2013.pdf:},
}

@article{remesModellingNonstationaryFunctions,
	title = {Modelling non-stationary functions with {Gaussian} processes},
	abstract = {Gaussian processes (GP's) are a central piece of non-parametric Bayesian methods, which allow placing priors over functions in settings such as classiﬁcation and regression. The prior is described using a kernel function that encodes a similarity between any two points in the input space, and thus deﬁnes the properties of functions that are modelled by the GP. In applying Gaussian processes the choice of the kernel is crucial, and the commonly used standard kernels often offer unsatisfactory performance due to making the assumption of stationarity. This thesis presents approaches in modelling non-stationarity from two different perspectives in Gaussian processes. First, this thesis presents a formulation of a non-stationary spectral mixture kernel for univariate outputs, focusing on modelling the non-stationarity in the input space. The construction is based on the spectral mixture (SM) kernel, which has been derived for stationary functions using the Fourier duality implied by Bochner's theorem. The work done in this thesis extends the SM kernel into the non-stationary case. This is achieved by two complementary approaches, based on replacing the constant frequency parameters by input-dependent functions. The ﬁrst approach is based on modelling the latent functions describing the frequency surface as Gaussian processes. In the second approach the functions are directly modelled as a neural network, parameters of which are optimized with respect to the variational evidence lower bound (ELBO). Second, this thesis presents a kernel suitable for modelling non-stationary couplings between multiple output variables of interest in the context of multi-task or multi-output GP regression. The construction of the kernel is based on a Hadamard product of two kernels, which model the different aspects of dependencies between the outputs. The part of the kernel modelling the inputdependent couplings is based on a generalized Wishart process, which is a stochastic process on time-varying positive-deﬁnite matrices, in this case describing the changing dependencies between the outputs. The proposed Hadamard product kernel is applied in a latent factor model to enrich the latent variable prior distribution, that is, to model correlations within the latent variables explicitly. This results in the latent correlation Gaussian process model (LCGP). This thesis additionally considers novel, ﬂexible models for classiﬁcation of multi-view data, speciﬁcally one based on a mixture of group factor analyzers (GFA). The model has a close relationship to the LCGP that builds a classiﬁer in the latent variable space, while the classiﬁer in the GFA mixture is based on the mixture assignments. GFA also allows modelling dependencies between groups of variables, which is not done by the LCGP. Applying Gaussian processes and adapting the proposed multi-output kernel would make the multi-view model even more general. The methods introduced in this thesis now allow modelling non-stationary functions in Gaussian processes in a ﬂexible way. The proposed kernels can be applied very generally, and the approaches introduced to derive them can also be applied to derive other types of non-stationary kernels.},
	language = {en},
	author = {Remes, Sami},
	note = {ZSCC: 0000000},
	pages = {46},
	file = {Modelling non-stationary functions with Gaussian processes - Remes -.pdf:/home/theo/Zotero/storage/CQ5VGQHJ/Modelling non-stationary functions with Gaussian processes - Remes -.pdf:application/pdf},
}

@article{cowlesMarkovChainMonte1996,
	title = {Markov {Chain} {Monte} {Carlo} {Convergence} {Diagnostics}: {A} {Comparative} {Review}},
	volume = {91},
	issn = {0162-1459, 1537-274X},
	shorttitle = {Markov {Chain} {Monte} {Carlo} {Convergence} {Diagnostics}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1996.10476956},
	doi = {10.1080/01621459.1996.10476956},
	language = {en},
	number = {434},
	urldate = {2020-05-19},
	journal = {Journal of the American Statistical Association},
	author = {Cowles, Mary Kathryn and Carlin, Bradley P.},
	month = jun,
	year = {1996},
	note = {ZSCC: 0002389},
	pages = {883--904},
	file = {Markov Chain Monte Carlo Convergence Diagnostics - Cowles_Carlin - 1996.pdf:/home/theo/Zotero/storage/B9ARQ8JZ/Markov Chain Monte Carlo Convergence Diagnostics - Cowles_Carlin - 1996.pdf:application/pdf},
}

@article{briolProbabilisticIntegrationRole2017,
	title = {Probabilistic {Integration}: {A} {Role} in {Statistical} {Computation}?},
	shorttitle = {Probabilistic {Integration}},
	url = {http://arxiv.org/abs/1512.00933},
	abstract = {A research frontier has emerged in scientific computation, wherein numerical error is regarded as a source of epistemic uncertainty that can be modelled. This raises several statistical challenges, including the design of statistical methods that enable the coherent propagation of probabilities through a (possibly deterministic) computational work-flow. This paper examines the case for probabilistic numerical methods in routine statistical computation. Our focus is on numerical integration, where a probabilistic integrator is equipped with a full distribution over its output that reflects the presence of an unknown numerical error. Our main technical contribution is to establish, for the first time, rates of posterior contraction for these methods. These show that probabilistic integrators can in principle enjoy the "best of both worlds", leveraging the sampling efficiency of Monte Carlo methods whilst providing a principled route to assess the impact of numerical error on scientific conclusions. Several substantial applications are provided for illustration and critical evaluation, including examples from statistical modelling, computer graphics and a computer model for an oil reservoir.},
	urldate = {2020-05-18},
	journal = {arXiv:1512.00933 [cs, math, stat]},
	author = {Briol, François-Xavier and Oates, Chris J. and Girolami, Mark and Osborne, Michael A. and Sejdinovic, Dino},
	month = oct,
	year = {2017},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1512.00933},
	keywords = {Statistics - Machine Learning, Statistics - Computation, Mathematics - Numerical Analysis, Mathematics - Statistics Theory, toread},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/7N4K5M5N/1512.html:text/html;Probabilistic Integration - Briol et al - 2017.pdf:/home/theo/Zotero/storage/I6Y24SYJ/Probabilistic Integration - Briol et al - 2017.pdf:application/pdf},
}

@article{acerbiVariationalBayesianMonte2018,
	title = {Variational {Bayesian} {Monte} {Carlo}},
	url = {http://arxiv.org/abs/1810.05558},
	abstract = {Many probabilistic models of interest in scientific computing and machine learning have expensive, black-box likelihoods that prevent the application of standard techniques for Bayesian inference, such as MCMC, which would require access to the gradient or a large number of likelihood evaluations. We introduce here a novel sample-efficient inference framework, Variational Bayesian Monte Carlo (VBMC). VBMC combines variational inference with Gaussian-process based, active-sampling Bayesian quadrature, using the latter to efficiently approximate the intractable integral in the variational objective. Our method produces both a nonparametric approximation of the posterior distribution and an approximate lower bound of the model evidence, useful for model selection. We demonstrate VBMC both on several synthetic likelihoods and on a neuronal model with data from real neurons. Across all tested problems and dimensions (up to \$D = 10\$), VBMC performs consistently well in reconstructing the posterior and the model evidence with a limited budget of likelihood evaluations, unlike other methods that work only in very low dimensions. Our framework shows great promise as a novel tool for posterior and model inference with expensive, black-box likelihoods.},
	urldate = {2020-05-18},
	journal = {arXiv:1810.05558 [cs, q-bio, stat]},
	author = {Acerbi, Luigi},
	month = nov,
	year = {2018},
	note = {ZSCC: 0000013 
arXiv: 1810.05558},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, toread, Quantitative Biology - Neurons and Cognition, Quantitative Biology - Quantitative Methods},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/2ZYR3FU5/1810.html:text/html;Variational Bayesian Monte Carlo - Acerbi - 2018.pdf:/home/theo/Zotero/storage/IS5IHWJV/Variational Bayesian Monte Carlo - Acerbi - 2018.pdf:application/pdf},
}

@article{karvonenFullySymmetricKernel2018,
	title = {Fully symmetric kernel quadrature},
	url = {http://arxiv.org/abs/1703.06359},
	abstract = {Kernel quadratures and other kernel-based approximation methods typically suffer from prohibitive cubic time and quadratic space complexity in the number of function evaluations. The problem arises because a system of linear equations needs to be solved. In this article we show that the weights of a kernel quadrature rule can be computed efficiently and exactly for up to tens of millions of nodes if the kernel, integration domain, and measure are fully symmetric and the node set is a union of fully symmetric sets. This is based on the observations that in such a setting there are only as many distinct weights as there are fully symmetric sets and that these weights can be solved from a linear system of equations constructed out of row sums of certain submatrices of the full kernel matrix. We present several numerical examples that show feasibility, both for a large number of nodes and in high dimensions, of the developed fully symmetric kernel quadrature rules. Most prominent of the fully symmetric kernel quadrature rules we propose are those that use sparse grids.},
	urldate = {2020-05-18},
	journal = {arXiv:1703.06359 [cs, math, stat]},
	author = {Karvonen, Toni and Särkkä, Simo},
	month = jan,
	year = {2018},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1703.06359},
	keywords = {Statistics - Computation, Mathematics - Numerical Analysis},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/LA2FVL2W/1703.html:text/html;Fully symmetric kernel quadrature - Karvonen_Särkkä - 2018.pdf:/home/theo/Zotero/storage/YJML2QI3/Fully symmetric kernel quadrature - Karvonen_Särkkä - 2018.pdf:application/pdf},
}

@article{karvonenPositivityMagnitudesBayesian2019,
	title = {On the positivity and magnitudes of {Bayesian} quadrature weights},
	url = {http://arxiv.org/abs/1812.08509},
	abstract = {This article reviews and studies the properties of Bayesian quadrature weights, which strongly affect stability and robustness of the quadrature rule. Specifically, we investigate conditions that are needed to guarantee that the weights are positive or to bound their magnitudes. First, it is shown that the weights are positive in the univariate case if the design points locally minimise the posterior integral variance and the covariance kernel is totally positive (e.g., Gaussian and Hardy kernels). This suggests that gradient-based optimisation of design points may be effective in constructing stable and robust Bayesian quadrature rules. Secondly, we show that magnitudes of the weights admit an upper bound in terms of the fill distance and separation radius if the RKHS of the kernel is a Sobolev space (e.g., Mat{\textbackslash}'ern kernels), suggesting that quasi-uniform points should be used. A number of numerical examples demonstrate that significant generalisations and improvements appear to be possible, manifesting the need for further research.},
	urldate = {2020-05-18},
	journal = {arXiv:1812.08509 [cs, math, stat]},
	author = {Karvonen, Toni and Kanagawa, Motonobu and Särkkä, Simo},
	month = aug,
	year = {2019},
	note = {ZSCC: 0000001 
arXiv: 1812.08509},
	keywords = {Mathematics - Numerical Analysis, Mathematics - Statistics Theory},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/VJASVMAY/1812.html:text/html;On the positivity and magnitudes of Bayesian quadrature weights - Karvonen et al - 2019.pdf:/home/theo/Zotero/storage/XB2C6GIQ/On the positivity and magnitudes of Bayesian quadrature weights - Karvonen et al - 2019.pdf:application/pdf},
}

@article{fukumizuKernelBayesRule,
	title = {Kernel {Bayes}’ {Rule}: {Bayesian} {Inference} with {Positive} {Deﬁnite} {Kernels}},
	abstract = {A kernel method for realizing Bayes’ rule is proposed, based on representations of probabilities in reproducing kernel Hilbert spaces. Probabilities are uniquely characterized by the mean of the canonical map to the RKHS. The prior and conditional probabilities are expressed in terms of RKHS functions of an empirical sample: no explicit parametric model is needed for these quantities. The posterior is likewise an RKHS mean of a weighted sample. The estimator for the expectation of a function of the posterior is derived, and rates of consistency are shown. Some representative applications of the kernel Bayes’ rule are presented, including Bayesian computation without likelihood and ﬁltering with a nonparametric state-space model.},
	language = {en},
	author = {Fukumizu, Kenji and Jp, Ism Ac},
	note = {ZSCC: NoCitationData[s2]},
	pages = {31},
	file = {Kernel Bayes’ Rule - Fukumizu_Jp -.pdf:/home/theo/Zotero/storage/2UCP76CS/Kernel Bayes’ Rule - Fukumizu_Jp -.pdf:application/pdf},
}

@article{flaxmanFastKroneckerInference2015,
	title = {Fast {Kronecker} {Inference} in {Gaussian} {Processes} with non-{Gaussian} {Likelihoods}},
	volume = {37},
	abstract = {Gaussian processes (GPs) are a flexible class of methods with state of the art performance on spatial statistics applications. However, GPs re-quire O(n 3) computations and O(n 2) storage, and popular GP kernels are typically limited to smoothing and interpolation. To address these difficulties, Kronecker methods have been used to exploit structure in the GP covariance ma-trix for scalability, while allowing for expres-sive kernel learning (Wilson et al., 2014). How-ever, fast Kronecker methods have been confined to Gaussian likelihoods. We propose new scal-able Kronecker methods for Gaussian processes with non-Gaussian likelihoods, using a Laplace approximation which involves linear conjugate gradients for inference, and a lower bound on the GP marginal likelihood for kernel learning. Our approach has near linear scaling, requir-ing O(Dn D+1 D) operations and O(Dn 2 D) stor-age, for n training data-points on a dense D {\textgreater} 1 dimensional grid. Moreover, we introduce a log Gaussian Cox process, with highly expres-sive kernels, for modelling spatiotemporal count processes, and apply it to a point pattern (n = 233,088) of a decade of crime events in Chicago. Using our model, we discover spatially varying multiscale seasonal trends and produce highly accurate long-range local area forecasts.},
	number = {1978},
	journal = {Proceedings of The 32nd International Conference on Machine Learning},
	author = {Flaxman, Seth and Wilson, Andrew Gordon and Neill, Daniel B and Org, Alex Smola},
	year = {2015},
	note = {ZSCC: NoCitationData[s0] 
ISBN: 9781510810587},
	pages = {607--616},
	file = {Fast Kronecker Inference in Gaussian Processes with non-Gaussian Likelihoods - Flaxman et al - 2015.pdf:/home/theo/Zotero/storage/PCWVVBFM/Fast Kronecker Inference in Gaussian Processes with non-Gaussian Likelihoods - Flaxman et al - 2015.pdf:application/pdf},
}

@article{nemethStochasticGradientMarkov2019,
	title = {Stochastic gradient {Markov} chain {Monte} {Carlo}},
	url = {http://arxiv.org/abs/1907.06986},
	abstract = {Markov chain Monte Carlo (MCMC) algorithms are generally regarded as the gold standard technique for Bayesian inference. They are theoretically well-understood and conceptually simple to apply in practice. The drawback of MCMC is that in general performing exact inference requires all of the data to be processed at each iteration of the algorithm. For large data sets, the computational cost of MCMC can be prohibitive, which has led to recent developments in scalable Monte Carlo algorithms that have a significantly lower computational cost than standard MCMC. In this paper, we focus on a particular class of scalable Monte Carlo algorithms, stochastic gradient Markov chain Monte Carlo (SGMCMC) which utilises data subsampling techniques to reduce the per-iteration cost of MCMC. We provide an introduction to some popular SGMCMC algorithms and review the supporting theoretical results, as well as comparing the efficiency of SGMCMC algorithms against MCMC on benchmark examples. The supporting R code is available online.},
	urldate = {2020-05-18},
	journal = {arXiv:1907.06986 [stat]},
	author = {Nemeth, Christopher and Fearnhead, Paul},
	month = jul,
	year = {2019},
	note = {ZSCC: 0000002 
arXiv: 1907.06986},
	keywords = {Statistics - Machine Learning, Statistics - Computation},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/P4IXGVZS/1907.html:text/html;Stochastic gradient Markov chain Monte Carlo - Nemeth_Fearnhead - 2019.pdf:/home/theo/Zotero/storage/PN3B54QV/Stochastic gradient Markov chain Monte Carlo - Nemeth_Fearnhead - 2019.pdf:application/pdf},
}

@article{liuSteinVariationalGradient2017,
	title = {Stein {Variational} {Gradient} {Descent} as {Gradient} {Flow}},
	url = {http://arxiv.org/abs/1704.07520},
	abstract = {Stein variational gradient descent (SVGD) is a deterministic sampling algorithm that iteratively transports a set of particles to approximate given distributions, based on an efficient gradient-based update that guarantees to optimally decrease the KL divergence within a function space. This paper develops the first theoretical analysis on SVGD, discussing its weak convergence properties and showing that its asymptotic behavior is captured by a gradient flow of the KL divergence functional under a new metric structure induced by Stein operator. We also provide a number of results on Stein operator and Stein's identity using the notion of weak derivative, including a new proof of the distinguishability of Stein discrepancy under weak conditions.},
	urldate = {2020-05-15},
	journal = {arXiv:1704.07520 [stat]},
	author = {Liu, Qiang},
	month = nov,
	year = {2017},
	note = {ZSCC: 0000070 
arXiv: 1704.07520},
	keywords = {Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/GNI6ACXY/1704.html:text/html;Stein Variational Gradient Descent as Gradient Flow - Liu - 2017.pdf:/home/theo/Zotero/storage/VCFIFGR3/Stein Variational Gradient Descent as Gradient Flow - Liu - 2017.pdf:application/pdf},
}

@article{peyreCourseNotesOptimization,
	title = {Course notes on {Optimization} for {Machine} {Learning}},
	abstract = {This document presents ﬁrst order optimization methods and their applications to machine learning. This is not a course on machine learning (in particular it does not cover modeling and statistical considerations) and it is focussed on the use and analysis of cheap methods that can scale to large datasets and models with lots of parameters. These methods are variations around the notion of “gradient descent”, so that the computation of gradients plays a major role. This course covers basic theoretical properties of optimization problems (in particular convex analysis and ﬁrst order diﬀerential calculus), the gradient descent method, the stochastic gradient method, automatic diﬀerentiation, shallow and deep networks.},
	language = {en},
	author = {Peyre, Gabriel},
	note = {ZSCC: NoCitationData[s0]},
	keywords = {optimization, ad},
	pages = {38},
	file = {Course notes on Optimization for Machine Learning - Peyre -.pdf:/home/theo/Zotero/storage/Q5T5E5DU/Course notes on Optimization for Machine Learning - Peyre -.pdf:application/pdf},
}

@article{donner2018efficient,
	title = {Efficient {Bayesian} inference of sigmoidal {Gaussian} {Cox} processes},
	volume = {19},
	number = {1},
	journal = {The Journal of Machine Learning Research},
	author = {Donner, Christian and Opper, Manfred},
	year = {2018},
	note = {ZSCC: 0000006 
Publisher: JMLR. org},
	pages = {2710--2743},
}

@article{bruinsmaScalableExactInference2019,
	title = {Scalable {Exact} {Inference} in {Multi}-{Output} {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/1911.06287},
	abstract = {Multi-output Gaussian processes (MOGPs) leverage the flexibility and interpretability of GPs while capturing structure across outputs, which is desirable, for example, in spatio-temporal modelling. The key problem with MOGPs is the cubic computational scaling in the number of both inputs (e.g., time points or locations), n, and outputs, p. Current methods reduce this to O(n{\textasciicircum}3 m{\textasciicircum}3), where m {\textless} p is the desired degrees of freedom. This computational cost, however, is still prohibitive in many applications. To address this limitation, we present the Orthogonal Linear Mixing Model (OLMM), an MOGP in which exact inference scales linearly in m: O(n{\textasciicircum}3 m). This advance opens up a wide range of real-world tasks and can be combined with existing GP approximations in a plug-and-play way as demonstrated in the paper. Additionally, the paper organises the existing disparate literature on MOGP models into a simple taxonomy called the Mixing Model Hierarchy (MMH).},
	author = {Bruinsma, Wessel P. and Perim, Eric and Tebbutt, Will and Hosking, J. Scott and Solin, Arno and Turner, Richard E.},
	year = {2019},
	note = {ZSCC: 0000000 
arXiv: 1911.06287},
	file = {Scalable Exact Inference in Multi-Output Gaussian Processes - Bruinsma et al - 2019.pdf:/home/theo/Zotero/storage/F2WF44T2/Scalable Exact Inference in Multi-Output Gaussian Processes - Bruinsma et al - 2019.pdf:application/pdf},
}

@article{hoffmanAutoConjRecognizingExploiting2018,
	title = {{AutoConj}: {Recognizing} and exploiting conjugacy without a domain-specific language},
	volume = {2018-Decem},
	issn = {10495258},
	abstract = {Deriving conditional and marginal distributions using conjugacy relationships can be time consuming and error prone. In this paper, we propose a strategy for automating such derivations. Unlike previous systems which focus on relationships between pairs of random variables, our system (which we call Autoconj) operates directly on Python functions that compute log-joint distribution functions. Autoconj provides support for conjugacy-exploiting algorithms in any Python-embedded PPL. This paves the way for accelerating development of novel inference algorithms and structure-exploiting modeling strategies.1},
	number = {NeurIPS},
	journal = {Advances in Neural Information Processing Systems},
	author = {Hoffman, Matthew D. and Johnson, Matthew J. and Tran, Dustin},
	year = {2018},
	note = {ZSCC: 0000006 
arXiv: 1811.11926},
	pages = {10716--10726},
}

@article{moreno-munozHeterogeneousMultioutputGaussian2018,
	title = {Heterogeneous {Multi}-output {Gaussian} {Process} {Prediction}},
	volume = {2018-Decem},
	issn = {10495258},
	abstract = {We present a novel extension of multi-output Gaussian processes for handling heterogeneous outputs. We assume that each output has its own likelihood function and use a vector-valued Gaussian process prior to jointly model the parameters in all likelihoods as latent functions. Our multi-output Gaussian process uses a covariance function with a linear model of coregionalisation form. Assuming conditional independence across the underlying latent functions together with an inducing variable framework, we are able to obtain tractable variational bounds amenable to stochastic variational inference. We illustrate the performance of the model on synthetic data and two real datasets: a human behavioral study and a demographic high-dimensional dataset.},
	number = {NeurIPS},
	journal = {Advances in Neural Information Processing Systems},
	author = {Moreno-Muñoz, Pablo and Artés-Rodríguez, Antonio and Álvarez, Mauricio A.},
	year = {2018},
	note = {ZSCC: 0000000 
arXiv: 1805.07633},
	pages = {6711--6720},
	file = {Heterogeneous Multi-output Gaussian Process Prediction - Moreno-Muñoz et al - 2018.pdf:/home/theo/Zotero/storage/PMFRD55A/Heterogeneous Multi-output Gaussian Process Prediction - Moreno-Muñoz et al - 2018.pdf:application/pdf},
}

@article{turnerGaussianProcessesState2011,
	title = {Gaussian {Processes} for {State} {Space} {Models} and {Change} {Point} {Detection}},
	abstract = {This thesis details several applications of Gaussian processes (GPs) for enhanced time series modeling. We first cover different approaches for using Gaussian processes in time series problems. These are extended to the state space approach to time series in two different problems. We also combine Gaussian processes and Bayesian online change point detection (BOCPD) to increase the generality of the Gaussian process time series methods. These methodologies are evaluated on predictive performance on six real world data sets, which include three environ- mental data sets, one financial, one biological, and one from industrial well drilling. Gaussian processes are capable of generalizing standard linear time series models. We cover two approaches: the Gaussian process time se- ries model (GPTS) and the autoregressive Gaussian process (ARGP). We cover a variety of methods that greatly reduce the computational and memory complexity of Gaussian process approaches, which are generally cubic in computational complexity. Two different improvements to state space based approaches are covered. First, Gaussian process inference and learning (GPIL) generalizes linear dynamical systems (LDS), for which the Kalman filter is based, to general nonlinear systems for nonparametric system identification. Second, we address pathologies in the unscented Kalman filter (UKF). We use Gaussian process optimization (GPO) to learn UKF settings that minimize the potential for sigma point collapse. We show how to embed mentioned Gaussian process approaches to time series into a change point framework. Old data, from an old regime, that hinders predictive performance is automatically and el- egantly phased out. The computational improvements for Gaussian process time series approaches are of even greater use in the change point framework. We also present a supervised framework learning a change point model when change point labels are available in training. These mentioned methodologies significantly improve predictive per- formance on the diverse set of data sets selected.},
	journal = {Learning},
	author = {Turner, Ryan Darby},
	year = {2011},
	note = {ZSCC: NoCitationData[s0]},
	file = {Gaussian Processes for State Space Models and Change Point Detection - Turner - 2011.pdf:/home/theo/Zotero/storage/EEQBHS2X/Gaussian Processes for State Space Models and Change Point Detection - Turner - 2011.pdf:application/pdf},
}

@article{alvarezComputationallyEfficientConvolved2011,
	title = {Computationally efficient convolved multiple output gaussian processes},
	volume = {12},
	issn = {15324435},
	abstract = {Recently there has been an increasing interest in regression methods that deal with multiple outputs. This has been motivated partly by frameworks like multitask learning, multisensor networks or structured output data. From a Gaussian processes perspective, the problem reduces to specifying an appropriate covariance function that, whilst being positive semi-definite, captures the dependencies between all the data points and across all the outputs. One approach to account for non-trivial correlations between outputs employs convolution processes. Under a latent function interpretation of the convolution transform we establish dependencies between output variables. The main drawbacks of this approach are the associated computational and storage demands. In this paper we address these issues. We present different efficient approximations for dependent output Gaussian processes constructed through the convolution formalism. We exploit the conditional independencies present naturally in the model. This leads to a form of the covariance similar in spirit to the so called PITC and FITC approximations for a single output. We show experimental results with synthetic and real data, in particular, we show results in school exams score prediction, pollution prediction and gene expression data. © 2011 Mauricio A. Álvarez and Neil D. Lawrence.},
	journal = {Journal of Machine Learning Research},
	author = {Álvarez, Mauricio A. and Lawrence, Neil D.},
	year = {2011},
	note = {ZSCC: 0000211},
	keywords = {Gaussian processes, Convolution processes, Efficient approximations, Multitask learning, Multivariate processes, Structured outputs},
	pages = {1459--1500},
	file = {Computationally efficient convolved multiple output gaussian processes - Álvarez_Lawrence - 2011.pdf:/home/theo/Zotero/storage/FJR35KLX/Computationally efficient convolved multiple output gaussian processes - Álvarez_Lawrence - 2011.pdf:application/pdf},
}

@article{moreno-munozContinualMultitaskGaussian2019,
	title = {Continual {Multi}-task {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/1911.00002},
	abstract = {We address the problem of continual learning in multi-task Gaussian process (GP) models for handling sequential input-output observations. Our approach extends the existing prior-posterior recursion of online Bayesian inference, i.e.{\textbackslash} past posterior discoveries become future prior beliefs, to the infinite functional space setting of GP. For a reason of scalability, we introduce variational inference together with an sparse approximation based on inducing inputs. As a consequence, we obtain tractable continual lower-bounds where two novel Kullback-Leibler (KL) divergences intervene in a natural way. The key technical property of our method is the recursive reconstruction of conditional GP priors conditioned on the variational parameters learned so far. To achieve this goal, we introduce a novel factorization of past variational distributions, where the predictive GP equation propagates the posterior uncertainty forward. We then demonstrate that it is possible to derive GP models over many types of sequential observations, either discrete or continuous and amenable to stochastic optimization. The continual inference approach is also applicable to scenarios where potential multi-channel or heterogeneous observations might appear. Extensive experiments demonstrate that the method is fully scalable, shows a reliable performance and is robust to uncertainty error propagation over a plenty of synthetic and real-world datasets.},
	author = {Moreno-Muñoz, Pablo and Artés-Rodríguez, Antonio and Álvarez, Mauricio A.},
	year = {2019},
	note = {ZSCC: 0000000 
arXiv: 1911.00002},
	file = {Continual Multi-task Gaussian Processes - Moreno-Muñoz et al - 2019.pdf:/home/theo/Zotero/storage/FXKVW2MD/Continual Multi-task Gaussian Processes - Moreno-Muñoz et al - 2019.pdf:application/pdf},
}

@article{alvarezKernelsVectorvaluedFunctions2011,
	title = {Kernels for vector-valued functions: {A} review},
	volume = {4},
	issn = {19358237},
	doi = {10.1561/2200000036},
	abstract = {Kernel methods are among the most popular techniques in machine learning. From a regularization perspective they play a central role in regularization theory as they provide a natural choice for the hypotheses space and the regularization functional through the notion of reproducing kernel Hilbert spaces. From a probabilistic perspective they are the key in the context of Gaussian processes, where the kernel function is known as the covariance function. Traditionally, kernel methods have been used in supervised learning problems with scalar outputs and indeed there has been a considerable amount of work devoted to designing and learning kernels. More recently there has been an increasing interest in methods that deal with multiple outputs, motivated partially by frameworks like multitask learning. In this monograph, we review different methods to design or learn valid kernel functions for multiple outputs, paying particular attention to the connection between probabilistic and functional methods. © 2012 M. A. Álvarez, L. Rosasco and N. D. Lawrence.},
	number = {3},
	journal = {Foundations and Trends in Machine Learning},
	author = {Álvarez, Mauricio A. and Rosasco, Lorenzo and Lawrence, Neil D.},
	year = {2011},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1106.6251},
	pages = {195--266},
	file = {Kernels for vector-valued functions - Álvarez et al - 2011.pdf:/home/theo/Zotero/storage/SC5KVXFK/Kernels for vector-valued functions - Álvarez et al - 2011.pdf:application/pdf},
}

@article{wierstraNaturalEvolutionStrategies2008,
	title = {Natural {Evolution} {Strategies}},
	volume = {15},
	doi = {10.1109/CEC.2008.4631255},
	abstract = {This paper presents Natural Evolution Strategies (NES), a novel algorithm for performing real-valued 'black box' function optimization: optimizing an unknown objective function where algorithm-selected function measurements constitute the only information accessible to the method. Natural Evolution Strategies search the fitness landscape using a multivariate normal distribution with a self-adapting mutation matrix to generate correlated mutations in promising regions. NES shares this property with Covariance Matrix Adaption (CMA), an Evolution Strategy (ES) which has been shown to perform well on a variety of high-precision optimization tasks. The Natural Evolution Strategies algorithm, however, is simpler, less ad-hoc and more principled. Self-adaptation of the mutation matrix is derived using a Monte Carlo estimate of the natural gradient towards better expected fitness. By following the natural gradient instead of the 'vanilla' gradient, we can ensure efficient update steps while preventing early convergence due to overly greedy updates, resulting in reduced sensitivity to local suboptima. We show NES has competitive performance with CMA on unimodal tasks, while outperforming it on several multimodal tasks that are rich in deceptive local optima. © 2008 IEEE.},
	journal = {2008 IEEE Congress on Evolutionary Computation, CEC 2008},
	author = {Wierstra, Daan and Schaul, Tom and Peters, Jan and Schmidhuber, Juergen},
	year = {2008},
	note = {ZSCC: 0000232 
ISBN: 9781424418237},
	pages = {3381--3387},
	file = {Natural Evolution Strategies - Wierstra et al - 2008.pdf:/home/theo/Zotero/storage/8ATRRM4S/Natural Evolution Strategies - Wierstra et al - 2008.pdf:application/pdf},
}

@article{wangVariationalInferenceNonconjugate2012,
	title = {Variational {Inference} in {Nonconjugate} {Models}},
	volume = {14},
	issn = {1532-4435},
	url = {http://arxiv.org/abs/1209.4360},
	abstract = {Mean-field variational methods are widely used for approximate posterior inference in many probabilistic models. In a typical application, mean-field methods approximately compute the posterior with a coordinate-ascent optimization algorithm. When the model is conditionally conjugate, the coordinate updates are easily derived and in closed form. However, many models of interest---like the correlated topic model and Bayesian logistic regression---are nonconjuate. In these models, mean-field methods cannot be directly applied and practitioners have had to develop variational algorithms on a case-by-case basis. In this paper, we develop two generic methods for nonconjugate models, Laplace variational inference and delta method variational inference. Our methods have several advantages: they allow for easily derived variational algorithms with a wide class of nonconjugate models; they extend and unify some of the existing algorithms that have been derived for specific models; and they work well on real-world datasets. We studied our methods on the correlated topic model, Bayesian logistic regression, and hierarchical Bayesian logistic regression.},
	journal = {Journal of Machine Learning Research},
	author = {Wang, Chong and Blei, David M.},
	year = {2012},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1209.4360
ISBN: 1532-4435},
	keywords = {variational inference, Laplace approximations, nonconjugate models, the multivariate delta method},
	pages = {1005--1031},
	file = {Variational Inference in Nonconjugate Models - Wang_Blei - 2012.pdf:/home/theo/Zotero/storage/PW9WVANU/Variational Inference in Nonconjugate Models - Wang_Blei - 2012.pdf:application/pdf},
}

@article{arbelKernelizedWassersteinNatural2019,
	title = {Kernelized {Wasserstein} {Natural} {Gradient}},
	url = {http://arxiv.org/abs/1910.09652},
	abstract = {Many machine learning problems can be expressed as the optimization of some cost functional over a parametric family of probability distributions. It is often beneficial to solve such optimization problems using natural gradient methods. These methods are invariant to the parametrization of the family, and thus can yield more effective optimization. Unfortunately, computing the natural gradient is challenging as it requires inverting a high dimensional matrix at each iteration. We propose a general framework to approximate the natural gradient for the Wasserstein metric, by leveraging a dual formulation of the metric restricted to a Reproducing Kernel Hilbert Space. Our approach leads to an estimator for gradient direction that can trade-off accuracy and computational cost, with theoretical guarantees. We verify its accuracy on simple examples, and show the advantage of using such an estimator in classification tasks on Cifar10 and Cifar100 empirically.},
	author = {Arbel, Michael and Gretton, Arthur and Li, Wuchen and Montufar, Guido},
	year = {2019},
	note = {ZSCC: 0000001 
arXiv: 1910.09652},
	pages = {1--31},
	file = {Kernelized Wasserstein Natural Gradient - Arbel et al - 2019.pdf:/home/theo/Zotero/storage/75Z6TH8D/Kernelized Wasserstein Natural Gradient - Arbel et al - 2019.pdf:application/pdf},
}

@article{karvonenClassicalQuadratureRules2017,
	title = {Classical {Quadrature} {Rules} {Via} {Gaussian} {Processes}},
	author = {Karvonen, Toni and Särkkä, Simo},
	year = {2017},
	note = {ZSCC: 0000014 
ISBN: 9781509063413},
	file = {Classical Quadrature Rules Via Gaussian Processes - Karvonen_Särkkä - 2017.pdf:/home/theo/Zotero/storage/GUCBAMJ4/Classical Quadrature Rules Via Gaussian Processes - Karvonen_Särkkä - 2017.pdf:application/pdf},
}

@article{millerGeneratingFunctionsConvolutions2019,
	title = {Generating {Functions} and {Convolutions}},
	volume = {1},
	doi = {10.2307/j.ctvc7767n.23},
	journal = {The Probability Lifesaver},
	author = {MILLER, STEVEN J.},
	year = {2019},
	note = {ZSCC: NoCitationData[s0]},
	pages = {494--526},
}

@article{karvonenGaussianKernelQuadrature2019,
	title = {Gaussian kernel quadrature at scaled {Gauss}–{Hermite} nodes},
	volume = {59},
	issn = {15729125},
	doi = {10.1007/s10543-019-00758-3},
	abstract = {This article derives an accurate, explicit, and numerically stable approximation to the kernel quadrature weights in one dimension and on tensor product grids when the kernel and integration measure are Gaussian. The approximation is based on use of scaled Gauss–Hermite nodes and truncation of the Mercer eigendecomposition of the Gaussian kernel. Numerical evidence indicates that both the kernel quadrature and the approximate weights at these nodes are positive. An exponential rate of convergence for functions in the reproducing kernel Hilbert space induced by the Gaussian kernel is proved under an assumption on growth of the sum of absolute values of the approximate weights.},
	number = {4},
	journal = {BIT Numerical Mathematics},
	author = {Karvonen, Toni and Särkkä, Simo},
	year = {2019},
	note = {ZSCC: 0000005 
arXiv: 1803.09532},
	keywords = {Gaussian quadrature, Kernel quadrature, Mercer eigendecomposition, Numerical integration},
	pages = {877--902},
	file = {Gaussian kernel quadrature at scaled Gauss–Hermite nodes - Karvonen_Särkkä - 2019.pdf:/home/theo/Zotero/storage/7554WES5/Gaussian kernel quadrature at scaled Gauss–Hermite nodes - Karvonen_Särkkä - 2019.pdf:application/pdf},
}

@article{keisterMultidimensionalQuadratureAlgorithms1996,
	title = {Multidimensional quadrature algorithms},
	volume = {10},
	issn = {08941866},
	doi = {10.1063/1.168565},
	abstract = {This paper provides an overview of some basic concepts behind multidimensional quadrature algorithm. They are illustrated with two selected algorithms, together with some specific examples. For certain application this algorithm provides a powerful alternative to costly product rules and slowly convergent Monte-Carlo methods. These rules are based upon intergrands that can be approximated as a series of low-order polynomials.},
	number = {2},
	journal = {Computers in physics},
	author = {Keister, Bradley D.},
	year = {1996},
	note = {ZSCC: 0000036},
	pages = {119--122},
	file = {Multidimensional quadrature algorithms - Keister - 1996.pdf:/home/theo/Zotero/storage/R4SMKCC4/Multidimensional quadrature algorithms - Keister - 1996.pdf:application/pdf},
}

@article{Polson2011,
	title = {Data augmentation for support vector machines},
	volume = {6},
	issn = {19360975},
	doi = {10.1214/11-BA601},
	abstract = {This paper presents a latent variable representation of regularized support vector machines (SVM's) that enables EM, ECME or MCMC algorithms to provide parameter estimates. We verify our representation by demonstrating that minimizing the SVM optimality criterion together with the parameter regularization penalty is equivalent to finding the mode of a mean-variance mixture of normals pseudo-posterior distribution. The latent variables in the mixture representation lead to EM and ECME point estimates of SVM parameters, as well as MCMC algorithms based on Gibbs sampling that can bring Bayesian tools for Gaussian linear models to bear on SVM's. We show how to implement SVM's with spike-and-slab priors and run them against data from a standard spam filtering data set.},
	number = {1},
	journal = {Bayesian Analysis},
	author = {Polson, Nicholas G. and Scott, Steven L.},
	year = {2011},
	note = {ZSCC: 0000144 },
	keywords = {Bayesian inference, ECME, EM, Lasso, Lα-norm, MCMC, Regularization},
	pages = {1--24},
	file = {PDF:/home/theo/Zotero/storage/YX7EJ73Y/Polson, Scott - 2011 - Data augmentation for support vector machines(2).pdf:application/pdf},
}

@article{ribeiroExpectationPropagationFactorizing2011,
	title = {Expectation propagation with factorizing distributions: {A} gaussian approximation and performance results for simple models},
	volume = {23},
	issn = {08997667},
	url = {http://arxiv.org/abs/1602.04133},
	doi = {10.1162/NECO_a_00104},
	abstract = {We discuss the expectation propagation (EP) algorithm for approximate Bayesian inference using a factorizing posterior approximation. For neural network models, we use a central limit theorem argument to make EP tractable when the number of parameters is large. For two types of models, we show that EP can achieve optimal generalization performance when data are drawn from a simple distribution.},
	number = {4},
	journal = {Neural Computation},
	author = {Ribeiro, Fabiano and Opper, Manfred},
	year = {2011},
	pmid = {21222527},
	note = {ZSCC: 0000014 
arXiv: 1602.04133
ISBN: 978-0-387-30768-8, 978-0-387-30164-8},
	pages = {1047--1069},
	file = {Expectation propagation with factorizing distributions - Ribeiro_Opper - 2011.pdf:/home/theo/Zotero/storage/QEJYJ2SW/Expectation propagation with factorizing distributions - Ribeiro_Opper - 2011.pdf:application/pdf;Expectation propagation with factorizing distributions - Ribeiro_Opper - 2011.pdf:/home/theo/Zotero/storage/7TASQBFT/Expectation propagation with factorizing distributions - Ribeiro_Opper - 2011.pdf:application/pdf},
}

@article{requeimaGaussianProcessAutoregressive2019,
	title = {The {Gaussian} {Process} {Autoregressive} {Regression} {Model} ({GPAR})},
	url = {http://arxiv.org/abs/1802.07182},
	abstract = {Multi-output regression models must exploit dependencies between outputs to maximise predictive performance. The application of Gaussian processes (GPs) to this setting typically yields models that are computationally demanding and have limited representational power. We present the Gaussian Process Autoregressive Regression (GPAR) model, a scalable multi-output GP model that is able to capture nonlinear, possibly input-varying, dependencies between outputs in a simple and tractable way: the product rule is used to decompose the joint distribution over the outputs into a set of conditionals, each of which is modelled by a standard GP. GPAR’s eﬃcacy is demonstrated on a variety of synthetic and real-world problems, outperforming existing GP models and achieving state-of-the-art performance on established benchmarks.},
	language = {en},
	urldate = {2020-03-20},
	journal = {arXiv:1802.07182 [stat]},
	author = {Requeima, James and Tebbutt, Will and Bruinsma, Wessel and Turner, Richard E.},
	month = feb,
	year = {2019},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1802.07182},
	keywords = {Statistics - Machine Learning},
	file = {PDF:/home/theo/Zotero/storage/T535RQE2/Requeima et al. - 2018 - The Gaussian Process Autoregressive Regression Model (GPAR).pdf:application/pdf},
}

@article{blei2017variational,
	title = {Variational inference: {A} review for statisticians},
	volume = {112},
	number = {518},
	journal = {Journal of the American Statistical Association},
	author = {Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
	year = {2017},
	note = {ZSCC: 0001235 
Publisher: Taylor \& Francis},
	pages = {859--877},
}

@article{galy2019multi,
	title = {Multi-{Class} {Gaussian} {Process} {Classification} {Made} {Conjugate}: {Efficient} {Inference} via {Data} {Augmentation}},
	journal = {Uncertainty in Artificial Intelligence (\{UAI\})},
	author = {Galy-Fajou, Théo and Wenzel, Florian and Donner, Christian and Opper, Manfred},
	year = {2019},
	note = {ZSCC: 0000003 },
}

@book{widder1946laplace,
	title = {The {Laplace} transform},
	publisher = {Princeton university press},
	author = {Widder, David Vernon},
	year = {1946},
	note = {ZSCC: 0000012 },
}

@inproceedings{wenzel2019efficient,
	title = {Efficient {Gaussian} process classification using \{{P}\}òlya-{Gamma} data augmentation},
	volume = {33},
	copyright = {All rights reserved},
	booktitle = {Proceedings of the {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Wenzel, Florian and Galy-Fajou, Théo and Donner, Christan and Kloft, Marius and Opper, Manfred},
	year = {2019},
	note = {ZSCC: NoCitationData[s0] },
	pages = {5417--5424},
}

@article{gneiting1999radial,
	title = {Radial positive definite functions generated by {Euclid}'s hat},
	volume = {69},
	number = {1},
	journal = {Journal of Multivariate Analysis},
	author = {Gneiting, Tilmann},
	year = {1999},
	note = {ZSCC: 0000081 
Publisher: Elsevier},
	pages = {88--119},
}

@book{rasmussen2003gaussian,
	title = {Gaussian processes in machine learning},
	publisher = {Springer},
	author = {Rasmussen, Carl Edward},
	year = {2003},
	note = {ZSCC: 0017519 },
}

@article{matthews2017gpflow,
	title = {{GPflow}: {A} {Gaussian} process library using {TensorFlow}},
	volume = {18},
	number = {1},
	journal = {The Journal of Machine Learning Research},
	author = {Matthews, De G and Alexander, G and Van Der Wilk, Mark and Nickson, Tom and Fujii, Keisuke and Boukouvalas, Alexis and León-Villagrá, Pablo and Ghahramani, Zoubin and Hensman, James},
	year = {2017},
	note = {ZSCC: 0000164 
Publisher: JMLR},
	pages = {1299--1304},
}

@article{bernsteinFonctionsAbsolumentMonotones1929,
	title = {Sur les fonctions absolument monotones},
	volume = {52},
	issn = {0001-5962, 1871-2509},
	url = {https://projecteuclid.org/journals/acta-mathematica/volume-52/issue-none/Sur-les-fonctions-absolument-monotones/10.1007/BF02592679.full},
	doi = {10.1007/BF02592679},
	abstract = {Acta Mathematica},
	number = {none},
	urldate = {2021-02-25},
	journal = {Acta Mathematica},
	author = {Bernstein, Serge},
	month = jan,
	year = {1929},
	note = {ZSCC: 0000524 
Publisher: Institut Mittag-Leffler},
	pages = {1--66},
	file = {Snapshot:/home/theo/Zotero/storage/5XWNCQZS/BF02592679.html:text/html;Sur les fonctions absolument monotones - Bernstein - 1929.pdf:/home/theo/Zotero/storage/GEIZPDFQ/Sur les fonctions absolument monotones - Bernstein - 1929.pdf:application/pdf},
}

@article{huangConvexPotentialFlows2020,
	title = {Convex {Potential} {Flows}: {Universal} {Probability} {Distributions} with {Optimal} {Transport} and {Convex} {Optimization}},
	shorttitle = {Convex {Potential} {Flows}},
	url = {http://arxiv.org/abs/2012.05942},
	abstract = {Flow-based models are powerful tools for designing probabilistic models with tractable density. This paper introduces Convex Potential Flows (CP-Flow), a natural and efficient parameterization of invertible models inspired by the optimal transport (OT) theory. CP-Flows are the gradient map of a strongly convex neural potential function. The convexity implies invertibility and allows us to resort to convex optimization to solve the convex conjugate for efficient inversion. To enable maximum likelihood training, we derive a new gradient estimator of the log-determinant of the Jacobian, which involves solving an inverse-Hessian vector product using the conjugate gradient method. The gradient estimator has constant-memory cost, and can be made effectively unbiased by reducing the error tolerance level of the convex optimization routine. Theoretically, we prove that CP-Flows are universal density approximators and are optimal in the OT sense. Our empirical results show that CP-Flow performs competitively on standard benchmarks of density estimation and variational inference.},
	urldate = {2021-02-24},
	journal = {arXiv:2012.05942 [cs, math]},
	author = {Huang, Chin-Wei and Chen, Ricky T. Q. and Tsirigotis, Christos and Courville, Aaron},
	month = dec,
	year = {2020},
	note = {ZSCC: 0000000 
arXiv: 2012.05942},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/XFE6HVZQ/2012.html:text/html;Convex Potential Flows - Huang et al - 2020.pdf:/home/theo/Zotero/storage/ESGFMSGT/Convex Potential Flows - Huang et al - 2020.pdf:application/pdf},
}

@article{wenzelEfficientGaussianProcess2018,
	title = {Efficient {Gaussian} {Process} {Classification} {Using} {Polya}-{Gamma} {Data} {Augmentation}},
	url = {http://arxiv.org/abs/1802.06383},
	abstract = {We propose a scalable stochastic variational approach to GP classification building on Polya-Gamma data augmentation and inducing points. Unlike former approaches, we obtain closed-form updates based on natural gradients that lead to efficient optimization. We evaluate the algorithm on real-world datasets containing up to 11 million data points and demonstrate that it is up to two orders of magnitude faster than the state-of-the-art while being competitive in terms of prediction performance.},
	urldate = {2021-02-24},
	journal = {arXiv:1802.06383 [cs, stat]},
	author = {Wenzel, Florian and Galy-Fajou, Theo and Donner, Christan and Kloft, Marius and Opper, Manfred},
	month = nov,
	year = {2018},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1802.06383},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/L9EG5XZ9/1802.html:text/html;Efficient Gaussian Process Classification Using Polya-Gamma Data Augmentation - Wenzel et al - 2018.pdf:/home/theo/Zotero/storage/8RUW2NAY/Efficient Gaussian Process Classification Using Polya-Gamma Data Augmentation - Wenzel et al - 2018.pdf:application/pdf},
}

@article{galy-fajouAutomatedAugmentedConjugate2020,
	title = {Automated {Augmented} {Conjugate} {Inference} for {Non}-conjugate {Gaussian} {Process} {Models}},
	copyright = {All rights reserved},
	url = {http://arxiv.org/abs/2002.11451},
	abstract = {We propose automated augmented conjugate inference, a new inference method for non-conjugate Gaussian processes (GP) models. Our method automatically constructs an auxiliary variable augmentation that renders the GP model conditionally conjugate. Building on the conjugate structure of the augmented model, we develop two inference methods. First, a fast and scalable stochastic variational inference method that uses efficient block coordinate ascent updates, which are computed in closed form. Second, an asymptotically correct Gibbs sampler that is useful for small datasets. Our experiments show that our method are up two orders of magnitude faster and more robust than existing state-of-the-art black-box methods.},
	urldate = {2021-02-23},
	journal = {arXiv:2002.11451 [cs, stat]},
	author = {Galy-Fajou, Théo and Wenzel, Florian and Opper, Manfred},
	month = feb,
	year = {2020},
	note = {ZSCC: 0000000 
arXiv: 2002.11451},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/93F5TT6V/2002.html:text/html;Automated Augmented Conjugate Inference for Non-conjugate Gaussian Process - Galy-Fajou et al - 2020.pdf:/home/theo/Zotero/storage/Q34MMUJR/Automated Augmented Conjugate Inference for Non-conjugate Gaussian Process - Galy-Fajou et al - 2020.pdf:application/pdf},
}

@article{buiUnifyingFrameworkGaussian2017,
	title = {A {Unifying} {Framework} for {Gaussian} {Process} {Pseudo}-{Point} {Approximations} using {Power} {Expectation} {Propagation}},
	url = {http://arxiv.org/abs/1605.07066},
	abstract = {Gaussian processes (GPs) are flexible distributions over functions that enable high-level assumptions about unknown functions to be encoded in a parsimonious, flexible and general way. Although elegant, the application of GPs is limited by computational and analytical intractabilities that arise when data are sufficiently numerous or when employing non-Gaussian models. Consequently, a wealth of GP approximation schemes have been developed over the last 15 years to address these key limitations. Many of these schemes employ a small set of pseudo data points to summarise the actual data. In this paper, we develop a new pseudo-point approximation framework using Power Expectation Propagation (Power EP) that unifies a large number of these pseudo-point approximations. Unlike much of the previous venerable work in this area, the new framework is built on standard methods for approximate inference (variational free-energy, EP and Power EP methods) rather than employing approximations to the probabilistic generative model itself. In this way, all of approximation is performed at `inference time' rather than at `modelling time' resolving awkward philosophical and empirical questions that trouble previous approaches. Crucially, we demonstrate that the new framework includes new pseudo-point approximation methods that outperform current approaches on regression and classification tasks.},
	urldate = {2021-02-18},
	journal = {arXiv:1605.07066 [cs, stat]},
	author = {Bui, Thang D. and Yan, Josiah and Turner, Richard E.},
	month = oct,
	year = {2017},
	note = {ZSCC: 0000072 
arXiv: 1605.07066},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/Z7FYI9FG/1605.html:text/html;A Unifying Framework for Gaussian Process Pseudo-Point Approximations using - Bui et al - 2017.pdf:/home/theo/Zotero/storage/EXAGWU7L/A Unifying Framework for Gaussian Process Pseudo-Point Approximations using - Bui et al - 2017.pdf:application/pdf},
}

@misc{160507066Unifying,
	title = {[1605.07066] {A} {Unifying} {Framework} for {Gaussian} {Process} {Pseudo}-{Point} {Approximations} using {Power} {Expectation} {Propagation}},
	url = {https://arxiv.org/abs/1605.07066},
	urldate = {2021-02-18},
}

@article{kucukelbirAutomaticDifferentiationVariational2016,
	title = {Automatic {Differentiation} {Variational} {Inference}},
	url = {http://arxiv.org/abs/1603.00788},
	abstract = {Probabilistic modeling is iterative. A scientist posits a simple model, ﬁts it to her data, reﬁnes it according to her analysis, and repeats. However, ﬁtting complex models to large data is a bottleneck in this process. Deriving algorithms for new models can be both mathematically and computationally challenging, which makes it difﬁcult to efﬁciently cycle through the steps. To this end, we develop automatic differentiation variational inference (ADVI). Using our method, the scientist only provides a probabilistic model and a dataset, nothing else. ADVI automatically derives an efﬁcient variational inference algorithm, freeing the scientist to reﬁne and explore many models. ADVI supports a broad class of models—no conjugacy assumptions are required. We study ADVI across ten different models and apply it to a dataset with millions of observations. ADVI is integrated into Stan, a probabilistic programming system; it is available for immediate use.},
	language = {en},
	urldate = {2021-02-17},
	journal = {arXiv:1603.00788 [cs, stat]},
	author = {Kucukelbir, Alp and Tran, Dustin and Ranganath, Rajesh and Gelman, Andrew and Blei, David M.},
	month = mar,
	year = {2016},
	note = {ZSCC: 0000079 
arXiv: 1603.00788},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Computation, Computer Science - Artificial Intelligence},
	file = {Automatic Differentiation Variational Inference - Kucukelbir et al - 2016.pdf:/home/theo/Zotero/storage/4TTY8D8X/Automatic Differentiation Variational Inference - Kucukelbir et al - 2016.pdf:application/pdf},
}

@article{rasmussenBayesianMonteCarlo2008,
	title = {Bayesian {Monte} {Carlo}},
	issn = {00835560},
	abstract = {We investigate Bayesian alternatives to classical Monte Carlo methods for evaluating integrals. Bayesian Monte Carlo (BMC) allows the in- corporation of prior knowledge, such as smoothness of the integrand, into the estimation. In a simple problem we show that this outperforms any classical importance sampling method. We also attempt more chal- lenging multidimensional integrals involved in computing marginal like- lihoods of statistical models (a.k.a. partition functions and model evi- dences). We find that Bayesian Monte Carlo outperformed Annealed Importance Sampling, although for very high dimensional problems or problems with massive multimodality BMC may be less adequate. One advantage of the Bayesian approach to Monte Carlo is that samples can be drawn from any distribution. This allows for the possibility of active design of sample points so as to maximise information gain.},
	number = {2031},
	journal = {VDI Berichte},
	author = {Rasmussen, Carl Edward and Ghahramani, Zoubin},
	year = {2008},
	note = {ZSCC: NoCitationData[s2] 
ISBN: 9783180920313},
	pages = {143--159},
	file = {Bayesian Monte Carlo - Rasmussen_Ghahramani - 2008.pdf:/home/theo/Zotero/storage/B6NLS4PE/Bayesian Monte Carlo - Rasmussen_Ghahramani - 2008.pdf:application/pdf},
}

@article{wangInformationNewtonFlow2020,
	title = {Information {Newton}'s flow: second-order optimization method in probability space},
	shorttitle = {Information {Newton}'s flow},
	url = {http://arxiv.org/abs/2001.04341},
	abstract = {We introduce a framework for Newton's flows in probability space with information metrics, named information Newton's flows. Here two information metrics are considered, including both the Fisher-Rao metric and the Wasserstein-2 metric. A known fact is that overdamped Langevin dynamics correspond to Wasserstein gradient flows of Kullback-Leibler (KL) divergence. Extending this fact to Wasserstein Newton's flows, we derive Newton's Langevin dynamics. We provide examples of Newton's Langevin dynamics in both one-dimensional space and Gaussian families. For the numerical implementation, we design sampling efficient variational methods in affine models and reproducing kernel Hilbert space (RKHS) to approximate Wasserstein Newton's directions. We also establish convergence results of the proposed information Newton's method with approximated directions. Several numerical examples from Bayesian sampling problems are shown to demonstrate the effectiveness of the proposed method.},
	urldate = {2021-02-08},
	journal = {arXiv:2001.04341 [cs, math, stat]},
	author = {Wang, Yifei and Li, Wuchen},
	month = aug,
	year = {2020},
	note = {ZSCC: 0000008 
arXiv: 2001.04341},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Mathematics - Optimization and Control},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/TR45F2G3/2001.html:text/html;Information Newton's flow - Wang_Li - 2020.pdf:/home/theo/Zotero/storage/ZAAEB2MP/Information Newton's flow - Wang_Li - 2020.pdf:application/pdf},
}

@article{ambrogioniWassersteinVariationalGradient2019,
	title = {Wasserstein variational gradient descent: {From} semi-discrete optimal transport to ensemble variational inference},
	shorttitle = {Wasserstein variational gradient descent},
	url = {http://arxiv.org/abs/1811.02827},
	abstract = {Particle-based variational inference offers a flexible way of approximating complex posterior distributions with a set of particles. In this paper we introduce a new particle-based variational inference method based on the theory of semi-discrete optimal transport. Instead of minimizing the KL divergence between the posterior and the variational approximation, we minimize a semi-discrete optimal transport divergence. The solution of the resulting optimal transport problem provides both a particle approximation and a set of optimal transportation densities that map each particle to a segment of the posterior distribution. We approximate these transportation densities by minimizing the KL divergence between a truncated distribution and the optimal transport solution. The resulting algorithm can be interpreted as a form of ensemble variational inference where each particle is associated with a local variational approximation.},
	urldate = {2021-02-08},
	journal = {arXiv:1811.02827 [cs, stat]},
	author = {Ambrogioni, Luca and Guclu, Umut and van Gerven, Marcel},
	month = may,
	year = {2019},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1811.02827},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/AK3V3VQK/1811.html:text/html;Wasserstein variational gradient descent - Ambrogioni et al - 2019.pdf:/home/theo/Zotero/storage/YPVC62QU/Wasserstein variational gradient descent - Ambrogioni et al - 2019.pdf:application/pdf},
}

@article{rahimiRandomFeaturesLargeScale,
	title = {Random {Features} for {Large}-{Scale} {Kernel} {Machines}},
	abstract = {To accelerate the training of kernel machines, we propose to map the input data to a randomized low-dimensional feature space and then apply existing fast linear methods. Our randomized features are designed so that the inner products of the transformed data are approximately equal to those in the feature space of a user speciﬁed shift-invariant kernel. We explore two sets of random features, provide convergence bounds on their ability to approximate various radial basis kernels, and show that in large-scale classiﬁcation and regression tasks linear machine learning algorithms that use these features outperform state-of-the-art large-scale kernel machines.},
	language = {en},
	author = {Rahimi, Ali and Recht, Ben},
	note = {ZSCC: 0002512},
	pages = {8},
	file = {Random Features for Large-Scale Kernel Machines - Rahimi_Recht -.pdf:/home/theo/Zotero/storage/UGTCKQS9/Random Features for Large-Scale Kernel Machines - Rahimi_Recht -.pdf:application/pdf},
}

@article{wolfVariationalInferenceHamiltonian2016,
	title = {Variational {Inference} with {Hamiltonian} {Monte} {Carlo}},
	url = {http://arxiv.org/abs/1609.08203},
	abstract = {Variational inference lies at the core of many state-of-the-art algorithms. To improve the approximation of the posterior beyond parametric families, it was proposed to include MCMC steps into the variational lower bound. In this work we explore this idea using steps of the Hamiltonian Monte Carlo (HMC) algorithm, an efficient MCMC method. In particular, we incorporate the acceptance step of the HMC algorithm, guaranteeing asymptotic convergence to the true posterior. Additionally, we introduce some extensions to the HMC algorithm geared towards faster convergence. The theoretical advantages of these modifications are reflected by performance improvements in our experimental results.},
	urldate = {2021-02-01},
	journal = {arXiv:1609.08203 [stat]},
	author = {Wolf, Christopher and Karl, Maximilian and van der Smagt, Patrick},
	month = sep,
	year = {2016},
	note = {ZSCC: 0000014 
arXiv: 1609.08203},
	keywords = {Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/24TXKQKY/1609.html:text/html;Variational Inference with Hamiltonian Monte Carlo - Wolf et al - 2016.pdf:/home/theo/Zotero/storage/PKIR5YXP/Variational Inference with Hamiltonian Monte Carlo - Wolf et al - 2016.pdf:application/pdf},
}

@inproceedings{liuUnderstandingAcceleratingParticleBased2019,
	title = {Understanding and {Accelerating} {Particle}-{Based} {Variational} {Inference}},
	url = {http://proceedings.mlr.press/v97/liu19i.html},
	abstract = {Particle-based variational inference methods (ParVIs) have gained attention in the Bayesian inference literature, for their capacity to yield flexible and accurate approximations. We explore ParVIs...},
	language = {en},
	urldate = {2021-02-01},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Liu, Chang and Zhuo, Jingwei and Cheng, Pengyu and Zhang, Ruiyi and Zhu, Jun},
	month = may,
	year = {2019},
	note = {ZSCC: 0000017 
ISSN: 2640-3498},
	pages = {4082--4092},
	file = {Snapshot:/home/theo/Zotero/storage/54PLAG9I/liu19i.html:text/html;Understanding and Accelerating Particle-Based Variational Inference - Liu et al - 2019.pdf:/home/theo/Zotero/storage/7F9AXIKA/Understanding and Accelerating Particle-Based Variational Inference - Liu et al - 2019.pdf:application/pdf;Understanding and Accelerating Particle-Based Variational Inference - Liu et al - 2019.pdf:/home/theo/Zotero/storage/5KCCAF45/Understanding and Accelerating Particle-Based Variational Inference - Liu et al - 2019.pdf:application/pdf},
}

@article{gunterSamplingInferenceProbabilistic,
	title = {Sampling for {Inference} in {Probabilistic} {Models} with {Fast} {Bayesian} {Quadrature}},
	abstract = {We propose a novel sampling framework for inference in probabilistic models: an active learning approach that converges more quickly (in wall-clock time) than Markov chain Monte Carlo (MCMC) benchmarks. The central challenge in probabilistic inference is numerical integration, to average over ensembles of models or unknown (hyper-)parameters (for example to compute the marginal likelihood or a partition function). MCMC has provided approaches to numerical integration that deliver state-of-the-art inference, but can suffer from sample inefﬁciency and poor convergence diagnostics. Bayesian quadrature techniques offer a model-based solution to such problems, but their uptake has been hindered by prohibitive computation costs. We introduce a warped model for probabilistic integrands (likelihoods) that are known to be non-negative, permitting a cheap active learning scheme to optimally select sample locations. Our algorithm is demonstrated to offer faster convergence (in seconds) relative to simple Monte Carlo and annealed importance sampling on both synthetic and real-world examples.},
	language = {en},
	author = {Gunter, Tom and Osborne, Michael A and Garnett, Roman and Hennig, Philipp and Roberts, Stephen J},
	note = {ZSCC: 0000072},
	pages = {9},
	file = {Sampling for Inference in Probabilistic Models with Fast Bayesian Quadrature - Gunter et al -.pdf:/home/theo/Zotero/storage/SF5FTT3U/Sampling for Inference in Probabilistic Models with Fast Bayesian Quadrature - Gunter et al -.pdf:application/pdf},
}

@article{kingmaAutoEncodingVariationalBayes2014,
	title = {Auto-{Encoding} {Variational} {Bayes}},
	url = {http://arxiv.org/abs/1312.6114},
	abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
	urldate = {2021-01-28},
	journal = {arXiv:1312.6114 [cs, stat]},
	author = {Kingma, Diederik P. and Welling, Max},
	month = may,
	year = {2014},
	note = {ZSCC: 0000006 
arXiv: 1312.6114},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/9BG4XD57/1312.html:text/html;Auto-Encoding Variational Bayes - Kingma_Welling - 2014.pdf:/home/theo/Zotero/storage/CNQQPDRS/Auto-Encoding Variational Bayes - Kingma_Welling - 2014.pdf:application/pdf},
}

@misc{domkeEmbarassingQuestionsVariational,
	title = {Some {Embarassing} {Questions} {About} {Variational} {Inference}},
	url = {https://people.cs.umass.edu/~domke/aabi.pdf},
	abstract = {Presentation for AABI 2021},
	urldate = {2021-01-27},
	author = {Domke, Justin},
	file = {Some Embarassing Questions About Variational Inference - Domke -.pdf:/home/theo/Zotero/storage/VJZTCGVT/Some Embarassing Questions About Variational Inference - Domke -.pdf:application/pdf},
}

@inproceedings{geffnerRuleGradientEstimator2020,
	title = {A {Rule} for {Gradient} {Estimator} {Selection}, with an {Application} to {Variational} {Inference}},
	url = {http://proceedings.mlr.press/v108/geffner20a.html},
	abstract = {Stochastic gradient descent (SGD) is the workhorse of modern machine learning. Sometimes, there are many different potential gradient estimators that can be used. When so, choosing the one with the...},
	language = {en},
	urldate = {2021-01-27},
	booktitle = {International {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Geffner, Tomas and Domke, Justin},
	month = jun,
	year = {2020},
	note = {ZSCC: 0000000 
ISSN: 2640-3498},
	pages = {1803--1812},
	file = {Snapshot:/home/theo/Zotero/storage/UNDY6X9U/geffner20a.html:text/html;A Rule for Gradient Estimator Selection, with an Application to Variational - Geffner_Domke - 2020.pdf:/home/theo/Zotero/storage/MWCRIWPN/A Rule for Gradient Estimator Selection, with an Application to Variational - Geffner_Domke - 2020.pdf:application/pdf},
}

@inproceedings{domkeProvableSmoothnessGuarantees2020,
	title = {Provable {Smoothness} {Guarantees} for {Black}-{Box} {Variational} {Inference}},
	url = {http://proceedings.mlr.press/v119/domke20a.html},
	abstract = {Black-box variational inference tries to approximate a complex target distribution through a gradient-based optimization of the parameters of a simpler distribution. Provable convergence guarantees...},
	language = {en},
	urldate = {2021-01-27},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Domke, Justin},
	month = nov,
	year = {2020},
	note = {ZSCC: 0000005 
ISSN: 2640-3498},
	pages = {2587--2596},
	file = {Snapshot:/home/theo/Zotero/storage/K6RAHMAK/domke20a.html:text/html;Provable Smoothness Guarantees for Black-Box Variational Inference - Domke - 2020.pdf:/home/theo/Zotero/storage/ZK3XZUK5/Provable Smoothness Guarantees for Black-Box Variational Inference - Domke - 2020.pdf:application/pdf},
}

@article{liuSteinVariationalGradient2018,
	title = {Stein {Variational} {Gradient} {Descent} as {Moment} {Matching}},
	url = {http://arxiv.org/abs/1810.11693},
	abstract = {Stein variational gradient descent (SVGD) is a non-parametric inference algorithm that evolves a set of particles to fit a given distribution of interest. We analyze the non-asymptotic properties of SVGD, showing that there exists a set of functions, which we call the Stein matching set, whose expectations are exactly estimated by any set of particles that satisfies the fixed point equation of SVGD. This set is the image of Stein operator applied on the feature maps of the positive definite kernel used in SVGD. Our results provide a theoretical framework for analyzing the properties of SVGD with different kernels, shedding insight into optimal kernel choice. In particular, we show that SVGD with linear kernels yields exact estimation of means and variances on Gaussian distributions, while random Fourier features enable probabilistic bounds for distributional approximation. Our results offer a refreshing view of the classical inference problem as fitting Stein's identity or solving the Stein equation, which may motivate more efficient algorithms.},
	urldate = {2021-01-22},
	journal = {arXiv:1810.11693 [cs, stat]},
	author = {Liu, Qiang and Wang, Dilin},
	month = oct,
	year = {2018},
	note = {ZSCC: 0000015 
arXiv: 1810.11693},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/HXXRNFRV/1810.html:text/html;Stein Variational Gradient Descent as Moment Matching - Liu_Wang - 2018.pdf:/home/theo/Zotero/storage/7GLG9FMR/Stein Variational Gradient Descent as Moment Matching - Liu_Wang - 2018.pdf:application/pdf},
}

@article{ongGaussianVariationalApproximation2017,
	title = {Gaussian variational approximation with a factor covariance structure},
	url = {http://arxiv.org/abs/1701.03208},
	abstract = {Variational approximation methods have proven to be useful for scaling Bayesian computations to large data sets and highly parametrized models. Applying variational methods involves solving an optimization problem, and recent research in this area has focused on stochastic gradient ascent methods as a general approach to implementation. Here variational approximation is considered for a posterior distribution in high dimensions using a Gaussian approximating family. Gaussian variational approximation with an unrestricted covariance matrix can be computationally burdensome in many problems because the number of elements in the covariance matrix increases quadratically with the dimension of the model parameter. To circumvent this problem, low-dimensional factor covariance structures are considered. General stochastic gradient approaches to efficiently perform the optimization are described, with gradient estimates obtained using the so-called "reparametrization trick". The end result is a flexible and efficient approach to high-dimensional Gaussian variational approximation, which we illustrate using eight real datasets.},
	urldate = {2020-11-27},
	journal = {arXiv:1701.03208 [stat]},
	author = {Ong, Victor M.-H. and Nott, David J. and Smith, Michael S.},
	month = jan,
	year = {2017},
	note = {ZSCC: NoCitationData[s1] 
arXiv: 1701.03208},
	keywords = {Statistics - Methodology},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/XBIV7FJR/1701.html:text/html;Gaussian variational approximation with a factor covariance structure - Ong et al - 2017.pdf:/home/theo/Zotero/storage/ALACCNS3/Gaussian variational approximation with a factor covariance structure - Ong et al - 2017.pdf:application/pdf},
}

@article{zhangWhichAlgorithmicChoices2019,
	title = {Which {Algorithmic} {Choices} {Matter} at {Which} {Batch} {Sizes}? {Insights} {From} a {Noisy} {Quadratic} {Model}},
	shorttitle = {Which {Algorithmic} {Choices} {Matter} at {Which} {Batch} {Sizes}?},
	url = {http://arxiv.org/abs/1907.04164},
	abstract = {Increasing the batch size is a popular way to speed up neural network training, but beyond some critical batch size, larger batch sizes yield diminishing returns. In this work, we study how the critical batch size changes based on properties of the optimization algorithm, including acceleration and preconditioning, through two different lenses: large scale experiments, and analysis of a simple noisy quadratic model (NQM). We experimentally demonstrate that optimization algorithms that employ preconditioning, specifically Adam and K-FAC, result in much larger critical batch sizes than stochastic gradient descent with momentum. We also demonstrate that the NQM captures many of the essential features of real neural network training, despite being drastically simpler to work with. The NQM predicts our results with preconditioned optimizers, previous results with accelerated gradient descent, and other results around optimal learning rates and large batch training, making it a useful tool to generate testable predictions about neural network optimization.},
	urldate = {2021-01-21},
	journal = {arXiv:1907.04164 [cs, stat]},
	author = {Zhang, Guodong and Li, Lala and Nado, Zachary and Martens, James and Sachdeva, Sushant and Dahl, George E. and Shallue, Christopher J. and Grosse, Roger},
	month = oct,
	year = {2019},
	note = {ZSCC: 0000023 
arXiv: 1907.04164},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/ZF8DI8MY/1907.html:text/html;Which Algorithmic Choices Matter at Which Batch Sizes - Zhang et al - 2019.pdf:/home/theo/Zotero/storage/BC53YSRE/Which Algorithmic Choices Matter at Which Batch Sizes - Zhang et al - 2019.pdf:application/pdf},
}

@article{amariWhenDoesPreconditioning2020,
	title = {When {Does} {Preconditioning} {Help} or {Hurt} {Generalization}?},
	url = {http://arxiv.org/abs/2006.10732},
	abstract = {While second order optimizers such as natural gradient descent (NGD) often speed up optimization, their effect on generalization has been called into question. This work presents a more nuanced view on how the {\textbackslash}textit\{implicit bias\} of first- and second-order methods affects the comparison of generalization properties. We provide an exact asymptotic bias-variance decomposition of the generalization error of overparameterized ridgeless regression under a general class of preconditioner \${\textbackslash}boldsymbol\{P\}\$, and consider the inverse population Fisher information matrix (used in NGD) as a particular example. We determine the optimal \${\textbackslash}boldsymbol\{P\}\$ for both the bias and variance, and find that the relative generalization performance of different optimizers depends on the label noise and the "shape" of the signal (true parameters): when the labels are noisy, the model is misspecified, or the signal is misaligned with the features, NGD can achieve lower risk; conversely, GD generalizes better than NGD under clean labels, a well-specified model, or aligned signal. Based on this analysis, we discuss several approaches to manage the bias-variance tradeoff, and the potential benefit of interpolating between GD and NGD. We then extend our analysis to regression in the reproducing kernel Hilbert space and demonstrate that preconditioned GD can decrease the population risk faster than GD. Lastly, we empirically compare the generalization error of first- and second-order optimizers in neural network experiments, and observe robust trends matching our theoretical analysis.},
	urldate = {2021-01-21},
	journal = {arXiv:2006.10732 [cs, stat]},
	author = {Amari, Shun-ichi and Ba, Jimmy and Grosse, Roger and Li, Xuechen and Nitanda, Atsushi and Suzuki, Taiji and Wu, Denny and Xu, Ji},
	month = dec,
	year = {2020},
	note = {ZSCC: 0000001 
arXiv: 2006.10732},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/WG9QY82T/2006.html:text/html;When Does Preconditioning Help or Hurt Generalization - Amari et al - 2020.pdf:/home/theo/Zotero/storage/G95J627D/When Does Preconditioning Help or Hurt Generalization - Amari et al - 2020.pdf:application/pdf},
}

@article{gottwaldSupervisedLearningNoisy2020,
	title = {Supervised learning from noisy observations: {Combining} machine-learning techniques with data assimilation},
	shorttitle = {Supervised learning from noisy observations},
	url = {http://arxiv.org/abs/2007.07383},
	abstract = {Data-driven prediction and physics-agnostic machine-learning methods have attracted increased interest in recent years achieving forecast horizons going well beyond those to be expected for chaotic dynamical systems. In a separate strand of research data-assimilation has been successfully used to optimally combine forecast models and their inherent uncertainty with incoming noisy observations. The key idea in our work here is to achieve increased forecast capabilities by judiciously combining machine-learning algorithms and data assimilation. We combine the physics-agnostic data-driven approach of random feature maps as a forecast model within an ensemble Kalman filter data assimilation procedure. The machine-learning model is learned sequentially by incorporating incoming noisy observations. We show that the obtained forecast model has remarkably good forecast skill while being computationally cheap once trained. Going beyond the task of forecasting, we show that our method can be used to generate reliable ensembles for probabilistic forecasting as well as to learn effective model closure in multi-scale systems.},
	urldate = {2021-01-21},
	journal = {arXiv:2007.07383 [physics, stat]},
	author = {Gottwald, Georg A. and Reich, Sebastian},
	month = dec,
	year = {2020},
	note = {ZSCC: 0000001 
arXiv: 2007.07383},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Methodology, Physics - Computational Physics, Physics - Data Analysis, Statistics and Probability},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/P2J8EIAS/2007.html:text/html;Supervised learning from noisy observations - Gottwald_Reich - 2020.pdf:/home/theo/Zotero/storage/V8FAVRC8/Supervised learning from noisy observations - Gottwald_Reich - 2020.pdf:application/pdf},
}

@article{grathwohlLearningSteinDiscrepancy,
	title = {Learning the {Stein} {Discrepancy}  for {Training} and {Evaluating} {Energy}-{Based} {Models} without {Sampling}},
	abstract = {We present a new method for evaluating and training unnormalized density models. Our approach only requires access to the gradient of the unnormalized model’s log-density. We estimate the Stein discrepancy between the data density p(x) and the model density q(x) deﬁned by a vector function of the data. We parameterize this function with a neural network and ﬁt its parameters to maximize the discrepancy. This yields a novel goodness-of-ﬁt test which outperforms existing methods on high dimensional data. Furthermore, optimizing q(x) to minimize this discrepancy produces a novel method for training unnormalized models which scales more gracefully than existing methods. The ability to both learn and compare models is a unique feature of the proposed method.},
	language = {en},
	author = {Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, Jörn-Henrik and Duvenaud, David and Zemel, Richard},
	note = {ZSCC: 0000003},
	pages = {16},
	file = {Learning the Stein Discrepancy for Training and Evaluating Energy-Based Models - Grathwohl et al -.pdf:/home/theo/Zotero/storage/FMAPMTN5/Learning the Stein Discrepancy for Training and Evaluating Energy-Based Models - Grathwohl et al -.pdf:application/pdf},
}

@article{francaDissipativeSymplecticIntegration2020,
	title = {On {Dissipative} {Symplectic} {Integration} with {Applications} to {Gradient}-{Based} {Optimization}},
	url = {http://arxiv.org/abs/2004.06840},
	abstract = {Recently, continuous dynamical systems have proved useful in providing conceptual and quantitative insights into gradient-based optimization, widely used in modern machine learning and statistics. An important question that arises in this line of work is how to discretize the system in such a way that its stability and rates of convergence are preserved. In this paper we propose a geometric framework in which such discretizations can be realized systematically, enabling the derivation of "rate-matching" optimization algorithms without the need for a discrete convergence analysis. More specifically, we show that a generalization of symplectic integrators to dissipative Hamiltonian systems is able to preserve continuous rates of convergence up to a controlled error. Moreover, such methods preserve a perturbed Hamiltonian despite the absence of a conservation law, extending key results of symplectic integrators to dissipative cases. Our arguments rely on a combination of backward error analysis with fundamental results from symplectic geometry.},
	urldate = {2021-01-13},
	journal = {arXiv:2004.06840 [cond-mat, stat]},
	author = {França, Guilherme and Jordan, Michael I. and Vidal, René},
	month = jun,
	year = {2020},
	note = {ZSCC: 0000003 
arXiv: 2004.06840},
	keywords = {Statistics - Machine Learning, Mathematics - Optimization and Control, Condensed Matter - Disordered Systems and Neural Networks, Condensed Matter - Statistical Mechanics},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/I2P8SG6P/2004.html:text/html;On Dissipative Symplectic Integration with Applications to Gradient-Based - França et al - 2020.pdf:/home/theo/Zotero/storage/6ZIYCUD4/On Dissipative Symplectic Integration with Applications to Gradient-Based - França et al - 2020.pdf:application/pdf},
}

@article{barfootMultivariateGaussianVariational2020,
	title = {Multivariate {Gaussian} {Variational} {Inference} by {Natural} {Gradient} {Descent}},
	url = {http://arxiv.org/abs/2001.10025},
	abstract = {This short note reviews so-called Natural Gradient Descent (NGD) for multivariate Gaussians. The Fisher Information Matrix (FIM) is derived for several different parameterizations of Gaussians. Careful attention is paid to the symmetric nature of the covariance matrix when calculating derivatives. We show that there are some advantages to choosing a parameterization comprising the mean and inverse covariance matrix and provide a simple NGD update that accounts for the symmetric (and sparse) nature of the inverse covariance matrix.},
	urldate = {2021-01-19},
	journal = {arXiv:2001.10025 [cs, math, stat]},
	author = {Barfoot, Timothy D.},
	month = oct,
	year = {2020},
	note = {ZSCC: 0000004 
arXiv: 2001.10025},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Mathematics - Statistics Theory, Computer Science - Robotics},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/DXL9FNAQ/2001.html:text/html;Multivariate Gaussian Variational Inference by Natural Gradient Descent - Barfoot - 2020.pdf:/home/theo/Zotero/storage/MU8FGMVL/Multivariate Gaussian Variational Inference by Natural Gradient Descent - Barfoot - 2020.pdf:application/pdf},
}

@article{korbaNonAsymptoticAnalysisStein2021,
	title = {A {Non}-{Asymptotic} {Analysis} for {Stein} {Variational} {Gradient} {Descent}},
	url = {http://arxiv.org/abs/2006.09797},
	abstract = {We study the Stein Variational Gradient Descent (SVGD) algorithm, which optimises a set of particles to approximate a target probability distribution \${\textbackslash}pi{\textbackslash}propto e{\textasciicircum}\{-V\}\$ on \${\textbackslash}mathbb\{R\}{\textasciicircum}d\$. In the population limit, SVGD performs gradient descent in the space of probability distributions on the KL divergence with respect to \${\textbackslash}pi\$, where the gradient is smoothed through a kernel integral operator. In this paper, we provide a novel finite time analysis for the SVGD algorithm. We provide a descent lemma establishing that the algorithm decreases the objective at each iteration, and rates of convergence for the average Stein Fisher divergence (also referred to as Kernel Stein Discrepancy). We also provide a convergence result of the finite particle system corresponding to the practical implementation of SVGD to its population version.},
	urldate = {2021-01-15},
	journal = {arXiv:2006.09797 [cs, stat]},
	author = {Korba, Anna and Salim, Adil and Arbel, Michael and Luise, Giulia and Gretton, Arthur},
	month = jan,
	year = {2021},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 2006.09797},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/CA4P39KN/2006.html:text/html;A Non-Asymptotic Analysis for Stein Variational Gradient Descent - Korba et al - 2021.pdf:/home/theo/Zotero/storage/92CK94B6/A Non-Asymptotic Analysis for Stein Variational Gradient Descent - Korba et al - 2021.pdf:application/pdf},
}

@article{nalisnickStickBreakingVariationalAutoencoders2017,
	title = {Stick-{Breaking} {Variational} {Autoencoders}},
	url = {http://arxiv.org/abs/1605.06197},
	abstract = {We extend Stochastic Gradient Variational Bayes to perform posterior inference for the weights of Stick-Breaking processes. This development allows us to define a Stick-Breaking Variational Autoencoder (SB-VAE), a Bayesian nonparametric version of the variational autoencoder that has a latent representation with stochastic dimensionality. We experimentally demonstrate that the SB-VAE, and a semi-supervised variant, learn highly discriminative latent representations that often outperform the Gaussian VAE's.},
	urldate = {2021-01-12},
	journal = {arXiv:1605.06197 [stat]},
	author = {Nalisnick, Eric and Smyth, Padhraic},
	month = apr,
	year = {2017},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1605.06197},
	keywords = {Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/G73QL5A2/1605.html:text/html;Stick-Breaking Variational Autoencoders - Nalisnick_Smyth - 2017.pdf:/home/theo/Zotero/storage/9VVLL4BC/Stick-Breaking Variational Autoencoders - Nalisnick_Smyth - 2017.pdf:application/pdf},
}

@article{fellerMuntzTheoremCompletely1968,
	title = {On {Muntz}' {Theorem} and {Completely} {Monotone} {Functions}},
	volume = {75},
	issn = {00029890},
	url = {https://www.jstor.org/stable/2313410?origin=crossref},
	doi = {10.2307/2313410},
	number = {4},
	urldate = {2021-01-12},
	journal = {The American Mathematical Monthly},
	author = {Feller, William},
	month = apr,
	year = {1968},
	note = {ZSCC: NoCitationData[s0]},
	pages = {342},
	file = {On Muntz' Theorem and Completely Monotone Functions - Feller - 1968.pdf:/home/theo/Zotero/storage/39TQ7QYB/On Muntz' Theorem and Completely Monotone Functions - Feller - 1968.pdf:application/pdf},
}

@article{challisGaussianKullbackLeiblerApproximate,
	title = {Gaussian {Kullback}-{Leibler} {Approximate} {Inference}},
	abstract = {We investigate Gaussian Kullback-Leibler (G-KL) variational approximate inference techniques for Bayesian generalised linear models and various extensions. In particular we make the following novel contributions: sufﬁcient conditions for which the G-KL objective is differentiable and convex are described; constrained parameterisations of Gaussian covariance that make G-KL methods fast and scalable are provided; the lower bound to the normalisation constant provided by G-KL methods is proven to dominate those provided by local lower bounding methods; complexity and model applicability issues of G-KL versus other Gaussian approximate inference methods are discussed. Numerical results comparing G-KL and other deterministic Gaussian approximate inference methods are presented for: robust Gaussian process regression models with either Student-t or Laplace likelihoods, large scale Bayesian binary logistic regression models, and Bayesian sparse linear models for sequential experimental design.},
	language = {en},
	author = {Challis, Edward and Barber, David and Challis, E and Barber, D},
	note = {ZSCC: 0000055},
	pages = {48},
	file = {Gaussian Kullback-Leibler Approximate Inference - Challis et al -.pdf:/home/theo/Zotero/storage/YMSMGETH/Gaussian Kullback-Leibler Approximate Inference - Challis et al -.pdf:application/pdf},
}

@article{chenProjectedSteinVariational2020,
	title = {Projected {Stein} {Variational} {Gradient} {Descent}},
	url = {http://arxiv.org/abs/2002.03469},
	abstract = {The curse of dimensionality is a longstanding challenge in Bayesian inference in high dimensions. In this work, we propose a projected Stein variational gradient descent (pSVGD) method to overcome this challenge by exploiting the fundamental property of intrinsic low dimensionality of the data informed subspace stemming from ill-posedness of such problems. We adaptively construct the subspace using a gradient information matrix of the log-likelihood, and apply pSVGD to the much lower-dimensional coefficients of the parameter projection. The method is demonstrated to be more accurate and efficient than SVGD. It is also shown to be more scalable with respect to the number of parameters, samples, data points, and processor cores via experiments with parameters dimensions ranging from the hundreds to the tens of thousands.},
	urldate = {2020-12-14},
	journal = {arXiv:2002.03469 [cs, stat]},
	author = {Chen, Peng and Ghattas, Omar},
	month = jun,
	year = {2020},
	note = {ZSCC: 0000006 
arXiv: 2002.03469},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/779DXII9/2002.html:text/html;Projected Stein Variational Gradient Descent - Chen_Ghattas - 2020.pdf:/home/theo/Zotero/storage/BSJFKSA7/Projected Stein Variational Gradient Descent - Chen_Ghattas - 2020.pdf:application/pdf},
}

@article{jarvenpaaEfficientAcquisitionRules2019,
	title = {Efficient acquisition rules for model-based approximate {Bayesian} computation},
	volume = {14},
	issn = {1936-0975},
	url = {http://arxiv.org/abs/1704.00520},
	doi = {10.1214/18-BA1121},
	abstract = {Approximate Bayesian computation (ABC) is a method for Bayesian inference when the likelihood is unavailable but simulating from the model is possible. However, many ABC algorithms require a large number of simulations, which can be costly. To reduce the computational cost, Bayesian optimisation (BO) and surrogate models such as Gaussian processes have been proposed. Bayesian optimisation enables one to intelligently decide where to evaluate the model next but common BO strategies are not designed for the goal of estimating the posterior distribution. Our paper addresses this gap in the literature. We propose to compute the uncertainty in the ABC posterior density, which is due to a lack of simulations to estimate this quantity accurately, and define a loss function that measures this uncertainty. We then propose to select the next evaluation location to minimise the expected loss. Experiments show that the proposed method often produces the most accurate approximations as compared to common BO strategies.},
	number = {2},
	urldate = {2020-12-14},
	journal = {Bayesian Analysis},
	author = {Järvenpää, Marko and Gutmann, Michael U. and Pleska, Arijus and Vehtari, Aki and Marttinen, Pekka},
	month = jun,
	year = {2019},
	note = {ZSCC: 0000031 
arXiv: 1704.00520},
	keywords = {Statistics - Machine Learning, Statistics - Computation, Statistics - Methodology},
	pages = {595--622},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/7B343MGW/1704.html:text/html;Efficient acquisition rules for model-based approximate Bayesian computation - Järvenpää et al - 2019.pdf:/home/theo/Zotero/storage/AXHMBXBG/Efficient acquisition rules for model-based approximate Bayesian computation - Järvenpää et al - 2019.pdf:application/pdf},
}

@article{acerbiVariationalBayesianMonte2020,
	title = {Variational {Bayesian} {Monte} {Carlo} with {Noisy} {Likelihoods}},
	url = {http://arxiv.org/abs/2006.08655},
	abstract = {Variational Bayesian Monte Carlo (VBMC) is a recently introduced framework that uses Gaussian process surrogates to perform approximate Bayesian inference in models with black-box, non-cheap likelihoods. In this work, we extend VBMC to deal with noisy log-likelihood evaluations, such as those arising from simulation-based models. We introduce new `global' acquisition functions, such as expected information gain (EIG) and variational interquantile range (VIQR), which are robust to noise and can be efficiently evaluated within the VBMC setting. In a novel, challenging, noisy-inference benchmark comprising of a variety of models with real datasets from computational and cognitive neuroscience, VBMC+VIQR achieves state-of-the-art performance in recovering the ground-truth posteriors and model evidence. In particular, our method vastly outperforms `local' acquisition functions and other surrogate-based inference methods while keeping a small algorithmic cost. Our benchmark corroborates VBMC as a general-purpose technique for sample-efficient black-box Bayesian inference also with noisy models.},
	urldate = {2020-12-14},
	journal = {arXiv:2006.08655 [cs, q-bio, stat]},
	author = {Acerbi, Luigi},
	month = oct,
	year = {2020},
	note = {ZSCC: 0000003 
arXiv: 2006.08655},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Computation, Quantitative Biology - Neurons and Cognition, Quantitative Biology - Quantitative Methods},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/5FEM66Q4/2006.html:text/html;Variational Bayesian Monte Carlo with Noisy Likelihoods - Acerbi - 2020.pdf:/home/theo/Zotero/storage/DSL5IFFT/Variational Bayesian Monte Carlo with Noisy Likelihoods - Acerbi - 2020.pdf:application/pdf},
}

@article{diaconisConjugatePriorsExponential1979,
	title = {Conjugate {Priors} for {Exponential} {Families}},
	volume = {7},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/euclid.aos/1176344611},
	doi = {10.1214/aos/1176344611},
	abstract = {Let XXX be a random vector distributed according to an exponential family with natural parameter θ∈Θθ∈Θ{\textbackslash}theta {\textbackslash}in {\textbackslash}Theta. We characterize conjugate prior measures on ΘΘ{\textbackslash}Theta through the property of linear posterior expectation of the mean parameter of X:E\{E(X{\textbar}θ){\textbar}X=x\}=ax+bX:E\{E(X{\textbar}θ){\textbar}X=x\}=ax+bX : E{\textbackslash}\{E(X{\textbar}{\textbackslash}theta){\textbar}X = x{\textbackslash}\} = ax + b. We also delineate which hyperparameters permit such conjugate priors to be proper.},
	language = {EN},
	number = {2},
	urldate = {2020-12-08},
	journal = {Annals of Statistics},
	author = {Diaconis, Persi and Ylvisaker, Donald},
	month = mar,
	year = {1979},
	mrnumber = {MR520238},
	zmnumber = {0405.62011},
	note = {ZSCC: 0000753 
Publisher: Institute of Mathematical Statistics},
	keywords = {admissibility, Bayesian analysis, characterization theorems, Conjugate priors, credibility theory, exponential families, linearity of regression},
	pages = {269--281},
	file = {Snapshot:/home/theo/Zotero/storage/JLLSQ692/1176344611.html:text/html;Snapshot:/home/theo/Zotero/storage/SR98F9VJ/1176344611.html:text/html;Conjugate Priors for Exponential Families - Diaconis_Ylvisaker - 1979.pdf:/home/theo/Zotero/storage/4553TL6F/Conjugate Priors for Exponential Families - Diaconis_Ylvisaker - 1979.pdf:application/pdf;Conjugate Priors for Exponential Families - Diaconis_Ylvisaker - 1979.pdf:/home/theo/Zotero/storage/GCZET5E8/Conjugate Priors for Exponential Families - Diaconis_Ylvisaker - 1979.pdf:application/pdf},
}

@misc{RelativeGradientOverview,
	title = {Relative {Gradient} - an overview {\textbar} {ScienceDirect} {Topics}},
	url = {https://www.sciencedirect.com/topics/computer-science/relative-gradient},
	urldate = {2020-12-08},
	file = {Relative Gradient - an overview | ScienceDirect Topics:/home/theo/Zotero/storage/65Z5G4BR/relative-gradient.html:text/html},
}

@article{pfauIntegrableNonparametricFlows2020,
	title = {Integrable {Nonparametric} {Flows}},
	url = {http://arxiv.org/abs/2012.02035},
	abstract = {We introduce a method for reconstructing an infinitesimal normalizing flow given only an infinitesimal change to a (possibly unnormalized) probability distribution. This reverses the conventional task of normalizing flows -- rather than being given samples from a unknown target distribution and learning a flow that approximates the distribution, we are given a perturbation to an initial distribution and aim to reconstruct a flow that would generate samples from the known perturbed distribution. While this is an underdetermined problem, we find that choosing the flow to be an integrable vector field yields a solution closely related to electrostatics, and a solution can be computed by the method of Green's functions. Unlike conventional normalizing flows, this flow can be represented in an entirely nonparametric manner. We validate this derivation on low-dimensional problems, and discuss potential applications to problems in quantum Monte Carlo and machine learning.},
	urldate = {2020-12-07},
	journal = {arXiv:2012.02035 [cs, stat]},
	author = {Pfau, David and Rezende, Danilo},
	month = dec,
	year = {2020},
	note = {ZSCC: 0000000 
arXiv: 2012.02035},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/Z54XFHAR/2012.html:text/html;Integrable Nonparametric Flows - Pfau_Rezende - 2020.pdf:/home/theo/Zotero/storage/F3JQTEPD/Integrable Nonparametric Flows - Pfau_Rezende - 2020.pdf:application/pdf},
}

@article{titsiasOnevsEachApproximationSoftmax2016,
	title = {One-vs-{Each} {Approximation} to {Softmax} for {Scalable} {Estimation} of {Probabilities}},
	url = {http://arxiv.org/abs/1609.07410},
	abstract = {The softmax representation of probabilities for categorical variables plays a prominent role in modern machine learning with numerous applications in areas such as large scale classification, neural language modeling and recommendation systems. However, softmax estimation is very expensive for large scale inference because of the high cost associated with computing the normalizing constant. Here, we introduce an efficient approximation to softmax probabilities which takes the form of a rigorous lower bound on the exact probability. This bound is expressed as a product over pairwise probabilities and it leads to scalable estimation based on stochastic optimization. It allows us to perform doubly stochastic estimation by subsampling both training instances and class labels. We show that the new bound has interesting theoretical properties and we demonstrate its use in classification problems.},
	urldate = {2020-12-02},
	journal = {arXiv:1609.07410 [stat]},
	author = {Titsias, Michalis K.},
	month = oct,
	year = {2016},
	note = {ZSCC: 0000036 
arXiv: 1609.07410},
	keywords = {Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/24GUGKL8/1609.html:text/html;One-vs-Each Approximation to Softmax for Scalable Estimation of Probabilities - Titsias - 2016.pdf:/home/theo/Zotero/storage/TVW2NCIV/One-vs-Each Approximation to Softmax for Scalable Estimation of Probabilities - Titsias - 2016.pdf:application/pdf},
}

@article{opperVariationalGaussianApproximation2009,
	title = {The {Variational} {Gaussian} {Approximation} {Revisited}},
	volume = {21},
	issn = {0899-7667, 1530-888X},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/neco.2008.08-07-592},
	doi = {10.1162/neco.2008.08-07-592},
	abstract = {The variational approximation of posterior distributions by multivariate Gaussians has been much less popular in the Machine Learning community compared to the corresponding approximation by factorising distributions. This is for a good reason: the Gaussian approximation is in general plagued by an O(N 2) number of variational parameters to be optimised, N being the number of random variables. In this work, we discuss the relationship between the Laplace and the variational approximation and we show that for models with Gaussian priors and factorising likelihoods, the number of variational parameters is actually O(N ). The approach is applied to Gaussian process regression with non-Gaussian likelihoods.},
	language = {en},
	number = {3},
	urldate = {2020-12-02},
	journal = {Neural Computation},
	author = {Opper, Manfred and Archambeau, Cédric},
	month = mar,
	year = {2009},
	note = {ZSCC: 0000272},
	pages = {786--792},
	file = {The Variational Gaussian Approximation Revisited - Opper_Archambeau - 2009.pdf:/home/theo/Zotero/storage/V4J9RI5A/The Variational Gaussian Approximation Revisited - Opper_Archambeau - 2009.pdf:application/pdf},
}

@book{sarkkaAppliedStochasticDifferential2019,
	edition = {1},
	title = {Applied {Stochastic} {Differential} {Equations}},
	isbn = {978-1-108-18673-5 978-1-316-51008-7 978-1-316-64946-6},
	url = {https://www.cambridge.org/core/product/identifier/9781108186735/type/book},
	language = {en},
	urldate = {2020-11-24},
	publisher = {Cambridge University Press},
	author = {Särkkä, Simo and Solin, Arno},
	month = apr,
	year = {2019},
	doi = {10.1017/9781108186735},
	note = {ZSCC: 0000081 },
	file = {Applied Stochastic Differential Equations - Särkkä_Solin - 2019.pdf:/home/theo/Zotero/storage/2CKFVGVV/Applied Stochastic Differential Equations - Särkkä_Solin - 2019.pdf:application/pdf},
}

@article{linHandlingPositiveDefiniteConstraint2020,
	title = {Handling the {Positive}-{Definite} {Constraint} in the {Bayesian} {Learning} {Rule}},
	url = {http://arxiv.org/abs/2002.10060},
	abstract = {The Bayesian learning rule is a natural-gradient variational inference method, which not only contains many existing learning algorithms as special cases but also enables the design of new algorithms. Unfortunately, when variational parameters lie in an open constraint set, the rule may not satisfy the constraint and requires line-searches which could slow down the algorithm. In this work, we address this issue for positive-definite constraints by proposing an improved rule that naturally handles the constraints. Our modification is obtained by using Riemannian gradient methods, and is valid when the approximation attains a {\textbackslash}emph\{block-coordinate natural parameterization\} (e.g., Gaussian distributions and their mixtures). We propose a principled way to derive Riemannian gradients and retractions from scratch. Our method outperforms existing methods without any significant increase in computation. Our work makes it easier to apply the rule in the presence of positive-definite constraints in parameter spaces.},
	urldate = {2020-12-01},
	journal = {arXiv:2002.10060 [cs, stat]},
	author = {Lin, Wu and Schmidt, Mark and Khan, Mohammad Emtiyaz},
	month = oct,
	year = {2020},
	note = {ZSCC: 0000000 
arXiv: 2002.10060},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/CPH3ZWUF/2002.html:text/html;Handling the Positive-Definite Constraint in the Bayesian Learning Rule - Lin et al - 2020.pdf:/home/theo/Zotero/storage/CJDMIAZX/Handling the Positive-Definite Constraint in the Bayesian Learning Rule - Lin et al - 2020.pdf:application/pdf},
}

@article{looGeneralizedVariationalContinual2020,
	title = {Generalized {Variational} {Continual} {Learning}},
	url = {http://arxiv.org/abs/2011.12328},
	abstract = {Continual learning deals with training models on new tasks and datasets in an online fashion. One strand of research has used probabilistic regularization for continual learning, with two of the main approaches in this vein being Online Elastic Weight Consolidation (Online EWC) and Variational Continual Learning (VCL). VCL employs variational inference, which in other settings has been improved empirically by applying likelihood-tempering. We show that applying this modification to VCL recovers Online EWC as a limiting case, allowing for interpolation between the two approaches. We term the general algorithm Generalized VCL (GVCL). In order to mitigate the observed overpruning effect of VI, we take inspiration from a common multi-task architecture, neural networks with task-specific FiLM layers, and find that this addition leads to significant performance gains, specifically for variational methods. In the small-data regime, GVCL strongly outperforms existing baselines. In larger datasets, GVCL with FiLM layers outperforms or is competitive with existing baselines in terms of accuracy, whilst also providing significantly better calibration.},
	urldate = {2020-12-01},
	journal = {arXiv:2011.12328 [cs]},
	author = {Loo, Noel and Swaroop, Siddharth and Turner, Richard E.},
	month = nov,
	year = {2020},
	note = {ZSCC: 0000000 
arXiv: 2011.12328},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/QQEVTQAQ/2011.html:text/html;Generalized Variational Continual Learning - Loo et al - 2020.pdf:/home/theo/Zotero/storage/GMDAQHFG/Generalized Variational Continual Learning - Loo et al - 2020.pdf:application/pdf},
}

@article{briolFrankWolfeBayesianQuadrature2015,
	title = {Frank-{Wolfe} {Bayesian} {Quadrature}: {Probabilistic} {Integration} with {Theoretical} {Guarantees}},
	shorttitle = {Frank-{Wolfe} {Bayesian} {Quadrature}},
	url = {http://arxiv.org/abs/1506.02681},
	abstract = {There is renewed interest in formulating integration as an inference problem, motivated by obtaining a full distribution over numerical error that can be propagated through subsequent computation. Current methods, such as Bayesian Quadrature, demonstrate impressive empirical performance but lack theoretical analysis. An important challenge is to reconcile these probabilistic integrators with rigorous convergence guarantees. In this paper, we present the first probabilistic integrator that admits such theoretical treatment, called Frank-Wolfe Bayesian Quadrature (FWBQ). Under FWBQ, convergence to the true value of the integral is shown to be exponential and posterior contraction rates are proven to be superexponential. In simulations, FWBQ is competitive with state-of-the-art methods and out-performs alternatives based on Frank-Wolfe optimisation. Our approach is applied to successfully quantify numerical error in the solution to a challenging model choice problem in cellular biology.},
	urldate = {2020-11-30},
	journal = {arXiv:1506.02681 [stat]},
	author = {Briol, François-Xavier and Oates, Chris J. and Girolami, Mark and Osborne, Michael A.},
	month = dec,
	year = {2015},
	note = {ZSCC: 0000058 
arXiv: 1506.02681},
	keywords = {Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/KSBVURIL/1506.html:text/html;Frank-Wolfe Bayesian Quadrature - Briol et al - 2015.pdf:/home/theo/Zotero/storage/4GTFJBIJ/Frank-Wolfe Bayesian Quadrature - Briol et al - 2015.pdf:application/pdf},
}

@article{kamtheDataEfficientReinforcementLearning2018,
	title = {Data-{Efficient} {Reinforcement} {Learning} with {Probabilistic} {Model} {Predictive} {Control}},
	url = {http://arxiv.org/abs/1706.06491},
	abstract = {Trial-and-error based reinforcement learning (RL) has seen rapid advancements in recent times, especially with the advent of deep neural networks. However, the majority of autonomous RL algorithms require a large number of interactions with the environment. A large number of interactions may be impractical in many real-world applications, such as robotics, and many practical systems have to obey limitations in the form of state space or control constraints. To reduce the number of system interactions while simultaneously handling constraints, we propose a model-based RL framework based on probabilistic Model Predictive Control (MPC). In particular, we propose to learn a probabilistic transition model using Gaussian Processes (GPs) to incorporate model uncertainty into long-term predictions, thereby, reducing the impact of model errors. We then use MPC to find a control sequence that minimises the expected long-term cost. We provide theoretical guarantees for first-order optimality in the GP-based transition models with deterministic approximate inference for long-term planning. We demonstrate that our approach does not only achieve state-of-the-art data efficiency, but also is a principled way for RL in constrained environments.},
	urldate = {2020-11-30},
	journal = {arXiv:1706.06491 [cs, stat]},
	author = {Kamthe, Sanket and Deisenroth, Marc Peter},
	month = feb,
	year = {2018},
	note = {ZSCC: 0000089 
arXiv: 1706.06491},
	keywords = {Statistics - Machine Learning, Electrical Engineering and Systems Science - Systems and Control},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/HYWTMPV8/1706.html:text/html;Data-Efficient Reinforcement Learning with Probabilistic Model Predictive - Kamthe_Deisenroth - 2018.pdf:/home/theo/Zotero/storage/UT3L87I9/Data-Efficient Reinforcement Learning with Probabilistic Model Predictive - Kamthe_Deisenroth - 2018.pdf:application/pdf},
}

@article{curiEfficientModelBasedReinforcement,
	title = {Efﬁcient {Model}-{Based} {Reinforcement} {Learning} through {Optimistic} {Policy} {Search} and {Planning}},
	abstract = {Model-based reinforcement learning algorithms with probabilistic dynamical models are amongst the most data-efﬁcient learning methods. This is often attributed to their ability to distinguish between epistemic and aleatoric uncertainty. However, while most algorithms distinguish these two uncertainties for learning the model, they ignore it when optimizing the policy, which leads to greedy and insufﬁcient exploration. At the same time, there are no practical solvers for optimistic exploration algorithms. In this paper, we propose a practical optimistic exploration algorithm (H-UCRL). H-UCRL reparameterizes the set of plausible models and hallucinates control directly on the epistemic uncertainty. By augmenting the input space with the hallucinated inputs, H-UCRL can be solved using standard greedy planners. Furthermore, we analyze H-UCRL and construct a general regret bound for well-calibrated models, which is provably sublinear in the case of Gaussian Process models. Based on this theoretical foundation, we show how optimistic exploration can be easily combined with state-of-the-art reinforcement learning algorithms and different probabilistic models. Our experiments demonstrate that optimistic exploration signiﬁcantly speeds-up learning when there are penalties on actions, a setting that is notoriously difﬁcult for existing model-based reinforcement learning algorithms.},
	language = {en},
	author = {Curi, Sebastian and Berkenkamp, Felix and Krause, Andreas},
	note = {ZSCC: 0000003},
	pages = {51},
	file = {Efﬁcient Model-Based Reinforcement Learning through Optimistic Policy Search - Curi et al -.pdf:/home/theo/Zotero/storage/VXC4NI3P/Efﬁcient Model-Based Reinforcement Learning through Optimistic Policy Search - Curi et al -.pdf:application/pdf},
}

@article{tanGaussianVariationalApproximation2018,
	title = {Gaussian variational approximation with sparse precision matrices},
	volume = {28},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-017-9729-7},
	doi = {10.1007/s11222-017-9729-7},
	abstract = {We consider the problem of learning a Gaussian variational approximation to the posterior distribution for a high-dimensional parameter, where we impose sparsity in the precision matrix to reflect appropriate conditional independence structure in the model. Incorporating sparsity in the precision matrix allows the Gaussian variational distribution to be both flexible and parsimonious, and the sparsity is achieved through parameterization in terms of the Cholesky factor. Efficient stochastic gradient methods that make appropriate use of gradient information for the target distribution are developed for the optimization. We consider alternative estimators of the stochastic gradients, which have lower variation and are more stable. Our approach is illustrated using generalized linear mixed models and state-space models for time series.},
	language = {en},
	number = {2},
	urldate = {2020-11-27},
	journal = {Statistics and Computing},
	author = {Tan, Linda S. L. and Nott, David J.},
	month = mar,
	year = {2018},
	note = {ZSCC: 0000034},
	pages = {259--275},
	file = {Gaussian variational approximation with sparse precision matrices - Tan_Nott - 2018.pdf:/home/theo/Zotero/storage/3JEE6KMY/Gaussian variational approximation with sparse precision matrices - Tan_Nott - 2018.pdf:application/pdf;Gaussian variational approximation with sparse precision matrices - Tan_Nott - 2018.pdf:/home/theo/Zotero/storage/WI7RQR95/Gaussian variational approximation with sparse precision matrices - Tan_Nott - 2018.pdf:application/pdf},
}

@article{titsiasDoublyStochasticVariational,
	title = {Doubly {Stochastic} {Variational} {Bayes} for non-{Conjugate} {Inference}},
	abstract = {We propose a simple and effective variational inference algorithm based on stochastic optimisation that can be widely applied for Bayesian non-conjugate inference in continuous parameter spaces. This algorithm is based on stochastic approximation and allows for efﬁcient use of gradient information from the model joint density. We demonstrate these properties using illustrative examples as well as in challenging and diverse Bayesian inference problems such as variable selection in logistic regression and fully Bayesian inference over kernel hyperparameters in Gaussian process regression.},
	language = {en},
	author = {Titsias, Michalis K and Lázaro-Gredilla, Miguel},
	note = {ZSCC: 0000294},
	pages = {9},
	file = {Doubly Stochastic Variational Bayes for non-Conjugate Inference - Titsias_Lázaro-Gredilla -.pdf:/home/theo/Zotero/storage/RQF5E8Q8/Doubly Stochastic Variational Bayes for non-Conjugate Inference - Titsias_Lázaro-Gredilla -.pdf:application/pdf},
}

@article{burtUnderstandingVariationalInference2020,
	title = {Understanding {Variational} {Inference} in {Function}-{Space}},
	url = {http://arxiv.org/abs/2011.09421},
	abstract = {Recent work has attempted to directly approximate the `function-space' or predictive posterior distribution of Bayesian models, without approximating the posterior distribution over the parameters. This is appealing in e.g. Bayesian neural networks, where we only need the former, and the latter is hard to represent. In this work, we highlight some advantages and limitations of employing the Kullback-Leibler divergence in this setting. For example, we show that minimizing the KL divergence between a wide class of parametric distributions and the posterior induced by a (non-degenerate) Gaussian process prior leads to an ill-defined objective function. Then, we propose (featurized) Bayesian linear regression as a benchmark for `function-space' inference methods that directly measures approximation quality. We apply this methodology to assess aspects of the objective function and inference scheme considered in Sun, Zhang, Shi, and Grosse (2018), emphasizing the quality of approximation to Bayesian inference as opposed to predictive performance.},
	urldate = {2020-11-22},
	journal = {arXiv:2011.09421 [cs, stat]},
	author = {Burt, David R. and Ober, Sebastian W. and Garriga-Alonso, Adrià and van der Wilk, Mark},
	month = nov,
	year = {2020},
	note = {ZSCC: 0000000 
arXiv: 2011.09421},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/CXHEBSUV/2011.html:text/html;Understanding Variational Inference in Function-Space - Burt et al - 2020.pdf:/home/theo/Zotero/storage/DXPWLQZI/Understanding Variational Inference in Function-Space - Burt et al - 2020.pdf:application/pdf},
}

@article{opperVariationalInferenceStochastic2019,
	title = {Variational {Inference} for {Stochastic} {Differential} {Equations}},
	volume = {531},
	issn = {00033804},
	url = {http://doi.wiley.com/10.1002/andp.201800233},
	doi = {10.1002/andp.201800233},
	language = {en},
	number = {3},
	urldate = {2020-11-17},
	journal = {Annalen der Physik},
	author = {Opper, Manfred},
	month = mar,
	year = {2019},
	note = {ZSCC: 0000005},
	pages = {1800233},
	file = {Variational Inference for Stochastic Differential Equations - Opper - 2019.pdf:/home/theo/Zotero/storage/44GXPJFI/Variational Inference for Stochastic Differential Equations - Opper - 2019.pdf:application/pdf},
}

@article{andrieuTutorialAdaptiveMCMC2008,
	title = {A tutorial on adaptive {MCMC}},
	volume = {18},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-008-9110-y},
	doi = {10.1007/s11222-008-9110-y},
	abstract = {We review adaptive Markov chain Monte Carlo algorithms (MCMC) as a mean to optimise their performance. Using simple toy examples we review their theoretical underpinnings, and in particular show why adaptive MCMC algorithms might fail when some fundamental properties are not satisﬁed. This leads to guidelines concerning the design of correct algorithms. We then review criteria and the useful framework of stochastic approximation, which allows one to systematically optimise generally used criteria, but also analyse the properties of adaptive MCMC algorithms. We then propose a series of novel adaptive algorithms which prove to be robust and reliable in practice. These algorithms are applied to artiﬁcial and high dimensional scenarios, but also to the classic mine disaster dataset inference problem.},
	language = {en},
	number = {4},
	urldate = {2020-11-20},
	journal = {Statistics and Computing},
	author = {Andrieu, Christophe and Thoms, Johannes},
	month = dec,
	year = {2008},
	note = {ZSCC: 0000752},
	pages = {343--373},
	file = {A tutorial on adaptive MCMC - Andrieu_Thoms - 2008.pdf:/home/theo/Zotero/storage/49TCVPR3/A tutorial on adaptive MCMC - Andrieu_Thoms - 2008.pdf:application/pdf},
}

@article{robertsExamplesAdaptiveMCMC2009,
	title = {Examples of {Adaptive} {MCMC}},
	volume = {18},
	issn = {1061-8600, 1537-2715},
	url = {http://www.tandfonline.com/doi/abs/10.1198/jcgs.2009.06134},
	doi = {10.1198/jcgs.2009.06134},
	language = {en},
	number = {2},
	urldate = {2020-11-20},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Roberts, Gareth O. and Rosenthal, Jeffrey S.},
	month = jan,
	year = {2009},
	note = {ZSCC: 0000931},
	pages = {349--367},
	file = {Examples of Adaptive MCMC - Roberts_Rosenthal - 2009.pdf:/home/theo/Zotero/storage/ELNI6DM8/Examples of Adaptive MCMC - Roberts_Rosenthal - 2009.pdf:application/pdf},
}

@article{smolyakovAdaptiveScanGibbs,
	title = {Adaptive {Scan} {Gibbs} {Sampler} for {Large} {Scale} {Inference} {Problems}},
	abstract = {For large scale inference problems the update strategy is critical for performance. We derive an adaptive scan Gibbs sampler that optimizes the update frequency by selecting an optimum mini-batch size. We demonstrate performance of our adaptive batch-size Gibbs sampler by comparing it against the collapsed Gibbs sampler for Bayesian Lasso, Dirchlet Process Mixture Models (DPMM) and Latent Dirichlet Allocation (LDA) graphical models.},
	language = {en},
	author = {Smolyakov, Vadim and Liu, Qiang and Iii, John W Fisher},
	note = {ZSCC: 0000000},
	pages = {7},
	file = {Adaptive Scan Gibbs Sampler for Large Scale Inference Problems - Smolyakov et al -.pdf:/home/theo/Zotero/storage/IN3XWRBD/Adaptive Scan Gibbs Sampler for Large Scale Inference Problems - Smolyakov et al -.pdf:application/pdf},
}

@incollection{atchadeAdaptiveMarkovChain2011,
	address = {Cambridge},
	title = {Adaptive {Markov} chain {Monte} {Carlo}: theory and methods},
	isbn = {978-0-511-98467-9},
	shorttitle = {Adaptive {Markov} chain {Monte} {Carlo}},
	url = {https://www.cambridge.org/core/product/identifier/CBO9780511984679A018/type/book_part},
	language = {en},
	urldate = {2020-11-20},
	booktitle = {Bayesian {Time} {Series} {Models}},
	publisher = {Cambridge University Press},
	author = {Atchadé, Yves and Fort, Gersende and Moulines, Eric and Priouret, Pierre},
	editor = {Barber, David and Cemgil, A. Taylan and Chiappa, Silvia},
	year = {2011},
	doi = {10.1017/CBO9780511984679.003},
	note = {ZSCC: NoCitationData[s0] },
	pages = {32--51},
	file = {Adaptive Markov chain Monte Carlo - Atchadé et al - 2011.pdf:/home/theo/Zotero/storage/883VK3EG/Adaptive Markov chain Monte Carlo - Atchadé et al - 2011.pdf:application/pdf},
}

@article{changStrictlyPositiveDefinite1996,
	title = {Strictly {Positive} {Definite} {Functions}},
	volume = {87},
	issn = {0021-9045},
	url = {http://www.sciencedirect.com/science/article/pii/S0021904596900970},
	doi = {10.1006/jath.1996.0097},
	abstract = {We give a complete characterization of the strictly positive definite functions on the real line. By Bochner's theorem, this is equivalent to proving that if the separated sequence of real numbers \{an\} describes the points of discontinuity of a distribution function, there exists an almost periodic polynomial with the zeros \{an\}. We prove a useful necessary condition that every strictly normalized, positive definite functionfsatisfies {\textbar}f(x){\textbar}{\textless}1 for allx≠0. It is a sufficient condition for strictly positive definiteness that if the carrier of a nonzero finite Borel measure on R is not a discrete set, then the Fourier–Stieltjes transformμofμis strictly positive definite.},
	language = {en},
	number = {2},
	urldate = {2020-11-19},
	journal = {Journal of Approximation Theory},
	author = {Chang, Kuei-Fang},
	month = nov,
	year = {1996},
	note = {ZSCC: 0000038},
	pages = {148--158},
	file = {ScienceDirect Snapshot:/home/theo/Zotero/storage/4X4PSLUA/S0021904596900970.html:text/html;Strictly Positive Definite Functions - Chang - 1996.pdf:/home/theo/Zotero/storage/T2TU7IBV/Strictly Positive Definite Functions - Chang - 1996.pdf:application/pdf;Strictly Positive Definite Functions - Chang - 1996.pdf:/home/theo/Zotero/storage/ADT5U7VD/Strictly Positive Definite Functions - Chang - 1996.pdf:application/pdf},
}

@article{csekeExpectationPropagationContinuous2016,
	title = {Expectation propagation for continuous time stochastic processes},
	volume = {49},
	issn = {1751-8113, 1751-8121},
	url = {http://arxiv.org/abs/1512.06098},
	doi = {10.1088/1751-8113/49/49/494002},
	abstract = {We consider the inverse problem of reconstructing the posterior measure over the trajec- tories of a diffusion process from discrete time observations and continuous time constraints. We cast the problem in a Bayesian framework and derive approximations to the posterior distributions of single time marginals using variational approximate inference. We then show how the approximation can be extended to a wide class of discrete-state Markov jump pro- cesses by making use of the chemical Langevin equation. Our empirical results show that the proposed method is computationally efficient and provides good approximations for these classes of inverse problems.},
	number = {49},
	urldate = {2020-11-18},
	journal = {Journal of Physics A: Mathematical and Theoretical},
	author = {Cseke, Botond and Schnoerr, David and Opper, Manfred and Sanguinetti, Guido},
	month = dec,
	year = {2016},
	note = {ZSCC: 0000012 
arXiv: 1512.06098},
	keywords = {Statistics - Machine Learning},
	pages = {494002},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/87H9QLFX/1512.html:text/html;Expectation propagation for continuous time stochastic processes - Cseke et al - 2016.pdf:/home/theo/Zotero/storage/4SQYAQZU/Expectation propagation for continuous time stochastic processes - Cseke et al - 2016.pdf:application/pdf;Expectation propagation for continuous time stochastic processes - Cseke et al - 2016.pdf:/home/theo/Zotero/storage/ICS685TA/Expectation propagation for continuous time stochastic processes - Cseke et al - 2016.pdf:application/pdf},
}

@article{merkleCompletelyMonotoneFunctions2012,
	title = {Completely monotone functions - a digest},
	url = {http://arxiv.org/abs/1211.0900},
	abstract = {This work has a purpose to collect selected facts about the completely monotone (CM) functions that can be found in books and papers devoted to different areas of mathematics. We opted for lesser known ones, and for those which may help determining whether or not a given function is completely monotone. In particular, we emphasize the role of representation of a CM function as the Laplace transform of a measure, and we present and discuss a little known connection with log-convexity. Some of presented methods are illustrated by several examples involving Gamma and related functions.},
	urldate = {2020-11-19},
	journal = {arXiv:1211.0900 [math]},
	author = {Merkle, Milan},
	month = nov,
	year = {2012},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1211.0900},
	keywords = {Mathematics - Classical Analysis and ODEs},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/BXNBENRJ/1211.html:text/html;Completely monotone functions - a digest - Merkle - 2012.pdf:/home/theo/Zotero/storage/CHW3UT7N/Completely monotone functions - a digest - Merkle - 2012.pdf:application/pdf},
}

@article{zhangPoissonMinibatchingGibbsSampling,
	title = {Poisson-{Minibatching} for {Gibbs} {Sampling} with {Convergence} {Rate} {Guarantees}},
	abstract = {Gibbs sampling is a Markov chain Monte Carlo method that is often used for learning and inference on graphical models. Minibatching, in which a small random subset of the graph is used at each iteration, can help make Gibbs sampling scale to large graphical models by reducing its computational cost. In this paper, we propose a new auxiliary-variable minibatched Gibbs sampling method, Poissonminibatching Gibbs, which both produces unbiased samples and has a theoretical guarantee on its convergence rate. In comparison to previous minibatched Gibbs algorithms, Poisson-minibatching Gibbs supports fast sampling from continuous state spaces and avoids the need for a Metropolis-Hastings correction on discrete state spaces. We demonstrate the effectiveness of our method on multiple applications and in comparison with both plain Gibbs and previous minibatched methods.},
	language = {en},
	author = {Zhang, Ruqi and Sa, Christopher M De},
	note = {ZSCC: 0000003},
	pages = {10},
	file = {Poisson-Minibatching for Gibbs Sampling with Convergence Rate Guarantees - Zhang_Sa -.pdf:/home/theo/Zotero/storage/U27VLBJV/Poisson-Minibatching for Gibbs Sampling with Convergence Rate Guarantees - Zhang_Sa -.pdf:application/pdf},
}

@article{munteanuCoresetsMethodsHistoryTheoreticians2018,
	title = {Coresets-{Methods} and {History}: {A} {Theoreticians} {Design} {Pattern} for {Approximation} and {Streaming} {Algorithms}},
	volume = {32},
	issn = {1610-1987},
	shorttitle = {Coresets-{Methods} and {History}},
	url = {https://doi.org/10.1007/s13218-017-0519-3},
	doi = {10.1007/s13218-017-0519-3},
	abstract = {We present a technical survey on the state of the art approaches in data reduction and the coreset framework. These include geometric decompositions, gradient methods, random sampling, sketching and random projections. We further outline their importance for the design of streaming algorithms and give a brief overview on lower bounding techniques.},
	language = {en},
	number = {1},
	urldate = {2020-11-19},
	journal = {KI - Künstliche Intelligenz},
	author = {Munteanu, Alexander and Schwiegelshohn, Chris},
	month = feb,
	year = {2018},
	note = {ZSCC: 0000030},
	pages = {37--53},
	file = {Coresets-Methods and History - Munteanu_Schwiegelshohn - 2018.pdf:/home/theo/Zotero/storage/PWL99GVB/Coresets-Methods and History - Munteanu_Schwiegelshohn - 2018.pdf:application/pdf},
}

@article{zhangAsymptoticallyOptimalExact,
	title = {Asymptotically {Optimal} {Exact} {Minibatch} {Metropolis}-{Hastings}},
	abstract = {Metropolis-Hastings (MH) is a commonly-used MCMC algorithm, but it can be intractable on large datasets due to requiring computations over the whole dataset. In this paper, we study minibatch MH methods, which instead use subsamples to enable scaling. We observe that most existing minibatch MH methods are inexact (i.e. they may change the target distribution), and show that this inexactness can cause arbitrarily large errors in inference. We propose a new exact minibatch MH method, TunaMH, which exposes a tunable trade-off between its batch size and its theoretically guaranteed convergence rate. We prove a lower bound on the batch size that any minibatch MH method must use to retain exactness while guaranteeing fast convergence—the ﬁrst such bound for minibatch MH—and show TunaMH is asymptotically optimal in terms of the batch size. Empirically, we show TunaMH outperforms other exact minibatch MH methods on robust linear regression, truncated Gaussian mixtures, and logistic regression.},
	language = {en},
	author = {Zhang, Ruqi and Cooper, A Feder and Sa, Christopher De},
	note = {ZSCC: 0000003},
	pages = {37},
	file = {Asymptotically Optimal Exact Minibatch Metropolis-Hastings - Zhang et al -.pdf:/home/theo/Zotero/storage/UA3I3HI3/Asymptotically Optimal Exact Minibatch Metropolis-Hastings - Zhang et al -.pdf:application/pdf},
}

@article{gaoStreamingGibbsSampling2016,
	title = {Streaming {Gibbs} {Sampling} for {LDA} {Model}},
	url = {http://arxiv.org/abs/1601.01142},
	abstract = {Streaming variational Bayes (SVB) is successful in learning LDA models in an online manner. However previous attempts toward developing online Monte-Carlo methods for LDA have little success, often by having much worse perplexity than their batch counterparts. We present a streaming Gibbs sampling (SGS) method, an online extension of the collapsed Gibbs sampling (CGS). Our empirical study shows that SGS can reach similar perplexity as CGS, much better than SVB. Our distributed version of SGS, DSGS, is much more scalable than SVB mainly because the updates' communication complexity is small.},
	urldate = {2020-11-20},
	journal = {arXiv:1601.01142 [cs, stat]},
	author = {Gao, Yang and Chen, Jianfei and Zhu, Jun},
	month = jan,
	year = {2016},
	note = {ZSCC: 0000012 
arXiv: 1601.01142},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/SUGQZ425/1601.html:text/html;Streaming Gibbs Sampling for LDA Model - Gao et al - 2016.pdf:/home/theo/Zotero/storage/XTS5B6TC/Streaming Gibbs Sampling for LDA Model - Gao et al - 2016.pdf:application/pdf},
}

@misc{StrictlyPositiveDefinite,
	title = {Strictly {Positive} {Definite} {Functions} {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0021904596900970?token=AFBF4B9D3DF35AFF5ED2C5E5BB621A426FCB345C56F1DE37E6BA5D99DCCFB27C7A19C4707F4F25F0A513F36BE69779D8},
	language = {en},
	urldate = {2020-11-19},
	doi = {10.1006/jath.1996.0097},
	file = {Snapshot:/home/theo/Zotero/storage/82B3AEXX/S0021904596900970.html:text/html},
}

@article{ohaganBayesHermiteQuadrature1991,
	title = {Bayes–{Hermite} quadrature},
	volume = {29},
	issn = {03783758},
	url = {https://linkinghub.elsevier.com/retrieve/pii/037837589190002V},
	doi = {10.1016/0378-3758(91)90002-V},
	abstract = {Bayesian quadrature treats the problem of numerical integration as one of statistical inference. A prior Gaussian process distribution is assumed for the integrand, observations arise from evaluating the integrand at selected points, and a posterior distribution is derived for the integrand and the integral. Methods are developed for quadrature in IRP. A particular application is integrating the posterior density arising from some other Bayesian analysis. Simulation results are presented, to show that the resulting Bayes-Hermite quadrature rules may perform better than the conventional Gauss-Hermite rules for this application. A key result is derived for product designs, which makes Bayesian quadrature practically useful for integrating in several dimensions. Although the method does not at present provide a solution to the more difficult problem of quadrature in high dimensions, it does seem to offer real improvements over existing methods in relatively low dimensions.},
	language = {en},
	number = {3},
	urldate = {2020-11-12},
	journal = {Journal of Statistical Planning and Inference},
	author = {O'Hagan, A.},
	month = nov,
	year = {1991},
	note = {ZSCC: 0000294},
	pages = {245--260},
	file = {Bayes–Hermite quadrature - O'Hagan - 1991.pdf:/home/theo/Zotero/storage/4MC3J8Q2/Bayes–Hermite quadrature - O'Hagan - 1991.pdf:application/pdf},
}

@article{lartillotnicolasComputingBayesFactors,
	title = {Computing {Bayes} {Factors} {Using} {Thermodynamic} {Integration}},
	url = {https://watermark.silverchair.com/10635150500433722.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAr4wggK6BgkqhkiG9w0BBwagggKrMIICpwIBADCCAqAGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMl0IvibPatmtDj3F9AgEQgIICcZD09U8fsOlrSFZi2nDmICl24l0yoj-88aKakrPOkMYiTarPbEfxBzTVCxU2tiskpBJ0wtp0QbOgqBobX5h-XiON-ssOawwWjygErWQ4e6HqE5b-NpoeWezQDcxG9o9UMJ7LNQgF39eK82sUhIXQ9X0bhu1yEPon9x4RvVLnUOzI6E0Rm-KFOyieH6y0g5mKdnIgzXStpP23EiT3MyMy4E8zXnSE012i1X-K3LIbNdf0Da16rATKQO9yySkFVaSD65L0w4RmGX7-sbTxt2h5xVba8lk8Nb7PQoJM5PZ2X8Q5j4_Nc9-7LrxSzUMFTnuFs_u7P52BJZXhXWjRRZDJob6VRpaL1C4xsAzf8VEIw8c-3xScmbh74JdX7iSR-YQoc6L1X5x2Um3dL6vk-ZH6cXagVdFcbJmsFKQHnsLdElfHDXXjXBZhQS7Hh0CcwStZea2voGIUzgRl-3r67z0O_8jK_ic3qYQqIUHBAKdq1EMVC0EovHAvd2K00rWnFh6xgBEheBCPd9Z5jf-UJVdNx1v2ud1i9Tv-UAjOWdDZTjyFdTGlhU0CPrcKPAtwmsQSQoimSHvdQGEbX6Xh2b3XTIvD9aJIYmxNsRuPCdqFYUyFb9DOEPbAy__YSEvq3UzlLfUwVFzSgbR39GK4rLMNq7SxAMTnh4AkjPHNVTW-35f0jeXiv7KO7vvGULLQg-dg2ih37FqQxaLyvoNjihk84FSQtvoJk_UEG3Azc6mlGmp5sO32ojzGoo2YdXZUXpKddMeo4YAhhVwHyskgCh4MrDrLlAFhQgzDI0lz-nEBCq6x9135-ayL5tyaZUannfheqaQ},
	urldate = {2020-11-12},
	author = {Lartillot, Nicolas and Philippe, Herve},
	note = {ZSCC: 0000564},
	file = {Computing Bayes Factors Using Thermodynamic Integration - Lartillot, Nicolas_Philippe, Herve -.pdf:/home/theo/Zotero/storage/ZJRXRWYY/Computing Bayes Factors Using Thermodynamic Integration - Lartillot, Nicolas_Philippe, Herve -.pdf:application/pdf},
}

@article{gelmanSimulatingNormalizingConstants1998,
	title = {Simulating normalizing constants: from importance sampling to bridge sampling to path sampling},
	volume = {13},
	issn = {0883-4237, 2168-8745},
	shorttitle = {Simulating normalizing constants},
	url = {https://projecteuclid.org/euclid.ss/1028905934},
	doi = {10.1214/ss/1028905934},
	abstract = {Computing (ratios of) normalizing constants of probability models is a fundamental computational problem for many statistical and scientific studies. Monte Carlo simulation is an effective technique, especially with complex and high-dimensional models. This paper aims to bring to the attention of general statistical audiences of some effective methods originating from theoretical physics and at the same time to explore these methods from a more statistical perspective, through establishing theoretical connections and illustrating their uses with statistical problems. We show that the acceptance ratio method and thermodynamic integration are natural generalizations of importance sampling, which is most familiar to statistical audiences. The former generalizes importance sampling through the use of a single "bridge" density and is thus a case of bridge sampling in the sense of Meng and Wong. Thermodynamic integration, which is also known in the numerical analysis literature as Ogata's method for high-dimensional integration, corresponds to the use of infinitely many and continuously connected bridges (and thus a "path"). Our path sampling formulation offers more flexibility and thus potential efficiency to thermodynamic integration, and the search of optimal paths turns out to have close connections with the Jeffreys prior density and the Rao and Hellinger distances between two densities. We provide an informative theoretical example as well as two empirical examples (involving 17- to 70-dimensional integrations) to illustrate the potential and implementation of path sampling. We also discuss some open problems.},
	language = {en},
	number = {2},
	urldate = {2020-11-12},
	journal = {Statistical Science},
	author = {Gelman, Andrew and Meng, Xiao-Li},
	month = may,
	year = {1998},
	mrnumber = {MR1647507},
	zmnumber = {0966.65004},
	note = {ZSCC: 0001050 
Publisher: Institute of Mathematical Statistics},
	keywords = {Markov chain Monte Carlo, Hellinger distance, Acceptance ratio method, Jeffreys prior density, numerical integration, Rao distance, thermodynamic integration},
	pages = {163--185},
	file = {Snapshot:/home/theo/Zotero/storage/DADGPBYJ/1028905934.html:text/html;Snapshot:/home/theo/Zotero/storage/VS5WYPBX/1028905934.html:text/html;Simulating normalizing constants - Gelman_Meng - 1998.pdf:/home/theo/Zotero/storage/369LY9TY/Simulating normalizing constants - Gelman_Meng - 1998.pdf:application/pdf},
}

@article{ohaganMonteCarloFundamentally1987,
	title = {Monte {Carlo} is {Fundamentally} {Unsound}},
	volume = {36},
	number = {2},
	author = {O'Hagan, A.},
	year = {1987},
	note = {ZSCC: 0000085},
	pages = {247--249},
	file = {PDF:/home/theo/Zotero/storage/Z43I3EUV/A. O'Hagan - 1987 - Monte Carlo is Fundamentally Unsound.pdf:application/pdf},
}

@misc{eamonnkeoghHowGoodResearch1990,
	title = {How to do good research, get it published in {SIGKDD} and get it cited!},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/cbdv.200490137/abstract},
	abstract = {Publishing in top tier venues such as SIGKDD can seem daunting, and can be frustrating But you can do it! Taking a systematic approach, and being self- critical at every stage will help you chances greatly. Having an external critical eye (mock-reviewers) will also help you chances greatly.},
	author = {Eamonn, Keogh},
	year = {1990},
	note = {ZSCC: 0000016},
	keywords = {AIDS, Dextran sulfate, Disposition, Rat},
	file = {How to do good research, get it published in SIGKDD and get it cited - Eamonn, Keogh et al - 1990.pdf:/home/theo/Zotero/storage/BCQ9I2BK/How to do good research, get it published in SIGKDD and get it cited - Eamonn, Keogh et al - 1990.pdf:application/pdf},
}

@article{oatesControlFunctionalsMonte2016,
	title = {Control functionals for {Monte} {Carlo} integration},
	url = {http://arxiv.org/abs/1410.2392},
	abstract = {A non-parametric extension of control variates is presented. These leverage gradient information on the sampling density to achieve substantial variance reduction. It is not required that the sampling density be normalised. The novel contribution of this work is based on two important insights; (i) a trade-off between random sampling and deterministic approximation and (ii) a new gradient-based function space derived from Stein's identity. Unlike classical control variates, our estimators achieve super-root-\$n\$ convergence, often requiring orders of magnitude fewer simulations to achieve a fixed level of precision. Theoretical and empirical results are presented, the latter focusing on integration problems arising in hierarchical models and models based on non-linear ordinary differential equations.},
	urldate = {2020-11-09},
	journal = {arXiv:1410.2392 [stat]},
	author = {Oates, Chris J. and Girolami, Mark and Chopin, Nicolas},
	month = apr,
	year = {2016},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1410.2392},
	keywords = {Statistics - Methodology},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/GYHQ85X9/1410.html:text/html;Control functionals for Monte Carlo integration - Oates et al - 2016.pdf:/home/theo/Zotero/storage/9EVJDBXB/Control functionals for Monte Carlo integration - Oates et al - 2016.pdf:application/pdf},
}

@article{bousquetTheoryUniversalLearning,
	title = {A {Theory} of {Universal} {Learning}},
	abstract = {How quickly can a given class of concepts be learned from examples? It is common to measure the performance of a supervised machine learning algorithm by plotting its “learning curve”, that is, the decay of the error rate as a function of the number of training examples. However, the classical theoretical framework for understanding learnability, the PAC model of Vapnik-Chervonenkis and Valiant, does not explain the behavior of learning curves: the distribution-free PAC model of learning can only bound the upper envelope of the learning curves over all possible data distributions. This does not match the practice of machine learning, where the data source is typically ﬁxed in any given scenario, while the learner may choose the number of training examples on the basis of factors such as computational resources and desired accuracy.},
	language = {en},
	author = {Bousquet, Olivier and Hanneke, Steve and Moran, Shay},
	note = {ZSCC: NoCitationData[s0]},
	pages = {51},
	file = {A Theory of Universal Learning - Bousquet et al -.pdf:/home/theo/Zotero/storage/26Q6HDE2/A Theory of Universal Learning - Bousquet et al -.pdf:application/pdf},
}

@article{owenartb.QuasiMonteCarloSampling,
	title = {Quasi-{Monte} {Carlo} {Sampling}},
	url = {http://statweb.stanford.edu/~owen/courses/362-1415/readings/siggraph03.pdf},
	urldate = {2020-11-09},
	author = {Owen, Art B.},
	note = {ZSCC: 0000079},
	file = {Quasi-Monte Carlo Sampling - Owen, Art B. -.pdf:/home/theo/Zotero/storage/8IRABFQF/Quasi-Monte Carlo Sampling - Owen, Art B. -.pdf:application/pdf},
}

@article{gelmanandrewBayesianWorkflow,
	title = {Bayesian workflow},
	url = {https://dpsimpson.github.io/pages/talks/Bayesian_Workflow.pdf},
	abstract = {The Bayesian approach to data analysis provides a powerful way to handle uncertainty in all
observations, model parameters, and model structure using probability theory. Probabilistic
programming languages make it easier to specify and fit Bayesian models, but this still leaves
us with many options regarding constructing, evaluating, and using these models, along with
many remaining challenges in computation. Using Bayesian inference to solve real-world
problems requires not only statistical skills, subject matter knowledge, and programming, but
also awareness of the decisions made in the process of data analysis. All of these aspects
can be understood as part of a tangled workflow of applied Bayesian statistics. Beyond
inference, the workflow also includes iterative model building, model checking, validation and
troubleshooting of computational problems, model understanding, and model comparison. We
review all these aspects of workflow in the context of several examples, keeping in mind that
in practice we will be fitting many models for any given problem, even if only a subset of them
will ultimately be relevant for our conclusions},
	urldate = {2020-11-03},
	author = {Gelman, Andrew and Vehtari, Aki and Simpson, Daniel and Margossian, Charles C. and Carpenter, Bob and Yao, Yuling and Kennedy, Lauren and Gabry, Jonah and Bürkner, Paul-Christian and Modrák, Martin},
	note = {ZSCC: NoCitationData[s0]},
	file = {Bayesian workflow - Gelman, Andrew et al -.pdf:/home/theo/Zotero/storage/PJVH7SMY/Bayesian workflow - Gelman, Andrew et al -.pdf:application/pdf},
}

@article{garneloNeuralProcesses2018,
	title = {Neural {Processes}},
	url = {http://arxiv.org/abs/1807.01622},
	abstract = {A neural network (NN) is a parameterised function that can be tuned via gradient descent to approximate a labelled collection of data with high precision. A Gaussian process (GP), on the other hand, is a probabilistic model that defines a distribution over possible functions, and is updated in light of data via the rules of probabilistic inference. GPs are probabilistic, data-efficient and flexible, however they are also computationally intensive and thus limited in their applicability. We introduce a class of neural latent variable models which we call Neural Processes (NPs), combining the best of both worlds. Like GPs, NPs define distributions over functions, are capable of rapid adaptation to new observations, and can estimate the uncertainty in their predictions. Like NNs, NPs are computationally efficient during training and evaluation but also learn to adapt their priors to data. We demonstrate the performance of NPs on a range of learning tasks, including regression and optimisation, and compare and contrast with related models in the literature.},
	urldate = {2020-11-09},
	journal = {arXiv:1807.01622 [cs, stat]},
	author = {Garnelo, Marta and Schwarz, Jonathan and Rosenbaum, Dan and Viola, Fabio and Rezende, Danilo J. and Eslami, S. M. Ali and Teh, Yee Whye},
	month = jul,
	year = {2018},
	note = {ZSCC: 0000142 
arXiv: 1807.01622},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/FNWYZB4Z/1807.html:text/html;Neural Processes - Garnelo et al - 2018.pdf:/home/theo/Zotero/storage/ERH8Y823/Neural Processes - Garnelo et al - 2018.pdf:application/pdf},
}

@article{oshiroEffectiveMethodsObtaining2020,
	title = {Effective methods for obtaining good points for quadrature in reproducing kernel {Hilbert} spaces},
	volume = {12},
	issn = {1883-0609, 1883-0617},
	url = {https://www.jstage.jst.go.jp/article/jsiaml/12/0/12_61/_article},
	doi = {10.14495/jsiaml.12.61},
	abstract = {In this paper, we address the problem of numerical integration, which can be solved by kernel quadrature. Existing methods have limitations. In particular, the nodes are not well-balanced when their number is small. We propose two new methods for generating nodes for quadrature in reproducing kernel Hilbert spaces. By using the explicit formula for the error of the quadrature, we improve a set of a ﬁxed number of sampling points with a tractable optimization algorithm. We provide a theoretical analysis of the convergence rate of the error of our ﬁrst method. Numerical experiments show that our methods are eﬀective.},
	language = {en},
	number = {0},
	urldate = {2020-11-09},
	journal = {JSIAM Letters},
	author = {Oshiro, Ryunosuke and Tanaka, Ken'ichiro},
	year = {2020},
	note = {ZSCC: 0000000},
	pages = {61--64},
	file = {Effective methods for obtaining good points for quadrature in reproducing - Oshiro_Tanaka - 2020.pdf:/home/theo/Zotero/storage/BWZM632G/Effective methods for obtaining good points for quadrature in reproducing - Oshiro_Tanaka - 2020.pdf:application/pdf},
}

@article{wilsonDeepKernelLearning2015,
	title = {Deep {Kernel} {Learning}},
	url = {http://arxiv.org/abs/1511.02222},
	abstract = {We introduce scalable deep kernels, which combine the structural properties of deep learning architectures with the non-parametric flexibility of kernel methods. Specifically, we transform the inputs of a spectral mixture base kernel with a deep architecture, using local kernel interpolation, inducing points, and structure exploiting (Kronecker and Toeplitz) algebra for a scalable kernel representation. These closed-form kernels can be used as drop-in replacements for standard kernels, with benefits in expressive power and scalability. We jointly learn the properties of these kernels through the marginal likelihood of a Gaussian process. Inference and learning cost \$O(n)\$ for \$n\$ training points, and predictions cost \$O(1)\$ per test point. On a large and diverse collection of applications, including a dataset with 2 million examples, we show improved performance over scalable Gaussian processes with flexible kernel learning models, and stand-alone deep architectures.},
	urldate = {2020-11-06},
	journal = {arXiv:1511.02222 [cs, stat]},
	author = {Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P.},
	month = nov,
	year = {2015},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1511.02222},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Methodology, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/TEQIQK7Z/1511.html:text/html;Deep Kernel Learning - Wilson et al - 2015.pdf:/home/theo/Zotero/storage/QT6VDF3M/Deep Kernel Learning - Wilson et al - 2015.pdf:application/pdf;arXiv.org Snapshot:/home/theo/Zotero/storage/KBQY7ZV7/1511.html:text/html;Deep Kernel Learning - Wilson et al - 2015.pdf:/home/theo/Zotero/storage/YGVXJ52Y/Deep Kernel Learning - Wilson et al - 2015.pdf:application/pdf},
}

@article{khanFastScalableBayesian2018,
	title = {Fast and {Scalable} {Bayesian} {Deep} {Learning} by {Weight}-{Perturbation} in {Adam}},
	url = {http://arxiv.org/abs/1806.04854},
	abstract = {Uncertainty computation in deep learning is essential to design robust and reliable systems. Variational inference (VI) is a promising approach for such computation, but requires more effort to implement and execute compared to maximum-likelihood methods. In this paper, we propose new natural-gradient algorithms to reduce such efforts for Gaussian mean-field VI. Our algorithms can be implemented within the Adam optimizer by perturbing the network weights during gradient evaluations, and uncertainty estimates can be cheaply obtained by using the vector that adapts the learning rate. This requires lower memory, computation, and implementation effort than existing VI methods, while obtaining uncertainty estimates of comparable quality. Our empirical results confirm this and further suggest that the weight-perturbation in our algorithm could be useful for exploration in reinforcement learning and stochastic optimization.},
	urldate = {2020-10-12},
	journal = {arXiv:1806.04854 [cs, stat]},
	author = {Khan, Mohammad Emtiyaz and Nielsen, Didrik and Tangkaratt, Voot and Lin, Wu and Gal, Yarin and Srivastava, Akash},
	month = aug,
	year = {2018},
	note = {ZSCC: 0000080 
arXiv: 1806.04854},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Computation, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/68F5M3C4/1806.html:text/html;Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam - Khan et al - 2018.pdf:/home/theo/Zotero/storage/K9FLYZPZ/Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam - Khan et al - 2018.pdf:application/pdf},
}

@incollection{menaStatisticalBoundsEntropic2019,
	title = {Statistical bounds for entropic optimal transport: sample complexity and the central limit theorem},
	shorttitle = {Statistical bounds for entropic optimal transport},
	url = {http://papers.nips.cc/paper/8703-statistical-bounds-for-entropic-optimal-transport-sample-complexity-and-the-central-limit-theorem.pdf},
	urldate = {2020-10-02},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 32},
	publisher = {Curran Associates, Inc.},
	author = {Mena, Gonzalo and Niles-Weed, Jonathan},
	editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alché-Buc, F. d{\textbackslash}textquotesingle and Fox, E. and Garnett, R.},
	year = {2019},
	note = {ZSCC: NoCitationData[s0]},
	pages = {4541--4551},
	file = {NIPS Snapshot:/home/theo/Zotero/storage/Y3MB68BV/8703-statistical-bounds-for-entropic-optimal-transport-sample-complexity-and-the-central-limit-.html:text/html;Statistical bounds for entropic optimal transport - Mena_Niles-Weed - 2019.pdf:/home/theo/Zotero/storage/8HUV5FIW/Statistical bounds for entropic optimal transport - Mena_Niles-Weed - 2019.pdf:application/pdf},
}

@incollection{genevayStochasticOptimizationLargescale2016,
	title = {Stochastic {Optimization} for {Large}-scale {Optimal} {Transport}},
	url = {http://papers.nips.cc/paper/6566-stochastic-optimization-for-large-scale-optimal-transport.pdf},
	urldate = {2020-10-02},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {Genevay, Aude and Cuturi, Marco and Peyré, Gabriel and Bach, Francis},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	note = {ZSCC: NoCitationData[s0]},
	pages = {3440--3448},
	file = {NIPS Snapshot:/home/theo/Zotero/storage/J6CGUMGR/6566-stochastic-optimization-for-large-scale-optimal-transport.html:text/html;Stochastic Optimization for Large-scale Optimal Transport - Genevay et al - 2016.pdf:/home/theo/Zotero/storage/R5PJR42Z/Stochastic Optimization for Large-scale Optimal Transport - Genevay et al - 2016.pdf:application/pdf},
}

@article{zhangPolicyOptimizationWasserstein2018,
	title = {Policy {Optimization} as {Wasserstein} {Gradient} {Flows}},
	url = {http://arxiv.org/abs/1808.03030},
	abstract = {Policy optimization is a core component of reinforcement learning (RL), and most existing RL methods directly optimize parameters of a policy based on maximizing the expected total reward, or its surrogate. Though often achieving encouraging empirical success, its underlying mathematical principle on \{{\textbackslash}em policy-distribution\} optimization is unclear. We place policy optimization into the space of probability measures, and interpret it as Wasserstein gradient flows. On the probability-measure space, under specified circumstances, policy optimization becomes a convex problem in terms of distribution optimization. To make optimization feasible, we develop efficient algorithms by numerically solving the corresponding discrete gradient flows. Our technique is applicable to several RL settings, and is related to many state-of-the-art policy-optimization algorithms. Empirical results verify the effectiveness of our framework, often obtaining better performance compared to related algorithms.},
	urldate = {2020-10-02},
	journal = {arXiv:1808.03030 [cs, stat]},
	author = {Zhang, Ruiyi and Chen, Changyou and Li, Chunyuan and Carin, Lawrence},
	month = aug,
	year = {2018},
	note = {ZSCC: 0000028 
arXiv: 1808.03030},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/EE82ZW7U/1808.html:text/html;Policy Optimization as Wasserstein Gradient Flows - Zhang et al - 2018.pdf:/home/theo/Zotero/storage/3BCJ9E6B/Policy Optimization as Wasserstein Gradient Flows - Zhang et al - 2018.pdf:application/pdf},
}

@article{gustafssonBayesianOptimizationHyperparameters2020,
	title = {Bayesian {Optimization} of {Hyperparameters} when the {Marginal} {Likelihood} is {Estimated} by {MCMC}},
	url = {http://arxiv.org/abs/2004.10092},
	abstract = {Bayesian models often involve a small set of hyperparameters determined by maximizing the marginal likelihood. Bayesian optimization is a popular iterative method where a Gaussian process posterior of the underlying function is sequentially updated by new function evaluations. An acquisition strategy uses this posterior distribution to decide where to place the next function evaluation. We propose a novel Bayesian optimization framework for situations where the user controls the computational effort, and therefore the precision of the function evaluations. This is a common situation in econometrics where the marginal likelihood is often computed by Markov Chain Monte Carlo (MCMC) methods, with the precision of the marginal likelihood estimate determined by the number of MCMC draws. The proposed acquisition strategy gives the optimizer the option to explore the function with cheap noisy evaluations and therefore finds the optimum faster. Prior hyperparameter estimation in the steady-state Bayesian vector autoregressive (BVAR) model on US macroeconomic time series data is used for illustration. The proposed method is shown to find the optimum much quicker than traditional Bayesian optimization or grid search.},
	urldate = {2020-10-07},
	journal = {arXiv:2004.10092 [econ, stat]},
	author = {Gustafsson, Oskar and Villani, Mattias and Stockhammar, Pär},
	month = apr,
	year = {2020},
	note = {ZSCC: 0000001 
arXiv: 2004.10092},
	keywords = {Statistics - Computation, Economics - Econometrics},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/X9R3P25I/2004.html:text/html;Bayesian Optimization of Hyperparameters when the Marginal Likelihood is - Gustafsson et al - 2020.pdf:/home/theo/Zotero/storage/2B3T4IF3/Bayesian Optimization of Hyperparameters when the Marginal Likelihood is - Gustafsson et al - 2020.pdf:application/pdf},
}

@article{guoCalibrationModernNeural2017,
	title = {On {Calibration} of {Modern} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1706.04599},
	abstract = {Confidence calibration -- the problem of predicting probability estimates representative of the true correctness likelihood -- is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling -- a single-parameter variant of Platt Scaling -- is surprisingly effective at calibrating predictions.},
	urldate = {2020-10-04},
	journal = {arXiv:1706.04599 [cs]},
	author = {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q.},
	month = aug,
	year = {2017},
	note = {ZSCC: 0000853 
arXiv: 1706.04599},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/73HIM2BN/1706.html:text/html;On Calibration of Modern Neural Networks - Guo et al - 2017.pdf:/home/theo/Zotero/storage/2N2E6EZP/On Calibration of Modern Neural Networks - Guo et al - 2017.pdf:application/pdf},
}

@article{izmailovAveragingWeightsLeads2019,
	title = {Averaging {Weights} {Leads} to {Wider} {Optima} and {Better} {Generalization}},
	url = {http://arxiv.org/abs/1803.05407},
	abstract = {Deep neural networks are typically trained by optimizing a loss function with an SGD variant, in conjunction with a decaying learning rate, until convergence. We show that simple averaging of multiple points along the trajectory of SGD, with a cyclical or constant learning rate, leads to better generalization than conventional training. We also show that this Stochastic Weight Averaging (SWA) procedure finds much flatter solutions than SGD, and approximates the recent Fast Geometric Ensembling (FGE) approach with a single model. Using SWA we achieve notable improvement in test accuracy over conventional SGD training on a range of state-of-the-art residual networks, PyramidNets, DenseNets, and Shake-Shake networks on CIFAR-10, CIFAR-100, and ImageNet. In short, SWA is extremely easy to implement, improves generalization, and has almost no computational overhead.},
	urldate = {2020-10-03},
	journal = {arXiv:1803.05407 [cs, stat]},
	author = {Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
	month = feb,
	year = {2019},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1803.05407},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/6I97GDMN/1803.html:text/html;Averaging Weights Leads to Wider Optima and Better Generalization - Izmailov et al - 2019.pdf:/home/theo/Zotero/storage/BZKZT7C8/Averaging Weights Leads to Wider Optima and Better Generalization - Izmailov et al - 2019.pdf:application/pdf},
}

@book{chenNormalApproximationStein2011,
	address = {Berlin, Heidelberg},
	series = {Probability and {Its} {Applications}},
	title = {Normal {Approximation} by {Stein}’s {Method}},
	isbn = {978-3-642-15006-7 978-3-642-15007-4},
	url = {http://link.springer.com/10.1007/978-3-642-15007-4},
	urldate = {2020-09-30},
	publisher = {Springer Berlin Heidelberg},
	author = {Chen, Louis H.Y. and Goldstein, Larry and Shao, Qi-Man},
	year = {2011},
	doi = {10.1007/978-3-642-15007-4},
	note = {ZSCC: NoCitationData[s0] },
}

@article{nielsenElementaryIntroductionInformation2020,
	title = {An {Elementary} {Introduction} to {Information} {Geometry}},
	volume = {22},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1099-4300/22/10/1100},
	doi = {10.3390/e22101100},
	abstract = {In this survey, we describe the fundamental differential-geometric structures of information manifolds, state the fundamental theorem of information geometry, and illustrate some use cases of these information manifolds in information sciences. The exposition is self-contained by concisely introducing the necessary concepts of differential geometry. Proofs are omitted for brevity.},
	language = {en},
	number = {10},
	urldate = {2020-09-29},
	journal = {Entropy},
	author = {Nielsen, Frank},
	month = oct,
	year = {2020},
	note = {ZSCC: NoCitationData[s0]},
	keywords = {affine connection, Bayesian hypothesis testing, conjugate connections, curvature and flatness, differential geometry, dual metric-compatible parallel transport, dually flat manifolds, exponential family, Fisher–Rao distance, gauge freedom, Hessian manifolds, information manifold, metric compatibility, metric tensor, mixed parameterization, mixture clustering, mixture family, parameter divergence, separable divergence, statistical divergence, statistical invariance, statistical manifold, α-embeddings},
	pages = {1100},
}

@misc{TheogfParticleFlowExp,
	title = {theogf/{ParticleFlow}\_Exp},
	url = {https://github.com/theogf/ParticleFlow_Exp},
	abstract = {Contribute to theogf/ParticleFlow\_Exp development by creating an account on GitHub.},
	language = {en},
	urldate = {2020-09-30},
	journal = {GitHub},
	file = {Snapshot:/home/theo/Zotero/storage/GN3CAQJ2/README.html:text/html},
}

@article{shenkmanNaturalParametrizationMultivariate2017,
	title = {A natural parametrization of multivariate distributions with limited memory},
	volume = {155},
	issn = {0047-259X},
	url = {http://www.sciencedirect.com/science/article/pii/S0047259X17300088},
	doi = {10.1016/j.jmva.2017.01.004},
	abstract = {A unified formulation of the theory of d-variate wide-sense geometric (GdW) and Marshall–Olkin exponential (MOd) distributions is presented in which d-monotone set functions occupy a central role. A semi-analytical derivation of GdW and MOd distributions is deduced directly from the lack-of-memory property. In this context, the distributions are parametrized with d-monotone and d-log-monotone set functions arising from the univariate marginal distributions of minima and the d-decreasingness of the survival functions. In addition, a one-to-one correspondence is established between d-monotone (resp.  d-log-monotone) set functions and d-variate (resp.  d-variate min-infinitely divisible) Bernoulli distributions. The advantage of such a parametrization is that it makes the distributions highly tractable. As a showcase, we derive new results on the minimum stability and divisibility of the GdW family, and on the marginal equivalence in minima of GdW and distributions with geometric minima. Similarly, a surprisingly simple proof is given of the prominent result of Esary and Marshall (1974) on the marginal equivalence in minima of multivariate exponential distributions.},
	language = {en},
	urldate = {2020-09-18},
	journal = {Journal of Multivariate Analysis},
	author = {Shenkman, Natalia},
	month = mar,
	year = {2017},
	note = {ZSCC: 0000006},
	keywords = {(logarithmically) -monotone set function, Lack-of-memory, Marginal equivalence in minima, Marshall–Olkin distribution, Minimum divisibility, Multivariate Bernoulli distribution, Wide-sense geometric distribution},
	pages = {234--251},
	file = {ScienceDirect Snapshot:/home/theo/Zotero/storage/BCH4GQUH/S0047259X17300088.html:text/html;A natural parametrization of multivariate distributions with limited memory - Shenkman - 2017.pdf:/home/theo/Zotero/storage/RYGE8JBN/A natural parametrization of multivariate distributions with limited memory - Shenkman - 2017.pdf:application/pdf},
}

@article{wenzelHowGoodBayes2020,
	title = {How {Good} is the {Bayes} {Posterior} in {Deep} {Neural} {Networks} {Really}?},
	url = {http://arxiv.org/abs/2002.02405},
	abstract = {During the past five years the Bayesian deep learning community has developed increasingly accurate and efficient approximate inference procedures that allow for Bayesian inference in deep neural networks. However, despite this algorithmic progress and the promise of improved uncertainty quantification and sample efficiency there are---as of early 2020---no publicized deployments of Bayesian neural networks in industrial practice. In this work we cast doubt on the current understanding of Bayes posteriors in popular deep neural networks: we demonstrate through careful MCMC sampling that the posterior predictive induced by the Bayes posterior yields systematically worse predictions compared to simpler methods including point estimates obtained from SGD. Furthermore, we demonstrate that predictive performance is improved significantly through the use of a "cold posterior" that overcounts evidence. Such cold posteriors sharply deviate from the Bayesian paradigm but are commonly used as heuristic in Bayesian deep learning papers. We put forward several hypotheses that could explain cold posteriors and evaluate the hypotheses through experiments. Our work questions the goal of accurate posterior approximations in Bayesian deep learning: If the true Bayes posterior is poor, what is the use of more accurate approximations? Instead, we argue that it is timely to focus on understanding the origin of the improved performance of cold posteriors.},
	urldate = {2020-09-16},
	journal = {arXiv:2002.02405 [cs, stat]},
	author = {Wenzel, Florian and Roth, Kevin and Veeling, Bastiaan S. and Świątkowski, Jakub and Tran, Linh and Mandt, Stephan and Snoek, Jasper and Salimans, Tim and Jenatton, Rodolphe and Nowozin, Sebastian},
	month = jul,
	year = {2020},
	note = {ZSCC: 0000014 
arXiv: 2002.02405},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Computation},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/DBWN637Y/2002.html:text/html;How Good is the Bayes Posterior in Deep Neural Networks Really - Wenzel et al - 2020.pdf:/home/theo/Zotero/storage/H935A23N/How Good is the Bayes Posterior in Deep Neural Networks Really - Wenzel et al - 2020.pdf:application/pdf},
}

@article{lakshminarayananSimpleScalablePredictive2017,
	title = {Simple and {Scalable} {Predictive} {Uncertainty} {Estimation} using {Deep} {Ensembles}},
	url = {http://arxiv.org/abs/1612.01474},
	abstract = {Deep neural networks (NNs) are powerful black box predictors that have recently achieved impressive performance on a wide spectrum of tasks. Quantifying predictive uncertainty in NNs is a challenging and yet unsolved problem. Bayesian NNs, which learn a distribution over weights, are currently the state-of-the-art for estimating predictive uncertainty; however these require significant modifications to the training procedure and are computationally expensive compared to standard (non-Bayesian) NNs. We propose an alternative to Bayesian NNs that is simple to implement, readily parallelizable, requires very little hyperparameter tuning, and yields high quality predictive uncertainty estimates. Through a series of experiments on classification and regression benchmarks, we demonstrate that our method produces well-calibrated uncertainty estimates which are as good or better than approximate Bayesian NNs. To assess robustness to dataset shift, we evaluate the predictive uncertainty on test examples from known and unknown distributions, and show that our method is able to express higher uncertainty on out-of-distribution examples. We demonstrate the scalability of our method by evaluating predictive uncertainty estimates on ImageNet.},
	urldate = {2020-09-15},
	journal = {arXiv:1612.01474 [cs, stat]},
	author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
	month = nov,
	year = {2017},
	note = {ZSCC: 0000883 
arXiv: 1612.01474},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/5RYZNSLH/1612.html:text/html;Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles - Lakshminarayanan et al - 2017.pdf:/home/theo/Zotero/storage/F7DH4MRG/Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles - Lakshminarayanan et al - 2017.pdf:application/pdf},
}

@article{mandtStochasticGradientDescent2018,
	title = {Stochastic {Gradient} {Descent} as {Approximate} {Bayesian} {Inference}},
	url = {http://arxiv.org/abs/1704.04289},
	abstract = {Stochastic Gradient Descent with a constant learning rate (constant SGD) simulates a Markov chain with a stationary distribution. With this perspective, we derive several new results. (1) We show that constant SGD can be used as an approximate Bayesian posterior inference algorithm. Specifically, we show how to adjust the tuning parameters of constant SGD to best match the stationary distribution to a posterior, minimizing the Kullback-Leibler divergence between these two distributions. (2) We demonstrate that constant SGD gives rise to a new variational EM algorithm that optimizes hyperparameters in complex probabilistic models. (3) We also propose SGD with momentum for sampling and show how to adjust the damping coefficient accordingly. (4) We analyze MCMC algorithms. For Langevin Dynamics and Stochastic Gradient Fisher Scoring, we quantify the approximation errors due to finite learning rates. Finally (5), we use the stochastic process perspective to give a short proof of why Polyak averaging is optimal. Based on this idea, we propose a scalable approximate MCMC algorithm, the Averaged Stochastic Gradient Sampler.},
	urldate = {2020-09-17},
	journal = {arXiv:1704.04289 [cs, stat]},
	author = {Mandt, Stephan and Hoffman, Matthew D. and Blei, David M.},
	month = jan,
	year = {2018},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1704.04289},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, to read},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/BNFHN25P/1704.html:text/html;Stochastic Gradient Descent as Approximate Bayesian Inference - Mandt et al - 2018.pdf:/home/theo/Zotero/storage/5WSU3IQR/Stochastic Gradient Descent as Approximate Bayesian Inference - Mandt et al - 2018.pdf:application/pdf},
}

@article{koppelConsistentOnlineGaussian2020,
	title = {Consistent {Online} {Gaussian} {Process} {Regression} {Without} the {Sample} {Complexity} {Bottleneck}},
	url = {http://arxiv.org/abs/2004.11094},
	abstract = {Gaussian processes provide a framework for nonlinear nonparametric Bayesian inference widely applicable across science and engineering. Unfortunately, their computational burden scales cubically with the training sample size, which in the case that samples arrive in perpetuity, approaches infinity. This issue necessitates approximations for use with streaming data, which to date mostly lack convergence guarantees. Thus, we develop the first online Gaussian process approximation that preserves convergence to the population posterior, i.e., asymptotic posterior consistency, while ameliorating its intractable complexity growth with the sample size. We propose an online compression scheme that, following each a posteriori update, fixes an error neighborhood with respect to the Hellinger metric centered at the current posterior, and greedily tosses out past kernel dictionary elements until its boundary is hit. We call the resulting method Parsimonious Online Gaussian Processes (POG). For diminishing error radius, exact asymptotic consistency is preserved (Theorem 1(i)) at the cost of unbounded memory in the limit. On the other hand, for constant error radius, POG converges to a neighborhood of the population posterior (Theorem 1(ii))but with finite memory at-worst determined by the metric entropy of the feature space (Theorem 2). Experimental results are presented on several nonlinear regression problems which illuminates the merits of this approach as compared with alternatives that fix the subspace dimension defining the history of past points.},
	urldate = {2020-09-10},
	journal = {arXiv:2004.11094 [cs, math, stat]},
	author = {Koppel, Alec and Pradhan, Hrusikesha and Rajawat, Ketan},
	month = apr,
	year = {2020},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 2004.11094},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Mathematics - Statistics Theory, to read},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/6PIACQ3Q/2004.html:text/html;Consistent Online Gaussian Process Regression Without the Sample Complexity - Koppel et al - 2020.pdf:/home/theo/Zotero/storage/U72UPTEP/Consistent Online Gaussian Process Regression Without the Sample Complexity - Koppel et al - 2020.pdf:application/pdf},
}

@article{durmusHighdimensionalBayesianInference2018,
	title = {High-dimensional {Bayesian} inference via the {Unadjusted} {Langevin} {Algorithm}},
	url = {http://arxiv.org/abs/1605.01559},
	abstract = {We consider in this paper the problem of sampling a high-dimensional probability distribution \${\textbackslash}pi\$ having a density with respect to the Lebesgue measure on \${\textbackslash}mathbb\{R\}{\textasciicircum}d\$, known up to a normalization constant \$x {\textbackslash}mapsto {\textbackslash}pi(x)= {\textbackslash}mathrm\{e\}{\textasciicircum}\{-U(x)\}/{\textbackslash}int\_\{{\textbackslash}mathbb\{R\}{\textasciicircum}d\} {\textbackslash}mathrm\{e\}{\textasciicircum}\{-U(y)\} {\textbackslash}mathrm\{d\} y\$. Such problem naturally occurs for example in Bayesian inference and machine learning. Under the assumption that \$U\$ is continuously differentiable, \${\textbackslash}nabla U\$ is globally Lipschitz and \$U\$ is strongly convex, we obtain non-asymptotic bounds for the convergence to stationarity in Wasserstein distance of order \$2\$ and total variation distance of the sampling method based on the Euler discretization of the Langevin stochastic differential equation, for both constant and decreasing step sizes. The dependence on the dimension of the state space of these bounds is explicit. The convergence of an appropriately weighted empirical measure is also investigated and bounds for the mean square error and exponential deviation inequality are reported for functions which are measurable and bounded. An illustration to Bayesian inference for binary regression is presented to support our claims.},
	urldate = {2020-09-11},
	journal = {arXiv:1605.01559 [math, stat]},
	author = {Durmus, Alain and Moulines, Eric},
	month = jul,
	year = {2018},
	note = {ZSCC: 0000001 
arXiv: 1605.01559},
	keywords = {Statistics - Machine Learning, Statistics - Methodology, Mathematics - Statistics Theory},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/P3Z9UIME/1605.html:text/html;High-dimensional Bayesian inference via the Unadjusted Langevin Algorithm - Durmus_Moulines - 2018.pdf:/home/theo/Zotero/storage/PBS5XVU2/High-dimensional Bayesian inference via the Unadjusted Langevin Algorithm - Durmus_Moulines - 2018.pdf:application/pdf},
}

@inproceedings{ranganathBlackBoxVariational2014,
	title = {Black {Box} {Variational} {Inference}},
	url = {http://proceedings.mlr.press/v33/ranganath14.html},
	abstract = {Variational inference has become a widely used method to approximate posteriors in complex latent variables models.  However, deriving a variational inference algorithm generally requires significa...},
	language = {en},
	urldate = {2020-09-11},
	booktitle = {Artificial {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Ranganath, Rajesh and Gerrish, Sean and Blei, David},
	month = apr,
	year = {2014},
	note = {ZSCC: 0000608 
ISSN: 1938-7228},
	pages = {814--822},
	file = {Snapshot:/home/theo/Zotero/storage/CLFLIV49/ranganath14.html:text/html;Black Box Variational Inference - Ranganath et al - 2014.pdf:/home/theo/Zotero/storage/V6JQWSB2/Black Box Variational Inference - Ranganath et al - 2014.pdf:application/pdf},
}

@incollection{kingmaImprovedVariationalInference2016,
	title = {Improved {Variational} {Inference} with {Inverse} {Autoregressive} {Flow}},
	url = {http://papers.nips.cc/paper/6581-improved-variational-inference-with-inverse-autoregressive-flow.pdf},
	urldate = {2020-09-11},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {Kingma, Durk P and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	note = {ZSCC: NoCitationData[s0]},
	pages = {4743--4751},
	file = {NIPS Snapshot:/home/theo/Zotero/storage/J6A6EZRF/6581-improved-variational-inference-with-inverse-autoregressive-flow.html:text/html;Improved Variational Inference with Inverse Autoregressive Flow - Kingma et al - 2016.pdf:/home/theo/Zotero/storage/KKWUMNBU/Improved Variational Inference with Inverse Autoregressive Flow - Kingma et al - 2016.pdf:application/pdf},
}

@article{rayVariationalBayesHighdimensional2020,
	title = {Variational {Bayes} for high-dimensional linear regression with sparse priors},
	url = {http://arxiv.org/abs/1904.07150},
	abstract = {We study a mean-field spike and slab variational Bayes (VB) approximation to Bayesian model selection priors in sparse high-dimensional linear regression. Under compatibility conditions on the design matrix, oracle inequalities are derived for the mean-field VB approximation, implying that it converges to the sparse truth at the optimal rate and gives optimal prediction of the response vector. The empirical performance of our algorithm is studied, showing that it works comparably well as other state-of-the-art Bayesian variable selection methods. We also numerically demonstrate that the widely used coordinate-ascent variational inference (CAVI) algorithm can be highly sensitive to the parameter updating order, leading to potentially poor performance. To mitigate this, we propose a novel prioritized updating scheme that uses a data-driven updating order and performs better in simulations.},
	urldate = {2020-09-11},
	journal = {arXiv:1904.07150 [math, stat]},
	author = {Ray, Kolyan and Szabo, Botond},
	month = jul,
	year = {2020},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1904.07150},
	keywords = {Statistics - Machine Learning, Statistics - Methodology, Mathematics - Statistics Theory, 62G20 (Primary), 62G05, 65K10 (secondary)},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/D2J3ZSPW/1904.html:text/html;Variational Bayes for high-dimensional linear regression with sparse priors - Ray_Szabo - 2020.pdf:/home/theo/Zotero/storage/5M8WRQ5U/Variational Bayes for high-dimensional linear regression with sparse priors - Ray_Szabo - 2020.pdf:application/pdf},
}

@incollection{nguyen-tuongLocalGaussianProcess2009,
	title = {Local {Gaussian} {Process} {Regression} for {Real} {Time} {Online} {Model} {Learning}},
	url = {http://papers.nips.cc/paper/3403-local-gaussian-process-regression-for-real-time-online-model-learning.pdf},
	urldate = {2020-09-10},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 21},
	publisher = {Curran Associates, Inc.},
	author = {Nguyen-tuong, Duy and Peters, Jan R. and Seeger, Matthias},
	editor = {Koller, D. and Schuurmans, D. and Bengio, Y. and Bottou, L.},
	year = {2009},
	note = {ZSCC: NoCitationData[s0]},
	pages = {1193--1200},
	file = {NIPS Snapshot:/home/theo/Zotero/storage/M7XPT39M/3403-local-gaussian-process-regression-for-real-time-online-model-learning.html:text/html;Local Gaussian Process Regression for Real Time Online Model Learning - Nguyen-tuong et al - 2009.pdf:/home/theo/Zotero/storage/GD6V87DH/Local Gaussian Process Regression for Real Time Online Model Learning - Nguyen-tuong et al - 2009.pdf:application/pdf},
}

@article{smithHighdimensionalCopulaVariational2019,
	title = {High-dimensional copula variational approximation through transformation},
	url = {http://arxiv.org/abs/1904.07495},
	abstract = {Variational methods are attractive for computing Bayesian inference for highly parametrized models and large datasets where exact inference is impractical. They approximate a target distribution - either the posterior or an augmented posterior - using a simpler distribution that is selected to balance accuracy with computational feasibility. Here we approximate an element-wise parametric transformation of the target distribution as multivariate Gaussian or skew-normal. Approximations of this kind are implicit copula models for the original parameters, with a Gaussian or skew-normal copula function and flexible parametric margins. A key observation is that their adoption can improve the accuracy of variational inference in high dimensions at limited or no additional computational cost. We consider the Yeo-Johnson and G\&H transformations, along with sparse factor structures for the scale matrix of the Gaussian or skew-normal. We also show how to implement efficient reparametrization gradient methods for these copula-based approximations. The efficacy of the approach is illustrated by computing posterior inference for three different models using six real datasets. In each case, we show that our proposed copula model distributions are more accurate variational approximations than Gaussian or skew-normal distributions, but at only a minor or no increase in computational cost.},
	urldate = {2020-09-11},
	journal = {arXiv:1904.07495 [stat]},
	author = {Smith, Michael Stanley and Loaiza-Maya, Ruben and Nott, David J.},
	month = nov,
	year = {2019},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1904.07495},
	keywords = {Statistics - Computation},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/RLJ4QSJ9/1904.html:text/html;High-dimensional copula variational approximation through transformation - Smith et al - 2019.pdf:/home/theo/Zotero/storage/6SRNMWVI/High-dimensional copula variational approximation through transformation - Smith et al - 2019.pdf:application/pdf},
}

@article{coleLocallyInducedGaussian2020,
	title = {Locally induced {Gaussian} processes for large-scale simulation experiments},
	url = {http://arxiv.org/abs/2008.12857},
	abstract = {Gaussian processes (GPs) serve as flexible surrogates for complex surfaces, but buckle under the cubic cost of matrix decompositions with big training data sizes. Geospatial and machine learning communities suggest pseudo-inputs, or inducing points, as one strategy to obtain an approximation easing that computational burden. However, we show how placement of inducing points and their multitude can be thwarted by pathologies, especially in large-scale dynamic response surface modeling tasks. As remedy, we suggest porting the inducing point idea, which is usually applied globally, over to a more local context where selection is both easier and faster. In this way, our proposed methodology hybridizes global inducing point and data subset-based local GP approximation. A cascade of strategies for planning the selection of local inducing points is provided, and comparisons are drawn to related methodology with emphasis on computer surrogate modeling applications. We show that local inducing points extend their global and data-subset component parts on the accuracy--computational efficiency frontier. Illustrative examples are provided on benchmark data and a large-scale real-simulation satellite drag interpolation problem.},
	urldate = {2020-09-07},
	journal = {arXiv:2008.12857 [stat]},
	author = {Cole, D. Austin and Christianson, Ryan and Gramacy, Robert B.},
	month = aug,
	year = {2020},
	note = {ZSCC: 0000000 
arXiv: 2008.12857},
	keywords = {Statistics - Machine Learning, Statistics - Computation, Statistics - Methodology},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/BRLGUWZM/2008.html:text/html;Locally induced Gaussian processes for large-scale simulation experiments - Cole et al - 2020.pdf:/home/theo/Zotero/storage/9QRZISPZ/Locally induced Gaussian processes for large-scale simulation experiments - Cole et al - 2020.pdf:application/pdf},
}

@article{nabeyaTransformationsPreservingNormality1986,
	title = {Transformations preserving normality and {Wishart}-ness},
	volume = {20},
	issn = {0047-259X},
	url = {http://www.sciencedirect.com/science/article/pii/0047259X86900813},
	doi = {10.1016/0047-259X(86)90081-3},
	abstract = {Let Rn×p, O(n), Gl(p) and S+(p) denote respectively the set of n×p matrices, the set of n×n orthogonal matrices, the set of p×p nonsingular matrices and the set of p × p positive definite matrices. In this paper, it is first shown that a bijective and bimeasurable transformation (BBT) g on Rp≡Rp×1 preserving the multivariate normality of Np(μ, Σ) for fixed μ=μ1, μ2 (μ1≠μ2) and for all Σ∈S+(p) is of the form g(x)=Ax+b a.e. for some (A, b)∈Gl(p)×Rp. Second, a BBT g on Rn×p preserving the form Nn×p(, I⊗Σ) for certain 's and all Σ∈S+(p) is shown to be of the form g(x)=QxA+E a.e. for some (Q, A, E)∈O(n)×Gl(p)×Rn×p. Third, a BBT h on S+(p) preserving the Wishart-ness of Wp(Σ, m) (m≥p) for all Σ∈S+(p) is shown to be of the form h(w)=A′wA a.e. for some A∈Gl(p). Fourth, a BBT k(x, w)=(k1(x, w), k2(x, w)) on Rn×p×S+(p) which preserves the form of Nn×p(, I⊗Σ)×Wp(Σ, m) for certain 's and all Σ∈S+(p) is shown to be of the form k(x, w)=(QxA+E, A′wA) a.e. for some (Q, A, E)∈O(n)×Gl(p)×Rn×p.},
	language = {en},
	number = {2},
	urldate = {2020-09-07},
	journal = {Journal of Multivariate Analysis},
	author = {Nabeya, Seiji and Kariya, Takeaki},
	month = dec,
	year = {1986},
	note = {ZSCC: 0000003},
	keywords = {Bijective, bimeasurable transformation, maximality of a group, normality preserving transformation, the MANOVA problem, Whishart-ness preserving transformation},
	pages = {251--264},
	file = {ScienceDirect Snapshot:/home/theo/Zotero/storage/GZQRDKUJ/0047259X86900813.html:text/html;Transformations preserving normality and Wishart-ness - Nabeya_Kariya - 1986.pdf:/home/theo/Zotero/storage/UX2DC24J/Transformations preserving normality and Wishart-ness - Nabeya_Kariya - 1986.pdf:application/pdf;Transformations preserving normality and Wishart-ness - Nabeya_Kariya - 1986.pdf:/home/theo/Zotero/storage/AG3BP5Z3/Transformations preserving normality and Wishart-ness - Nabeya_Kariya - 1986.pdf:application/pdf},
}

@article{weberOptimizingBayesianLast,
	title = {Optimizing over a {Bayesian} {Last} {Layer}},
	abstract = {We propose a new method for training neural networks online in a bandit setting. Similar to prior work, we model the uncertainty only in the last layer of the network, treating the rest of the network as a feature extractor. This allows us to successfully balance between exploration and exploitation due to the efﬁcient, closed-form uncertainty estimates available for linear models. To train the rest of the network, we take advantage of the posterior we have over the last layer, optimizing over all values in the last layer distribution weighted by probability. We derive a closed form, differential approximation to this objective and show empirically that this method leads to both better online and ofﬂine performance when compared to other methods.},
	language = {en},
	author = {Weber, Noah and Starc, Janez and Mittal, Arpit and Blanco, Roi and Màrquez, Lluís},
	note = {ZSCC: 0000003},
	pages = {9},
	file = {Optimizing over a Bayesian Last Layer - Weber et al -.pdf:/home/theo/Zotero/storage/M2TGLB8D/Optimizing over a Bayesian Last Layer - Weber et al -.pdf:application/pdf},
}

@article{fasanoScalableAccurateVariational2020,
	title = {Scalable and {Accurate} {Variational} {Bayes} for {High}-{Dimensional} {Binary} {Regression} {Models}},
	url = {http://arxiv.org/abs/1911.06743},
	abstract = {State-of-the-art methods for Bayesian inference on regression models with binary responses are either computationally impractical or inaccurate in high dimensions. To cover this gap we propose a novel variational approximation for the posterior distribution of the coefficients in high-dimensional probit regression with Gaussian priors. Our method leverages a representation with global and local variables but, unlike for classical mean-field assumptions, it avoids a fully factorized approximation, and instead assumes a factorization only for the local variables. We prove that the resulting variational approximation belongs to a tractable class of unified skew-normal distributions that preserves the skewness of the actual posterior and, unlike for state-of-the-art variational Bayes solutions, converges to the exact posterior as the number of predictors p increases. A scalable coordinate ascent variational algorithm is proposed to obtain the optimal parameters of the approximating densities. As shown in theoretical studies and with an application to Alzheimer's data, this routine requires a number of iterations converging to one as p diverges to infinity, and can easily scale to large p settings where expectation-propagation and state-of-the-art Markov chain Monte Carlo algorithms are computationally impractical.},
	urldate = {2020-09-02},
	journal = {arXiv:1911.06743 [stat]},
	author = {Fasano, Augusto and Durante, Daniele and Zanella, Giacomo},
	month = feb,
	year = {2020},
	note = {ZSCC: NoCitationData[s0] 
arXiv: 1911.06743},
	keywords = {Statistics - Computation, Statistics - Methodology},
	file = {arXiv.org Snapshot:/home/theo/Zotero/storage/E4HVNPIP/1911.html:text/html;Scalable and Accurate Variational Bayes for High-Dimensional Binary Regression - Fasano et al - 2020.pdf:/home/theo/Zotero/storage/P75GB8KI/Scalable and Accurate Variational Bayes for High-Dimensional Binary Regression - Fasano et al - 2020.pdf:application/pdf},
}

@article{ruizAugmentReduceStochastic2018,
	title = {Augment and {Reduce}: {Stochastic} {Inference} for {Large} {Categorical} {Distributions}},
	url = {http://arxiv.org/abs/1802.04220},
	abstract = {Categorical distributions are ubiquitous in machine learning, e.g., in classification, language models, and recommendation systems. However, when the number of possible outcomes is very large, using categorical distributions becomes computationally expensive, as the complexity scales linearly with the number of outcomes. To address this problem, we propose augment and reduce (A\&R), a method to alleviate the computational complexity. A\&R uses two ideas: latent variable augmentation and stochastic variational inference. It maximizes a lower bound on the marginal likelihood of the data. Unlike existing methods which are specific to softmax, A\&R is more general and is amenable to other categorical models, such as multinomial probit. On several large-scale classification problems, we show that A\&R provides a tighter bound on the marginal likelihood and has better predictive performance than existing approaches.},
	number = {3},
	author = {Ruiz, Francisco J. R. and Titsias, Michalis K. and Dieng, Adji B. and Blei, David M.},
	year = {2018},
	note = {ZSCC: 0000012 
arXiv: 1802.04220},
	file = {Augment and Reduce - Ruiz et al - 2018.pdf:/home/theo/Zotero/storage/QX9GDZDM/Augment and Reduce - Ruiz et al - 2018.pdf:application/pdf},
}

@software{theo_galy_fajou_2021_5728215,
  author    = {Théo Galy-Fajou},
  title     = {{theogf/AugmentedGaussianProcesses.jl}},
  month     = nov,
  year      = 2021,
  publisher = {Zenodo},
  version   = {v0.11.3},
  doi       = {10.5281/zenodo.5728215},
  url       = {https://doi.org/10.5281/zenodo.5728215}
}

@software{theo_galy_fajou_2022_6246597,
  author    = {Théo Galy-Fajou and
               David Widmann and
               Sharan Yalburgi and
               willtebbutt and
               st-- and
               Isak Falk and
               Steffen Ridderbusch and
               Tom Wright and
               david-vicente and
               Sebastian Khan and
               Hong Ge and
               Johannes Giersdorf and
               Julia TagBot and
               Letif Mones and
               Pietro Monticone and
               Ross Viljoen and
               Simon Schölly and
               Kaan Öcal},
  title     = {{JuliaGaussianProcesses/KernelFunctions.jl}},
  month     = feb,
  year      = 2022,
  publisher = {Zenodo},
  version   = {v0.10.33},
  doi       = {10.5281/zenodo.6246597},
  url       = {https://doi.org/10.5281/zenodo.6246597}
}

@software{david_widmann_2022_5939997,
  author    = {David Widmann and
               willtebbutt and
               Théo Galy-Fajou and
               st-- and
               Sharan Yalburgi and
               Hong Ge and
               david-vicente and
               Nathanael Bosch and
               Niklas Schmitz and
               Ross Viljoen and
               Tom Wright and
               andreaskoher},
  title     = {{JuliaGaussianProcesses/AbstractGPs.jl}},
  month     = feb,
  year      = 2022,
  publisher = {Zenodo},
  version   = {v0.5.5},
  doi       = {10.5281/zenodo.5939997},
  url       = {https://doi.org/10.5281/zenodo.5939997}
}

@software{theo_galy_fajou_2022_6347022,
  author    = {Théo Galy-Fajou},
  title     = {{JuliaGaussianProcesses/AugmentedGPLikelihoods.jl: 
               v0.4.9}},
  month     = mar,
  year      = 2022,
  publisher = {Zenodo},
  version   = {v0.4.9},
  doi       = {10.5281/zenodo.6347022},
  url       = {https://doi.org/10.5281/zenodo.6347022}
}

@article{cressie1990origins,
  title     = {The origins of kriging},
  author    = {Cressie, Noel},
  journal   = {Mathematical geology},
  volume    = {22},
  number    = {3},
  pages     = {239--252},
  year      = {1990},
  publisher = {Springer}
}

@article{donner2018efficientdensity,
  title   = {Efficient bayesian inference for a gaussian process density model},
  author  = {Donner, Christian and Opper, Manfred},
  journal = {arXiv preprint arXiv:1805.11494},
  year    = {2018}
}


@article{liu1994collapsed,
  title     = {The collapsed Gibbs sampler in Bayesian computations with applications to a gene regulation problem},
  author    = {Liu, Jun S},
  journal   = {Journal of the American Statistical Association},
  volume    = {89},
  number    = {427},
  pages     = {958--966},
  year      = {1994},
  publisher = {Taylor \& Francis}
}

@article{Julia-2017,
  title     = {Julia: A fresh approach to numerical computing},
  author    = {Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B},
  journal   = {SIAM {R}eview},
  volume    = {59},
  number    = {1},
  pages     = {65--98},
  year      = {2017},
  publisher = {SIAM},
  doi       = {10.1137/141000671},
  url       = {https://epubs.siam.org/doi/10.1137/141000671}
}

@inproceedings{NIPS2009_5ea1649a,
  author    = {L\'{a}zaro-Gredilla, Miguel and Figueiras-Vidal, An\'{\i}bal},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {Y. Bengio and D. Schuurmans and J. Lafferty and C. Williams and A. Culotta},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Inter-domain Gaussian Processes for Sparse Inference using Inducing Features},
  url       = {https://proceedings.neurips.cc/paper/2009/file/5ea1649a31336092c05438df996a3e59-Paper.pdf},
  volume    = {22},
  year      = {2009}
}

@article{vdw2020framework,
  author = {Mark van der Wilk and Vincent Dutordoir and ST John and Artem Artemev and Vincent Adam and James Hensman},
  eprint = {arXiv:2003.01115},
  title  = {A Framework for Interdomain and Multioutput Gaussian Processes},
  url    = {https://arxiv.org/abs/2003.01115},
  year   = {2020}
}


@inproceedings{pmlr-v9-turner10a,
  title     = {State-Space Inference and Learning with Gaussian Processes},
  author    = {Turner, Ryan and Deisenroth, Marc and Rasmussen, Carl},
  booktitle = {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages     = {868--875},
  year      = {2010},
  editor    = {Teh, Yee Whye and Titterington, Mike},
  volume    = {9},
  series    = {Proceedings of Machine Learning Research},
  address   = {Chia Laguna Resort, Sardinia, Italy},
  month     = {13--15 May},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v9/turner10a/turner10a.pdf},
  url       = {https://proceedings.mlr.press/v9/turner10a.html},
  abstract  = {State-space inference and learning with Gaussian processes (GPs) is an unsolved problem. We propose a new, general methodology for inference and learning in nonlinear state-space models that are described probabilistically by non-parametric GP models. We apply the expectation maximization algorithm to iterate between inference in the latent state-space and learning the parameters of the underlying GP dynamics model.}
}

@article{duane1987hybrid,
  title     = {Hybrid monte carlo},
  author    = {Duane, Simon and Kennedy, Anthony D and Pendleton, Brian J and Roweth, Duncan},
  journal   = {Physics letters B},
  volume    = {195},
  number    = {2},
  pages     = {216--222},
  year      = {1987},
  publisher = {Elsevier}
}

@inproceedings{murray2010elliptical,
  title        = {Elliptical slice sampling},
  author       = {Murray, Iain and Adams, Ryan and MacKay, David},
  booktitle    = {Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages        = {541--548},
  year         = {2010},
  organization = {JMLR Workshop and Conference Proceedings}
}

@article{GPflow2017,
  author  = {Matthews, Alexander G. de G. and {van der Wilk}, Mark and Nickson, Tom and
             Fujii, Keisuke. and {Boukouvalas}, Alexis and {Le{\'o}n-Villagr{\'a}}, Pablo and
             Ghahramani, Zoubin and Hensman, James},
  title   = {{{GP}flow: A {G}aussian process library using {T}ensor{F}low}},
  journal = {Journal of Machine Learning Research},
  year    = {2017},
  month   = {apr},
  volume  = {18},
  number  = {40},
  pages   = {1-6},
  url     = {http://jmlr.org/papers/v18/16-537.html}
}

@article{gardner2018gpytorch,
  title   = {Gpytorch: Blackbox matrix-matrix gaussian process inference with gpu acceleration},
  author  = {Gardner, Jacob and Pleiss, Geoff and Weinberger, Kilian Q and Bindel, David and Wilson, Andrew G},
  journal = {Advances in neural information processing systems},
  volume  = {31},
  year    = {2018}
}

@article{schwartz1952transformation,
  title   = {Transformation de Laplace des distributions},
  author  = {Schwartz, Laurent},
  journal = {Comm. S{\'e}m. Math. Univ. Lund [Medd. Lunds Univ. Mat. Sem.]},
  volume  = {1952},
  number  = {Tome Suppl{\'e}mentaire},
  pages   = {196--206},
  year    = {1952}
}
